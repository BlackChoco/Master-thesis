import torch
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import random
from typing import List, Dict, Tuple, Optional, Union # Added Union
from Tree_data_model import PostStorage, ForestManager
import pickle
from collections import defaultdict, Counter # Added Counter
from tqdm import tqdm
import copy
# ä¿®æ”¹å¯¼å…¥ï¼šä½¿ç”¨ModelScopeæ›¿ä»£transformers
from modelscope import AutoModel, AutoTokenizer
from peft import get_peft_model, LoraConfig
import pandas as pd
import json
import itertools
import jieba # Added jieba
import os # Added os
import torch.nn.functional as F # Added F for TextCNN
import matplotlib.pyplot as plt # æ–°å¢
import io # æ–°å¢
import matplotlib.image as mpimg # æ–°å¢
import warnings
import re # æ–°å¢

# æ­¤è®¾ç½®å°†æŠ‘åˆ¶ (ignore) æ¶ˆæ¯å†…å®¹åŒ¹é…ç‰¹å®šæ¨¡å¼çš„ UserWarning ç±»å‹çš„è­¦å‘Š
# å…·ä½“æ¥è¯´ï¼Œå®ƒé’ˆå¯¹çš„æ˜¯ matplotlib åº“ä¸­å…³äº Arial å­—ä½“ç¼ºå°‘å­—å½¢ (Glyph) è€Œäº§ç”Ÿçš„è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, message=r"Glyph .* missing from font\(s\) Arial\.")

def preprocess_text(text: str) -> str:
    """
    å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼š
    1. å»é™¤æ–¹æ‹¬å·å†…çš„è¡¨æƒ…ç¬¦å·ï¼Œå¦‚ '[ç¬‘å“­]'ã€‚
    2. å»é™¤æŒ‡å®šçš„å“ç‰Œåç§°ã€‚
    3. è¿”å›å¤„ç†åå¹¶å»é™¤é¦–å°¾ç©ºæ ¼çš„æ–‡æœ¬ã€‚
    """
    if not isinstance(text, str):
        return ""
    
    # 1. æ­£åˆ™åŒ¹é…'[]'å»æ‰è¡¨æƒ…ç¬¦å·
    processed_text = re.sub(r'\[.*?\]', '', text)

    # --- æ–°å¢ï¼šå»æ‰@ç”¨æˆ·åçš„æ–‡æœ¬ ---
    # è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ä¼šåŒ¹é… '@' ç¬¦å·ï¼Œåé¢è·Ÿç€ä¸€ä¸ªæˆ–å¤šä¸ªéç©ºæ ¼å­—ç¬¦ï¼Œ
    # æœ€åå¯èƒ½è·Ÿç€ä¸€ä¸ªç©ºæ ¼ã€‚
    processed_text = re.sub(r'@\S+\s?', '', processed_text)

    # 2. å»æ‰å‚å•†çš„åå­—
    brand_names = [
        'å°ç±³', 'è‹¹æœ', 'ä¸‰æ˜Ÿ', 'è£è€€', 'åä¸º', 'ä¸€åŠ ', 
        'oppo', 'OPPO', 'vivo', 'realme', 'çº¢ç±³', 'çœŸæˆ‘','å®‰å“',
        'x7pro','x100s','gt5pro','GTneo5','pro','æ‰‹æœº','11','12','13','14','å¤‡ç”¨æœº',
        'p40'
    ]
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä¸€æ¬¡æ€§æ›¿æ¢æ‰€æœ‰å“ç‰Œåï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    brand_pattern = re.compile('|'.join(brand_names), re.IGNORECASE)
    processed_text = brand_pattern.sub('', processed_text)
    
    return processed_text.strip()

# æ·»åŠ ModelScopeè¾…åŠ©å‡½æ•°
def load_model_from_modelscope(model_name_or_path: str, trust_remote_code: bool = True, **kwargs):
    """
    ä¼˜å…ˆä»ModelScopeåŠ è½½æ¨¡å‹ï¼Œå¤±è´¥æ—¶æç¤ºç”¨æˆ·
    """
    try:
        print(f"ğŸ” æ­£åœ¨ä»ModelScopeåŠ è½½æ¨¡å‹: {model_name_or_path}")
        model = AutoModel.from_pretrained(
            model_name_or_path, 
            trust_remote_code=trust_remote_code,
            **kwargs
        )
        print(f"âœ… æˆåŠŸä»ModelScopeåŠ è½½æ¨¡å‹: {model_name_or_path}")
        return model
    except Exception as e:
        print(f"âŒ ä»ModelScopeåŠ è½½æ¨¡å‹å¤±è´¥: {model_name_or_path}")
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        print("è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ã€‚")
        raise e

def load_tokenizer_from_modelscope(model_name_or_path: str, trust_remote_code: bool = True, **kwargs):
    """
    ä¼˜å…ˆä»ModelScopeåŠ è½½åˆ†è¯å™¨ï¼Œå¤±è´¥æ—¶æç¤ºç”¨æˆ·
    """
    try:
        print(f"ğŸ” æ­£åœ¨ä»ModelScopeåŠ è½½åˆ†è¯å™¨: {model_name_or_path}")
        tokenizer = AutoTokenizer.from_pretrained(
            model_name_or_path, 
            trust_remote_code=trust_remote_code,
            **kwargs
        )
        print(f"âœ… æˆåŠŸä»ModelScopeåŠ è½½åˆ†è¯å™¨: {model_name_or_path}")
        return tokenizer
    except Exception as e:
        print(f"âŒ ä»ModelScopeåŠ è½½åˆ†è¯å™¨å¤±è´¥: {model_name_or_path}")
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        print("è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ã€‚")
        raise e
    
# Helper function to build vocabulary
def build_vocab_from_post_storage(post_storage: PostStorage, min_freq: int = 1) -> Tuple[Dict[str, int], int]:
    """
    ä½¿ç”¨jiebaä»PostStorageä¸­çš„æ‰€æœ‰è¯„è®ºå†…å®¹æ„å»ºè¯æ±‡è¡¨ã€‚
    """
    print("æ­£åœ¨ä½¿ç”¨ jieba æ„å»ºè¯æ±‡è¡¨...")
    word_counts = Counter()
    
    all_comments_content = []
    for post_id, post_tree in post_storage.posts.items():
        def collect_content_from_node(node):
            if node.content and isinstance(node.content, str): # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²
                all_comments_content.append(node.content)
            else:
                # å¦‚æœå†…å®¹ä¸æ˜¯å­—ç¬¦ä¸²æˆ–ä¸ºç©ºï¼Œå¯ä»¥è®°å½•æˆ–è·³è¿‡
                # print(f"è­¦å‘Š: èŠ‚ç‚¹ {node.comment_id} åœ¨å¸–å­ {post_id} ä¸­çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆå­—ç¬¦ä¸²: {node.content}")
                pass # æˆ–è€… all_comments_content.append("") å¦‚æœå¸Œæœ›ç©ºå­—ç¬¦ä¸²å‚ä¸
            for child in node.children:
                collect_content_from_node(child)
        if post_tree.root: # ç¡®ä¿æ ¹èŠ‚ç‚¹å­˜åœ¨
            collect_content_from_node(post_tree.root)

    print(f"æ‰¾åˆ° {len(all_comments_content)} æ¡è¯„è®ºç”¨äºæ„å»ºè¯æ±‡è¡¨ã€‚")
    
    for text in tqdm(all_comments_content, desc="è¯„è®ºåˆ†è¯ä¸­"):
        if text and isinstance(text, str): # å†æ¬¡ç¡®ä¿æ–‡æœ¬æ˜¯æœ‰æ•ˆå­—ç¬¦ä¸²
            try:
                seg_list = jieba.lcut(text.strip())
                word_counts.update(seg_list)
            except Exception as e:
                print(f"è­¦å‘Š: jieba åˆ†è¯å¤±è´¥ï¼Œæ–‡æœ¬: '{text[:50]}...'ï¼Œé”™è¯¯: {e}")
        elif not text:
            pass # è·³è¿‡ç©ºæ–‡æœ¬
        else:
            print(f"è­¦å‘Š: æ— æ•ˆçš„æ–‡æœ¬ç±»å‹è¿›è¡Œåˆ†è¯: {type(text)}, å†…å®¹: {text[:50]}...")


    # åˆ›å»ºè¯æ±‡è¡¨
    # ç‰¹æ®Šæ ‡è®°: <pad> ç”¨äºå¡«å……, <unk> ç”¨äºæœªçŸ¥è¯
    vocab = {"<pad>": 0, "<unk>": 1}
    idx = 2 # ä»2å¼€å§‹ç´¢å¼•
    for word, count in word_counts.items():
        if count >= min_freq:
            vocab[word] = idx
            idx += 1
    
    print(f"è¯æ±‡è¡¨æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(vocab)} ä¸ªç‹¬ç«‹è¯å…ƒ (min_freq={min_freq})ã€‚")
    return vocab, len(vocab)

class TextCNNTokenizer:
    """
    ä½¿ç”¨é¢„æ„å»ºè¯æ±‡è¡¨å’Œjiebaçš„TextCNNæ¨¡å‹åˆ†è¯å™¨ã€‚
    """
    def __init__(self, word_to_idx: Dict[str, int], max_length: int = 128):
        self.word_to_idx = word_to_idx
        self.max_length = max_length
        self.pad_token = "<pad>"
        self.unk_token = "<unk>"
        self.pad_token_id = word_to_idx.get(self.pad_token, 0) # æä¾›é»˜è®¤å€¼ä»¥é˜²ä¸‡ä¸€
        self.unk_token_id = word_to_idx.get(self.unk_token, 1) # æä¾›é»˜è®¤å€¼

    def tokenize(self, text: str) -> List[str]:
        if not isinstance(text, str):
            text = str(text) # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return jieba.lcut(text.strip())

    def convert_tokens_to_ids(self, tokens: List[str]) -> List[int]:
        return [self.word_to_idx.get(token, self.unk_token_id) for token in tokens]

    def _pad_truncate_single(self, token_ids: List[int], max_len: int) -> Tuple[List[int], List[int]]:
        attention_mask = [1] * len(token_ids)
        if len(token_ids) < max_len:
            padding_len = max_len - len(token_ids)
            token_ids.extend([self.pad_token_id] * padding_len)
            attention_mask.extend([0] * padding_len)
        elif len(token_ids) > max_len:
            token_ids = token_ids[:max_len]
            attention_mask = attention_mask[:max_len]
        return token_ids, attention_mask

    def __call__(self, texts: Union[str, List[str]], padding: Union[bool, str] = True, 
                 truncation: Union[bool, str] = True, return_tensors: Optional[str] = None, 
                 max_length: Optional[int] = None) -> Dict[str, Union[List[List[int]], torch.Tensor]]:
        if isinstance(texts, str):
            texts = [texts]
        
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½æ˜¯å­—ç¬¦ä¸²
        processed_texts = []
        for i, text_input in enumerate(texts):
            if not isinstance(text_input, str):
                # print(f"è­¦å‘Š: è¾“å…¥æ–‡æœ¬ {i} ä¸æ˜¯å­—ç¬¦ä¸² (ç±»å‹: {type(text_input)}), å°†å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚å†…å®¹: {str(text_input)[:50]}...")
                processed_texts.append(str(text_input))
            else:
                processed_texts.append(text_input)
        texts = processed_texts
        
        effective_max_length = max_length if max_length is not None else self.max_length

        batch_input_ids = []
        batch_attention_masks = []

        for text in texts:
            tokens = self.tokenize(text)
            token_ids = self.convert_tokens_to_ids(tokens)
            
            # æ ¹æ® truncation å’Œ padding å‚æ•°å¤„ç†
            if truncation:
                token_ids = token_ids[:effective_max_length]
            
            # åªæœ‰åœ¨ padding ä¸º True æ—¶æ‰è¿›è¡Œå¡«å……
            if padding:
                # å¦‚æœ truncation=True, token_ids å·²ç»è¢«æˆªæ–­åˆ° effective_max_length
                # å¦‚æœ truncation=False, token_ids å¯èƒ½ä»ç„¶è¶…è¿‡ effective_max_length, ä½†æˆ‘ä»¬åªå¡«å……åˆ° effective_max_length
                current_len = len(token_ids)
                attention_mask = [1] * current_len
                if current_len < effective_max_length:
                    pad_len = effective_max_length - current_len
                    token_ids.extend([self.pad_token_id] * pad_len)
                    attention_mask.extend([0] * pad_len)
                elif current_len > effective_max_length: # ç†è®ºä¸Šå¦‚æœ truncation=True ä¸ä¼šå‘ç”Ÿ
                    token_ids = token_ids[:effective_max_length]
                    attention_mask = [1] * effective_max_length

                padded_ids = token_ids
            else: #ä¸å¡«å……
                padded_ids = token_ids 
                attention_mask = [1] * len(token_ids)


            batch_input_ids.append(padded_ids)
            batch_attention_masks.append(attention_mask)

        if return_tensors == 'pt':
            # å¦‚æœ padding=Falseï¼Œä¸”åºåˆ—é•¿åº¦ä¸ä¸€è‡´ï¼Œtorch.tensor ä¼šæŠ¥é”™
            # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒHuggingFace é€šå¸¸ä¼šè¦æ±‚ç”¨æˆ·ä½¿ç”¨ DataCollator
            # è¿™é‡Œï¼Œå¦‚æœ padding=False ä½†è¦æ±‚ ptï¼Œæˆ‘ä»¬å¡«å……åˆ°æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦
            if not padding:
                max_len_in_batch = 0
                if batch_input_ids: # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                    max_len_in_batch = max(len(ids) for ids in batch_input_ids) if batch_input_ids else 0
                
                if max_len_in_batch > 0 : # ä»…å½“æœ‰å®é™…æ•°æ®æ—¶æ“ä½œ
                    for i in range(len(batch_input_ids)):
                        ids = batch_input_ids[i]
                        mask = batch_attention_masks[i]
                        len_diff = max_len_in_batch - len(ids)
                        if len_diff > 0:
                            batch_input_ids[i] = ids + [self.pad_token_id] * len_diff
                            batch_attention_masks[i] = mask + [0] * len_diff
            try:
                batch_input_ids_tensor = torch.tensor(batch_input_ids, dtype=torch.long)
                batch_attention_masks_tensor = torch.tensor(batch_attention_masks, dtype=torch.long)
            except RuntimeError as e:
                print(f"å°†åˆ—è¡¨è½¬æ¢ä¸ºå¼ é‡æ—¶å‡ºé”™ã€‚æ£€æŸ¥åºåˆ—é•¿åº¦æ˜¯å¦ä¸€è‡´ã€‚é”™è¯¯: {e}")
                print(f"æ‰¹å¤„ç†è¾“å…¥IDé•¿åº¦: {[len(ids) for ids in batch_input_ids]}")
                # å¯ä»¥é€‰æ‹©æŠ›å‡ºé”™è¯¯æˆ–å°è¯•è¿›ä¸€æ­¥å¤„ç†/è°ƒè¯•
                raise e

            return {
                'input_ids': batch_input_ids_tensor,
                'attention_mask': batch_attention_masks_tensor
            }
        else: # è¿”å›åˆ—è¡¨
            return {
                'input_ids': batch_input_ids,
                'attention_mask': batch_attention_masks
            }

class TextCNNModel(torch.nn.Module):
    """
    ç”¨äºå¥å­åµŒå…¥çš„TextCNNæ¨¡å‹ã€‚
    """
    def __init__(self, vocab_size: int, embedding_dim: int, num_filters: int, 
                 filter_sizes: List[int], output_dim_for_encoder: int, dropout_rate: float = 0.1):
        super().__init__()
        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.convs = torch.nn.ModuleList([
            torch.nn.Conv1d(in_channels=embedding_dim, 
                            out_channels=num_filters, 
                            kernel_size=K) 
            for K in filter_sizes
        ])
        self.dropout = torch.nn.Dropout(dropout_rate)
        # TextCNNæœ¬èº«çš„è¾“å‡ºç»´åº¦ï¼Œåœ¨ContrastiveEncoderä¸­çš„æŠ•å½±å¤´ä¹‹å‰
        self.fc = torch.nn.Linear(len(filter_sizes) * num_filters, output_dim_for_encoder)
        self.base_dim = output_dim_for_encoder # <--- æ·»åŠ è¿™ä¸€è¡Œ

    def forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        # input_ids: [batch_size, seq_len]
        embedded = self.embedding(input_ids)  # [batch_size, seq_len, embedding_dim]
        
        # (å¯é€‰) åº”ç”¨ attention_mask åˆ°åµŒå…¥å±‚ï¼Œå°†å¡«å……ä½ç½®çš„åµŒå…¥ç½®é›¶
        if attention_mask is not None:
            embedded = embedded * attention_mask.unsqueeze(-1).float()

        embedded = embedded.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]
        
        conved = [F.relu(conv(embedded)) for conv in self.convs]
        # conved[i]: [batch_size, num_filters, seq_len - filter_sizes[i] + 1]
        
        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]
        # pooled[i]: [batch_size, num_filters]
        
        cat = self.dropout(torch.cat(pooled, dim=1)) # [batch_size, num_filters * len(filter_sizes)]
        output = self.fc(cat) # [batch_size, output_dim_for_encoder]
        return output

class ContrastiveDataset1(Dataset):
    """
    Dataset1: ä»ç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼çš„çˆ¶å­è¯„è®ºå¯¹ä¸­æ„å»ºæ­£æ ·æœ¬
    ç”¨äºå­¦ä¹ å±€éƒ¨è¯­ä¹‰ç›¸ä¼¼æ€§
    """
    
    def __init__(self, post_storage: PostStorage, similarity_threshold: float = 0.5, 
                 min_subtree_size: int = 2, max_samples_per_post: Optional[int] = None):
        self.post_storage = post_storage
        self.similarity_threshold = similarity_threshold
        self.min_subtree_size = min_subtree_size
        self.positive_pairs = []
        self.comments_by_post = defaultdict(list)
        self._build_dataset(max_samples_per_post)
    
    def _ensure_str_content(self, content, default_str=""):
        if not isinstance(content, str):
            # print(f"è­¦å‘Š: å†…å®¹ä¸æ˜¯å­—ç¬¦ä¸² (ç±»å‹: {type(content)}), å°†è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ã€‚å†…å®¹: {str(content)[:30]}...")
            return default_str
        return content

    def _build_dataset(self, max_samples_per_post: Optional[int]):
        print("ğŸ”¨ æ„å»ºDataset1: çˆ¶å­è¯„è®ºç›¸ä¼¼åº¦å¯¹æ¯”å­¦ä¹ æ•°æ®é›†")
        total_pairs = 0
        for post_id, forest in tqdm(self.post_storage.forests.items(), desc="å¤„ç†å¸–å­(Dataset1)"):
            post_pairs = []
            if forest.subtrees is None: # ç¡®ä¿ subtrees å·²åˆå§‹åŒ–
                # print(f"è­¦å‘Š: å¸–å­ {post_id} çš„ forest.subtrees ä¸º Noneï¼Œè·³è¿‡ã€‚")
                continue

            for subtree_info in forest.subtrees:
                if subtree_info['size'] >= self.min_subtree_size:
                    pairs = self._extract_high_similarity_pairs(subtree_info['root'], post_id)
                    post_pairs.extend(pairs)
            
            if max_samples_per_post and len(post_pairs) > max_samples_per_post:
                post_pairs = random.sample(post_pairs, max_samples_per_post)
            
            self.positive_pairs.extend(post_pairs)
            total_pairs += len(post_pairs)
            self._collect_comments_for_negative_sampling(forest, post_id)
        print(f"âœ… Dataset1æ„å»ºå®Œæˆ: {total_pairs} ä¸ªæ­£æ ·æœ¬å¯¹ï¼Œè¦†ç›– {len(self.comments_by_post)} ä¸ªå¸–å­")

    def _extract_high_similarity_pairs(self, root, post_id) -> List[Dict]:
        pairs = []
        def traverse_node(node):
            node_content_raw = self._ensure_str_content(node.content)
            for child in node.children:
                child_content_raw = self._ensure_str_content(child.content)

                # --- æ–°å¢ï¼šé¢„å¤„ç†å’Œè¿‡æ»¤ ---
                parent_content_clean = preprocess_text(node_content_raw)
                child_content_clean = preprocess_text(child_content_raw)

                # 3. å½“å»æ‰è¿™äº›å­—ç¬¦åï¼Œæ–‡æœ¬é•¿åº¦lenï¼ˆï¼‰å°äº5çš„æ–‡æœ¬åº”è¯¥å»æ‰
                if len(parent_content_clean) < 5 or len(child_content_clean) < 5:
                    traverse_node(child) # å³ä½¿å½“å‰å¯¹ä¸åˆæ ¼ï¼Œä»éœ€ç»§ç»­éå†å­èŠ‚ç‚¹
                    continue
                # --- ç»“æŸæ–°å¢ ---

                try:
                    similarity = node.calculate_similarity(child) # å‡è®¾æ­¤æ–¹æ³•èƒ½å¤„ç†éå­—ç¬¦ä¸²å†…å®¹æˆ–å·²åœ¨å†…éƒ¨å¤„ç†
                    if similarity >= self.similarity_threshold:
                        pairs.append({
                            'parent_content': parent_content_clean, # ä½¿ç”¨æ¸…æ´—åçš„æ–‡æœ¬
                            'child_content': child_content_clean,   # ä½¿ç”¨æ¸…æ´—åçš„æ–‡æœ¬
                            'parent_id': node.comment_id,
                            'child_id': child.comment_id,
                            'similarity': similarity,
                            'post_id': post_id
                        })
                except (ValueError, AttributeError, TypeError) as e:
                    # print(f"è­¦å‘Š: è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ (çˆ¶: {node.comment_id}, å­: {child.comment_id})ï¼Œé”™è¯¯: {e}")
                    pass
                traverse_node(child)
        if root: traverse_node(root)
        return pairs

    def _collect_comments_for_negative_sampling(self, forest, post_id):
        comments = []
        if forest.subtrees is None: return

        for subtree_info in forest.subtrees:
            def collect_from_node(node):
                content_str = self._ensure_str_content(node.content)
                comments.append({'content': content_str, 'comment_id': node.comment_id, 'post_id': post_id})
                for child in node.children:
                    collect_from_node(child)
            if subtree_info['root']: collect_from_node(subtree_info['root'])
        self.comments_by_post[post_id] = comments
    
    def __len__(self):
        return len(self.positive_pairs)
    
    def __getitem__(self, idx):
        pair = self.positive_pairs[idx]
        return {
            'anchor_content': self._ensure_str_content(pair['parent_content']),
            'positive_content': self._ensure_str_content(pair['child_content']),
            'post_id': pair['post_id'],
            'similarity_score': pair['similarity'],
            'pair_type': 'parent_child'
        }
    
    def get_negative_samples(self, post_id: str, num_negatives: int = 1) -> List[str]:
        other_posts = [pid for pid in self.comments_by_post.keys() if pid != post_id]
        if not other_posts: return []
        negative_contents = []
        attempts = 0
        max_attempts = num_negatives * 5 # é¿å…æ— é™å¾ªç¯
        while len(negative_contents) < num_negatives and attempts < max_attempts:
            neg_post_id = random.choice(other_posts)
            neg_comments = self.comments_by_post[neg_post_id]
            if neg_comments:
                neg_comment = random.choice(neg_comments)
                content_str = self._ensure_str_content(neg_comment['content'])
                if content_str: # ç¡®ä¿è´Ÿæ ·æœ¬å†…å®¹ä¸ä¸ºç©º
                    negative_contents.append(content_str)
            attempts +=1
        # å¦‚æœä»ç„¶ä¸è¶³ï¼Œç”¨å ä½ç¬¦æˆ–é‡å¤
        while len(negative_contents) < num_negatives:
            negative_contents.append("<unk>") # æˆ–è€…å…¶ä»–å ä½ç¬¦
        return negative_contents

class ContrastiveDataset2(Dataset):
    """
    Dataset2: ä»å­æ ‘èŠ‚ç‚¹ä¸å­æ ‘å¹³å‡å†…å®¹æ„å»ºæ­£æ ·æœ¬
    ç”¨äºå­¦ä¹ å…¨å±€èšç±»ç›¸ä¼¼æ€§
    """
    def __init__(self, post_storage: PostStorage, min_subtree_size: int = 3,
                 max_samples_per_subtree: Optional[int] = None):
        self.post_storage = post_storage
        self.min_subtree_size = max(min_subtree_size, 3)
        self.positive_pairs = []
        self.comments_by_post = defaultdict(list)
        self._build_dataset(max_samples_per_subtree)

    def _ensure_str_content(self, content, default_str=""):
        if not isinstance(content, str):
            # print(f"è­¦å‘Š: å†…å®¹ä¸æ˜¯å­—ç¬¦ä¸² (ç±»å‹: {type(content)}), å°†è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ã€‚å†…å®¹: {str(content)[:30]}...")
            return default_str
        return content

    def _build_dataset(self, max_samples_per_subtree: Optional[int]):
        print("ğŸ”¨ æ„å»ºDataset2: èŠ‚ç‚¹-å­æ ‘ä¸­å¿ƒå¯¹æ¯”å­¦ä¹ æ•°æ®é›†")
        total_pairs = 0
        for post_id, forest in tqdm(self.post_storage.forests.items(), desc="å¤„ç†å¸–å­(Dataset2)"):
            post_pairs = []
            if forest.subtrees is None: continue

            for subtree_info in forest.subtrees:
                if subtree_info['size'] >= self.min_subtree_size and subtree_info['root']:
                    subtree_node_contents = self._collect_subtree_node_contents(subtree_info['root'])
                    if subtree_node_contents: # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                        pairs = self._extract_node_center_pairs(
                            subtree_info['root'], subtree_node_contents, post_id,
                            max_samples_per_subtree
                        )
                        post_pairs.extend(pairs)
            
            self.positive_pairs.extend(post_pairs)
            total_pairs += len(post_pairs)
            self._collect_comments_for_negative_sampling(forest, post_id)
        print(f"âœ… Dataset2æ„å»ºå®Œæˆ: {total_pairs} ä¸ªæ­£æ ·æœ¬å¯¹ï¼Œè¦†ç›– {len(self.comments_by_post)} ä¸ªå¸–å­")

    def _collect_subtree_node_contents(self, root) -> List[str]:
        contents = []
        def collect_contents(node):
            content_raw = self._ensure_str_content(node.content)
            # --- æ–°å¢ï¼šé¢„å¤„ç†å’Œè¿‡æ»¤ ---
            content_clean = preprocess_text(content_raw)
            if len(content_clean) >= 5: # åªæ·»åŠ é•¿åº¦åˆæ ¼çš„å¹²å‡€æ–‡æœ¬
                contents.append(content_clean)
            # --- ç»“æŸæ–°å¢ ---
            for child in node.children:
                collect_contents(child)
        if root: collect_contents(root)
        return contents

    def _extract_node_center_pairs(self, root, subtree_node_contents: List[str], post_id,
                                 max_samples: Optional[int]) -> List[Dict]:
        pairs = []
        # subtree_node_contents åˆ—è¡¨æ­¤æ—¶å·²æ˜¯æ¸…æ´—å’Œè¿‡æ»¤åçš„ï¼Œä½†æˆ‘ä»¬ä»éœ€æ£€æŸ¥å®ƒæ˜¯å¦ä¸ºç©º
        if not subtree_node_contents: return []

        # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹ï¼Œå³ä½¿å…¶å†…å®¹ä¸ºç©ºï¼Œå› ä¸ºå®ƒä»¬ä»ç„¶æ˜¯å­æ ‘çš„ä¸€éƒ¨åˆ†
        # ä½†ç”¨äºé…å¯¹çš„ anchor_content å¿…é¡»æ˜¯æœ‰æ•ˆå­—ç¬¦ä¸²
        all_nodes_in_subtree = []
        def _collect_all_nodes(node):
            all_nodes_in_subtree.append(node)
            for child in node.children:
                _collect_all_nodes(child)
        if root: _collect_all_nodes(root)
        
        for node in all_nodes_in_subtree:
            node_content_raw = self._ensure_str_content(node.content)
            # --- æ–°å¢ï¼šå¯¹é”šç‚¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†å’Œè¿‡æ»¤ ---
            node_content_clean = preprocess_text(node_content_raw)
            if len(node_content_clean) < 5:
                continue # å¦‚æœé”šç‚¹æ–‡æœ¬ä¸åˆæ ¼ï¼Œåˆ™è·³è¿‡
            # --- ç»“æŸæ–°å¢ ---

            # é”šç‚¹å†…å®¹å¿…é¡»æœ‰æ•ˆ (æ­¤æ£€æŸ¥ç°åœ¨æ˜¯å¤šä½™çš„ï¼Œä½†ä¿ç•™æ— å®³)
            if node_content_clean: 
                pairs.append({
                    'node_content': node_content_clean, # ä½¿ç”¨æ¸…æ´—åçš„æ–‡æœ¬
                    'center_node_contents': subtree_node_contents, # æ­¤åˆ—è¡¨å·²åœ¨æ”¶é›†ä¸­è¢«æ¸…æ´—
                    'node_id': node.comment_id,
                    'post_id': post_id,
                    'subtree_size': len(all_nodes_in_subtree) # ä½¿ç”¨å®é™…æ”¶é›†åˆ°çš„èŠ‚ç‚¹æ•°
                })
        
        if max_samples and len(pairs) > max_samples:
            pairs = random.sample(pairs, max_samples)
        return pairs
    
    def _collect_comments_for_negative_sampling(self, forest, post_id):
        # ä¸Dataset1ä¸­çš„æ–¹æ³•ç›¸åŒ
        comments = []
        if forest.subtrees is None: return
        for subtree_info in forest.subtrees:
            def collect_from_node(node):
                content_str = self._ensure_str_content(node.content)
                comments.append({'content': content_str, 'comment_id': node.comment_id, 'post_id': post_id})
                for child in node.children:
                    collect_from_node(child)
            if subtree_info['root']: collect_from_node(subtree_info['root'])
        self.comments_by_post[post_id] = comments
            
    def __len__(self):
        return len(self.positive_pairs)
    
    def __getitem__(self, idx):
        pair = self.positive_pairs[idx]
        return {
            'anchor_content': self._ensure_str_content(pair['node_content']),
            'positive_content_list': [self._ensure_str_content(c) for c in pair['center_node_contents']],
            'post_id': pair['post_id'],
            'subtree_size': pair['subtree_size'],
            'pair_type': 'node_center',
            'is_center_embedding': False
        }

    def get_negative_samples(self, post_id: str, num_negatives: int = 1) -> List[str]:
        # ä¸Dataset1ä¸­çš„æ–¹æ³•ç›¸åŒ
        other_posts = [pid for pid in self.comments_by_post.keys() if pid != post_id]
        if not other_posts: return []
        negative_contents = []
        attempts = 0
        max_attempts = num_negatives * 5 
        while len(negative_contents) < num_negatives and attempts < max_attempts:
            neg_post_id = random.choice(other_posts)
            neg_comments = self.comments_by_post[neg_post_id]
            if neg_comments:
                neg_comment = random.choice(neg_comments)
                content_str = self._ensure_str_content(neg_comment['content'])
                if content_str:
                    negative_contents.append(content_str)
            attempts +=1
        while len(negative_contents) < num_negatives:
            negative_contents.append("<unk>")
        return negative_contents

class ContrastiveEncoder(torch.nn.Module):
    """
    ğŸ”§ ä¿®æ”¹åçš„å¯¹æ¯”ç¼–ç å™¨ï¼šæ”¯æŒModelScope AutoModelå’Œè‡ªå®šä¹‰TextCNNã€‚
    """
    def __init__(self, model_type: str,
                 model_name_or_path: Optional[str] = None, # ModelScopeæ¨¡å‹è·¯å¾„æˆ–TextCNNçš„åç§°
                 vocab: Optional[Dict[str, int]] = None, # ä»…TextCNNéœ€è¦
                 textcnn_config: Optional[Dict] = None, # ä»…TextCNNéœ€è¦
                 projection_hidden_dim: int = 512, 
                 projection_output_dim: int = 256, 
                 projection_dropout_rate: float = 0.1):
        super().__init__()
        self.model_type = model_type.lower()
        self.tokenizer = None # åˆå§‹åŒ–
        self.base_model = None # åˆå§‹åŒ–
        self.base_dim = 0 # åˆå§‹åŒ–

        if self.model_type == 'modelscope':
            if model_name_or_path is None:
                raise ValueError("å¯¹äº 'modelscope' æ¨¡å‹ç±»å‹ï¼Œmodel_name_or_path æ˜¯å¿…éœ€çš„")
            
            # ä½¿ç”¨ModelScopeåŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
            self.tokenizer = load_tokenizer_from_modelscope(model_name_or_path)
            self.base_model = load_model_from_modelscope(
                model_name_or_path,
                torch_dtype=torch.float32  # å¼ºåˆ¶float32
            )
            
            if hasattr(self.base_model.config, 'hidden_size'):
                 self.base_dim = self.base_model.config.hidden_size
            elif hasattr(self.base_model.config, 'd_model'): # ä¾‹å¦‚T5
                 self.base_dim = self.base_model.config.d_model
            else:
                # å°è¯•ä»æ¨¡å‹è¾“å‡ºè·å–ç»´åº¦ï¼ˆå¦‚æœæ¨¡å‹å·²åŠ è½½å‚æ•°ï¼‰
                try:
                    dummy_input = self.tokenizer("test", return_tensors="pt")
                    # ç§»é™¤ token_type_ids å¦‚æœæ¨¡å‹ä¸æ”¯æŒ (ä¾‹å¦‚ distilbert)
                    if 'token_type_ids' in dummy_input and not any(p.name == 'token_type_ids' for p in self.base_model.forward.__code__.co_varnames):
                        del dummy_input['token_type_ids']
                    dummy_output = self.base_model(**dummy_input)
                    if hasattr(dummy_output, 'last_hidden_state'):
                        self.base_dim = dummy_output.last_hidden_state.shape[-1]
                    elif isinstance(dummy_output, torch.Tensor):
                         self.base_dim = dummy_output.shape[-1]
                    else:
                        raise ValueError(f"æ— æ³•è‡ªåŠ¨ç¡®å®šModelScopeæ¨¡å‹ {model_name_or_path} çš„åŸºç¡€ç»´åº¦ã€‚è¯·æ£€æŸ¥æ¨¡å‹é…ç½®ã€‚")
                except Exception as e:
                     raise ValueError(f"å°è¯•ç¡®å®šModelScopeæ¨¡å‹ {model_name_or_path} åŸºç¡€ç»´åº¦æ—¶å‡ºé”™: {e}")

            print(f"ğŸ—ï¸ ModelScope ContrastiveEncoder åˆå§‹åŒ–å®Œæˆ:")
            print(f"   åŸºç¡€æ¨¡å‹: {model_name_or_path}")

        elif self.model_type == 'textcnn':
            if vocab is None or textcnn_config is None:
                raise ValueError("å¯¹äº 'textcnn' æ¨¡å‹ç±»å‹ï¼Œvocab å’Œ textcnn_config æ˜¯å¿…éœ€çš„")
            
            _max_len = textcnn_config.get('max_seq_length', 128)
            self.tokenizer = TextCNNTokenizer(vocab, max_length=_max_len)
            self.base_model = TextCNNModel(
                vocab_size=len(vocab),
                embedding_dim=textcnn_config['embedding_dim'],
                num_filters=textcnn_config['num_filters'],
                filter_sizes=textcnn_config['filter_sizes'],
                output_dim_for_encoder=textcnn_config['textcnn_output_dim'],
                dropout_rate=textcnn_config.get('model_dropout_rate', 0.1)
            )
            self.base_dim = textcnn_config['textcnn_output_dim']
            print(f"ğŸ—ï¸ TextCNN ContrastiveEncoder åˆå§‹åŒ–å®Œæˆ:")
            print(f"   TextCNN è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
            print(f"   TextCNN é…ç½®: {textcnn_config}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}ã€‚è¯·é€‰æ‹© 'modelscope' æˆ– 'textcnn'ã€‚")

        # æŠ•å½±å¤´ (ä¸¤ç§æ¨¡å‹ç±»å‹é€šç”¨)
        self.projection_head = torch.nn.Sequential(
            torch.nn.Linear(self.base_dim, projection_hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Dropout(projection_dropout_rate),
            torch.nn.Linear(projection_hidden_dim, projection_output_dim),
            torch.nn.LayerNorm(projection_output_dim)
        ).float() # ç¡®ä¿æŠ•å½±å¤´æ˜¯ float32
        
        print(f"   åŸºç¡€æ¨¡å‹è¾“å‡ºç»´åº¦ (åˆ°æŠ•å½±å¤´): {self.base_dim}")
        print(f"   æŠ•å½±å¤´è¾“å…¥ç»´åº¦: {self.base_dim}")
        print(f"   æŠ•å½±å¤´éšè—å±‚ç»´åº¦: {projection_hidden_dim}")
        print(f"   æŠ•å½±å¤´è¾“å‡ºç»´åº¦ (æœ€ç»ˆåµŒå…¥): {projection_output_dim}")
        if self.base_model:
             print(f"   åŸºç¡€æ¨¡å‹æ•°æ®ç±»å‹: {next(self.base_model.parameters()).dtype}")
        print(f"   æŠ•å½±å¤´æ•°æ®ç±»å‹: {next(self.projection_head.parameters()).dtype}")

    def _ensure_float32(self, tensor):
        if tensor.dtype in [torch.bfloat16, torch.float16]:
            return tensor.float()
        return tensor

    def _ensure_list_of_strings(self, texts: Union[str, List[any]]) -> List[str]:
        if isinstance(texts, str):
            texts = [texts]
        
        processed_texts = []
        for text_input in texts:
            if not isinstance(text_input, str):
                # å¤„ç† None æˆ–å…¶ä»–ç±»å‹ï¼Œå°†å…¶è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²
                processed_texts.append(str(text_input) if text_input is not None else "")
            else:
                processed_texts.append(text_input if text_input else "") # ç¡®ä¿ç©ºè¾“å…¥ä¹Ÿæ˜¯ç©ºå­—ç¬¦ä¸²
        return processed_texts

    def get_base_embeddings(self, texts: Union[str, List[any]]):
        """
        è·å–åŸºç¡€æ¨¡å‹çš„åµŒå…¥ï¼ˆåœ¨æŠ•å½±å¤´ä¹‹å‰ï¼‰ã€‚
        """
        processed_texts = self._ensure_list_of_strings(texts)
        if not processed_texts:
            return torch.empty(0, self.base_dim, device=next(self.parameters()).device)

        device = next(self.parameters()).device
        
        max_len = 512
        if self.model_type == 'textcnn':
            max_len = self.tokenizer.max_length
        elif hasattr(self.tokenizer, 'model_max_length'):
            max_len = self.tokenizer.model_max_length

        inputs = self.tokenizer(
            processed_texts, 
            padding=True, 
            truncation=True, 
            return_tensors='pt', 
            max_length=max_len
        )
        # ä¿®å¤: å°†å­—å…¸ä¸­çš„æ¯ä¸ªå¼ é‡ç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
        inputs = {key: value.to(device) for key, value in inputs.items()}

        outputs = self.base_model(**inputs)

        if self.model_type == 'modelscope':
            if hasattr(outputs, 'last_hidden_state'):
                last_hidden = self._ensure_float32(outputs.last_hidden_state)
                attention_mask = inputs['attention_mask']
                mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()
                sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)
                sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)
                base_embeddings = sum_embeddings / sum_mask
            elif hasattr(outputs, 'pooler_output'):
                base_embeddings = self._ensure_float32(outputs.pooler_output)
            elif isinstance(outputs, torch.Tensor):
                base_embeddings = self._ensure_float32(outputs)
            else:
                raise ValueError("æ— æ³•ä»ModelScopeæ¨¡å‹è¾“å‡ºç¡®å®šåŸºç¡€åµŒå…¥ã€‚")
        elif self.model_type == 'textcnn':
            base_embeddings = self._ensure_float32(outputs)
        else:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {self.model_type}")

        return base_embeddings

    def forward(self, texts: Union[str, List[any]]):
        """
        å®šä¹‰æ¨¡å‹çš„å®Œæ•´å‰å‘ä¼ æ’­ï¼šåŸºç¡€æ¨¡å‹ -> æŠ•å½±å¤´ã€‚
        """
        base_embeddings = self.get_base_embeddings(texts)
        
        if base_embeddings.nelement() == 0:
            # ä»æŠ•å½±å¤´çš„æœ€åä¸€å±‚è·å–è¾“å‡ºç»´åº¦
            proj_output_dim = self.projection_head[-2].out_features
            return torch.empty(0, proj_output_dim, device=base_embeddings.device, dtype=torch.float)
            
        projected_embeddings = self.projection_head(base_embeddings)
        return projected_embeddings

    def save_base_model(self, path: str):
        """ä¿å­˜åŸºç¡€æ¨¡å‹ (ModelScope æˆ– TextCNN) åŠå…¶åˆ†è¯å™¨/è¯æ±‡è¡¨ã€‚"""
        os.makedirs(path, exist_ok=True)
        if self.model_type == 'modelscope':
            # å¯¹äºModelScopeæ¨¡å‹ï¼Œä¿å­˜æ–¹å¼ä¸HuggingFaceç±»ä¼¼
            self.base_model.save_pretrained(path)
            self.tokenizer.save_pretrained(path)
            print(f"ğŸ’¾ ModelScope åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨å·²ä¿å­˜åˆ°: {path}")
        elif self.model_type == 'textcnn':
            model_save_path = os.path.join(path, "textcnn_model.pth")
            vocab_save_path = os.path.join(path, "textcnn_vocab.json")
            tokenizer_config_path = os.path.join(path, "textcnn_tokenizer_config.json")

            torch.save(self.base_model.state_dict(), model_save_path)
            with open(vocab_save_path, 'w', encoding='utf-8') as f:
                json.dump(self.tokenizer.word_to_idx, f, ensure_ascii=False, indent=4)
            
            tokenizer_config = {'max_length': self.tokenizer.max_length}
            with open(tokenizer_config_path, 'w', encoding='utf-8') as f:
                json.dump(tokenizer_config, f, ensure_ascii=False, indent=4)

            print(f"ğŸ’¾ TextCNN åŸºç¡€æ¨¡å‹ state_dict å·²ä¿å­˜åˆ°: {model_save_path}")
            print(f"ğŸ’¾ TextCNN è¯æ±‡è¡¨å·²ä¿å­˜åˆ°: {vocab_save_path}")
            print(f"ğŸ’¾ TextCNN åˆ†è¯å™¨é…ç½®å·²ä¿å­˜åˆ°: {tokenizer_config_path}")
        else:
            print(f"âš ï¸ æœªçŸ¥æ¨¡å‹ç±»å‹ '{self.model_type}'ï¼Œæ— æ³•ä¿å­˜åŸºç¡€æ¨¡å‹ã€‚")

class ContrastiveDataCollator:
    """
    è‡ªå®šä¹‰çš„DataCollatorï¼Œç”¨äºæ‰¹é‡å¤„ç†å¹¶åŠ¨æ€æ·»åŠ è´Ÿæ ·æœ¬
    """
    def __init__(self, dataset: Union[ContrastiveDataset1, ContrastiveDataset2], num_negatives: int = 2):
        self.dataset = dataset
        self.num_negatives = num_negatives
    
    def _ensure_str_content(self, content, default_str="<unk>"): # Collatorä¸­çš„é»˜è®¤å€¼
        if not isinstance(content, str):
            # print(f"è­¦å‘Š (Collator): å†…å®¹ä¸æ˜¯å­—ç¬¦ä¸² (ç±»å‹: {type(content)}), å°†è½¬æ¢ä¸º '{default_str}'ã€‚å†…å®¹: {str(content)[:30]}...")
            return default_str
        return content if content else default_str # ç©ºå­—ç¬¦ä¸²ä¹Ÿè½¬ä¸ºé»˜è®¤å€¼

    def __call__(self, batch: List[Dict]) -> Dict[str, any]:
        anchor_texts = [self._ensure_str_content(item['anchor_content']) for item in batch]
        
        positive_texts_ds1 = [] 
        positive_content_lists_ds2 = []

        for item in batch:
            pair_type = item.get('pair_type', 'unknown')
            if pair_type == 'parent_child':
                positive_texts_ds1.append(self._ensure_str_content(item['positive_content']))
                positive_content_lists_ds2.append(None)
            elif pair_type == 'node_center':
                positive_texts_ds1.append(None)
                # ç¡®ä¿åˆ—è¡¨ä¸­çš„æ¯ä¸ªå†…å®¹éƒ½æ˜¯å­—ç¬¦ä¸²
                content_list = item.get('positive_content_list', [])
                if isinstance(content_list, list):
                    processed_list = [self._ensure_str_content(c) for c in content_list]
                    positive_content_lists_ds2.append(processed_list if processed_list else [self._ensure_str_content("")]) # ä¿è¯ä¸ä¸ºç©ºåˆ—è¡¨
                else: # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªåŒ…å«å•ä¸ªå…ƒç´ çš„åˆ—è¡¨
                    positive_content_lists_ds2.append([self._ensure_str_content(content_list)])

            else: # é»˜è®¤æˆ–æœªçŸ¥ç±»å‹
                positive_texts_ds1.append(self._ensure_str_content(item.get('positive_content', item['anchor_content'])))
                positive_content_lists_ds2.append(None)
        
        negative_texts = []
        if self.num_negatives > 0:
            for item in batch:
                post_id = item['post_id']
                neg_contents = []
                if hasattr(self.dataset, 'get_negative_samples'):
                    neg_contents = self.dataset.get_negative_samples(post_id, self.num_negatives)
                
                # ç¡®ä¿è´Ÿæ ·æœ¬æ˜¯å­—ç¬¦ä¸²ä¸”æ•°é‡æ­£ç¡®
                processed_neg_contents = []
                for neg_c in neg_contents:
                    processed_neg_contents.append(self._ensure_str_content(neg_c))
                
                while len(processed_neg_contents) < self.num_negatives:
                    # å°è¯•ä»æ‰¹å†…å…¶ä»–å¸–å­è·å–
                    other_items_texts = [self._ensure_str_content(b['anchor_content']) for b in batch if b['post_id'] != post_id and self._ensure_str_content(b['anchor_content'])]
                    if other_items_texts:
                        processed_neg_contents.append(random.choice(other_items_texts))
                    else: # ä¸‡ä¸å¾—å·²ç”¨å ä½ç¬¦
                        processed_neg_contents.append(self._ensure_str_content("")) 
                
                negative_texts.extend(processed_neg_contents[:self.num_negatives])
        
        return {
            'anchor_texts': anchor_texts,
            'positive_texts_ds1': positive_texts_ds1, 
            'positive_content_lists_ds2': positive_content_lists_ds2, 
            'negative_texts': negative_texts, # æ‰å¹³åˆ—è¡¨
            'post_ids': [item['post_id'] for item in batch],
            'pair_types': [item.get('pair_type', 'unknown') for item in batch],
            'num_negatives': self.num_negatives
        }

class ContrastiveLoss(torch.nn.Module):
    """
    å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œæ”¯æŒä¸‰ç§InfoNCEå˜ä½“
    """
    def __init__(self, temperature: float = 0.07, loss_type: str = 'infonce', 
                 infonce_mode: str = 'unidirectional'):
        super().__init__()
        self.temperature = temperature
        self.loss_type = loss_type
        self.infonce_mode = infonce_mode
        self.cosine_sim = torch.nn.CosineSimilarity(dim=-1)
        print(f"ğŸ¯ ContrastiveLossé…ç½®: ç±»å‹={loss_type}, InfoNCEæ¨¡å¼={infonce_mode}, æ¸©åº¦={temperature}")
        
    def forward(self, anchor, positive, negatives=None):
        if anchor.nelement() == 0 or positive.nelement() == 0: # å¤„ç†ç©ºè¾“å…¥
            return torch.tensor(0.0, device=anchor.device if anchor.nelement() > 0 else positive.device, requires_grad=True)

        if self.loss_type == 'infonce':
            if self.infonce_mode == 'unidirectional':
                return self._infonce_loss_unidirectional(anchor, positive, negatives)
            elif self.infonce_mode == 'bidirectional':
                return self._infonce_loss_bidirectional(anchor, positive, negatives)
            elif self.infonce_mode == 'in_batch':
                return self._infonce_loss_in_batch(anchor, positive)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ InfoNCE æ¨¡å¼: {self.infonce_mode}")
        # ... (triplet loss can be added here if needed)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŸå¤±ç±»å‹: {self.loss_type}")
    
    def _infonce_loss_unidirectional(self, anchor, positive, negatives):
        if negatives is None or negatives.nelement() == 0: # æ£€æŸ¥ negatives æ˜¯å¦æœ‰æ•ˆ
            # å¦‚æœæ²¡æœ‰è´Ÿæ ·æœ¬ï¼Œå¯ä»¥è€ƒè™‘é€€åŒ–ä¸ºç®€å•çš„æ­£æ ·æœ¬åŒ¹é…æˆ–è¿”å›0æŸå¤±
            # print("è­¦å‘Š: å•å‘InfoNCEéœ€è¦æœ‰æ•ˆçš„è´Ÿæ ·æœ¬ï¼Œä½†æœªæä¾›æˆ–ä¸ºç©ºã€‚è¿”å›0æŸå¤±ã€‚")
            # è®¡ç®—æ­£æ ·æœ¬ç›¸ä¼¼åº¦ï¼Œä½†ä¸è¿›è¡Œå¯¹æ¯”æŸå¤±
            # pos_sim = self.cosine_sim(anchor, positive) / self.temperature
            # return -pos_sim.mean() # å°è¯•æœ€å¤§åŒ–æ­£æ ·æœ¬ç›¸ä¼¼åº¦ï¼Œä½†è¿™å·²ä¸æ˜¯InfoNCE
            return torch.tensor(0.0, device=anchor.device, requires_grad=True)

        batch_size, num_negatives, _ = negatives.shape
        
        anchor_norm = F.normalize(anchor, dim=-1)
        positive_norm = F.normalize(positive, dim=-1)
        negatives_norm = F.normalize(negatives, dim=-1)
        
        pos_sim = self.cosine_sim(anchor_norm, positive_norm) / self.temperature
        
        anchor_expanded = anchor_norm.unsqueeze(1).expand(-1, num_negatives, -1)
        neg_sim = self.cosine_sim(anchor_expanded, negatives_norm) / self.temperature
        
        all_sim = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1)
        labels = torch.zeros(batch_size, dtype=torch.long, device=anchor.device)
        loss = F.cross_entropy(all_sim, labels)
        return loss
    
    def _infonce_loss_bidirectional(self, anchor, positive, negatives):
        if negatives is None or negatives.nelement() == 0:
            # print("è­¦å‘Š: åŒå‘InfoNCEéœ€è¦æœ‰æ•ˆçš„è´Ÿæ ·æœ¬ï¼Œä½†æœªæä¾›æˆ–ä¸ºç©ºã€‚è¿”å›0æŸå¤±ã€‚")
            return torch.tensor(0.0, device=anchor.device, requires_grad=True)
            
        loss1 = self._compute_single_direction_loss(anchor, positive, negatives)
        loss2 = self._compute_single_direction_loss(positive, anchor, negatives)
        return (loss1 + loss2) / 2.0
    
    def _infonce_loss_in_batch(self, anchor, positive):
        batch_size = anchor.shape[0]
        if batch_size <= 1:
            return torch.tensor(0.0, device=anchor.device, requires_grad=True)
        
        anchor_norm = F.normalize(anchor, dim=-1)
        positive_norm = F.normalize(positive, dim=-1)
        
        # æ­£æ ·æœ¬å¯¹çš„ç›¸ä¼¼åº¦ (anchor_i ä¸ positive_i)
        # å¯¹äºin-batchï¼Œæˆ‘ä»¬é€šå¸¸å‡è®¾ anchor å’Œ positive æ¥è‡ªåŒä¸€ç»„æ•°æ®ï¼Œåªæ˜¯å¢å¼ºä¸åŒ
        # æˆ–è€… anchor[i] çš„æ­£æ ·æœ¬æ˜¯ positive[i]
        # logits åˆ†å­: sim(anchor_i, positive_i)
        # logits åˆ†æ¯: sim(anchor_i, positive_i) + sum_{j!=i} sim(anchor_i, positive_j)
        
        # æ–¹æ³•1: anchor[i] vs positive[j] for all j. Positive is positive[i]
        similarity_matrix_ap = torch.matmul(anchor_norm, positive_norm.t()) / self.temperature # [B, B]
        labels_ap = torch.arange(batch_size, device=anchor.device)
        loss_ap = F.cross_entropy(similarity_matrix_ap, labels_ap)
        
        # æ–¹æ³•2: positive[i] vs anchor[j] for all j. Positive is anchor[i]
        # è¿™ç­‰ä»·äºä¸Šé¢çš„è½¬ç½®ï¼Œä½†ä¸ºäº†æ¦‚å¿µæ¸…æ™°
        similarity_matrix_pa = torch.matmul(positive_norm, anchor_norm.t()) / self.temperature # [B, B]
        labels_pa = torch.arange(batch_size, device=anchor.device)
        loss_pa = F.cross_entropy(similarity_matrix_pa, labels_pa)

        return (loss_ap + loss_pa) / 2.0

    def _compute_single_direction_loss(self, query, positive_key, negative_keys):
        # query: [B, D], positive_key: [B, D], negative_keys: [B, N, D]
        batch_size, num_negatives, _ = negative_keys.shape

        query_norm = F.normalize(query, dim=-1)
        positive_key_norm = F.normalize(positive_key, dim=-1)
        negative_keys_norm = F.normalize(negative_keys, dim=-1)

        pos_sim = self.cosine_sim(query_norm, positive_key_norm) / self.temperature # [B]
        
        query_expanded = query_norm.unsqueeze(1).expand(-1, num_negatives, -1) # [B, N, D]
        neg_sim = self.cosine_sim(query_expanded, negative_keys_norm) / self.temperature # [B, N]
        
        all_sim = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1) # [B, 1+N]
        labels = torch.zeros(batch_size, dtype=torch.long, device=query.device)
        loss = F.cross_entropy(all_sim, labels)
        return loss

class DynamicContrastiveTrainer:
    def __init__(self, post_storage: PostStorage,
                 training_model_type: str = 'modelscope',
                 training_model_identifier_or_path: Optional[str] = "google-bert/bert-base-chinese",
                 textcnn_config: Optional[Dict] = None,
                 projection_head_config: Optional[Dict] = None,
                 use_peft: bool = False,  # <--- æ–°å¢å‚æ•°ï¼šæ˜¯å¦ä½¿ç”¨PEFT
                 peft_config: Optional[Dict] = None, # <--- æ–°å¢å‚æ•°ï¼šPEFTé…ç½®
                 pruning_model_path: str = "google-bert/bert-base-chinese",
                 similarity_threshold: float = 0.5,
                 num_negatives: int = 2,
                 batch_size: int = 32,
                 pruning_inference_batch_size: int = 32,
                 base_lr: float = 1e-6,
                 projection_lr: float = 1e-4,
                 use_weighted_loss: bool = False,
                 loss_weights: Optional[Dict[str, float]] = None,
                 adaptive_weighting: bool = False,
                 infonce_mode: str = 'unidirectional',
                 min_subtree_size_ds1: int = 2,
                 max_samples_per_post_ds1: Optional[int] = None,
                 min_subtree_size_ds2: int = 4,
                 max_samples_per_subtree_ds2: Optional[int] = None):

        self.post_storage = post_storage
        self.training_model_type = training_model_type.lower()
        self.training_model_identifier_or_path = training_model_identifier_or_path
        self.textcnn_config = textcnn_config
        self.use_peft = use_peft
        self.peft_config = peft_config
        self.pruning_model_path = pruning_model_path
        self.similarity_threshold = similarity_threshold
        self.num_negatives = num_negatives if infonce_mode != 'in_batch' else 0
        self.batch_size = batch_size
        self.pruning_inference_batch_size = pruning_inference_batch_size
        self.infonce_mode = infonce_mode

        self.min_subtree_size_ds1 = min_subtree_size_ds1
        self.max_samples_per_post_ds1 = max_samples_per_post_ds1
        self.min_subtree_size_ds2 = min_subtree_size_ds2
        self.max_samples_per_subtree_ds2 = max_samples_per_subtree_ds2

        self.use_weighted_loss = use_weighted_loss
        if self.use_weighted_loss:
            if loss_weights is None: self.loss_weights = {'dataset1': 0.5, 'dataset2': 0.5}
            else: self.loss_weights = loss_weights.copy()
            weight_sum = sum(self.loss_weights.values())
            if weight_sum > 0:
                for k_lw in self.loss_weights: self.loss_weights[k_lw] /= weight_sum
            else:
                self.loss_weights = {'dataset1': 0.5, 'dataset2': 0.5}
            self.adaptive_weighting = adaptive_weighting
            self.initial_loss_weights = self.loss_weights.copy()
            print(f"ğŸ¯ å¯ç”¨æŸå¤±åŠ æƒ: {self.loss_weights}, è‡ªé€‚åº”: {self.adaptive_weighting}")
        else:
            self.loss_weights = {'dataset1': 1.0, 'dataset2': 1.0}
            self.adaptive_weighting = False
            print("ğŸ“Š ä½¿ç”¨ç‹¬ç«‹æŸå¤±ï¼ˆæ¯ä¸ªæ•°æ®é›†çš„æŸå¤±ä¹˜ä»¥å…¶æƒé‡ï¼Œé»˜è®¤ä¸º1.0ï¼‰")

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        _default_proj_config = {'hidden_dim': 512, 'output_dim': 256, 'dropout_rate': 0.1}
        self.projection_config = {**_default_proj_config, **(projection_head_config if projection_head_config is not None else {})}


        self.vocab = None
        if self.training_model_type == 'textcnn':
            print("ğŸ› ï¸ ä½¿ç”¨ TextCNN æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚")
            if self.textcnn_config is None:
                raise ValueError("å½“ training_model_type ä¸º 'textcnn' æ—¶ï¼Œtextcnn_config æ˜¯å¿…éœ€çš„")
            print("ğŸ—ï¸ ä» PostStorage ä¸º TextCNN æ„å»ºè¯æ±‡è¡¨...")
            self.vocab, _ = build_vocab_from_post_storage(self.post_storage, min_freq=self.textcnn_config.get('min_vocab_freq', 1))
            self.contrastive_encoder = ContrastiveEncoder(
                model_type='textcnn',
                vocab=self.vocab,
                textcnn_config=self.textcnn_config,
                projection_hidden_dim=self.projection_config['hidden_dim'],
                projection_output_dim=self.projection_config['output_dim'],
                projection_dropout_rate=self.projection_config['dropout_rate']
            ).to(self.device)
            print(f"   TextCNN æ¨¡å‹åç§° (æ ‡è¯†ç¬¦): {self.training_model_identifier_or_path}")
        elif self.training_model_type == 'modelscope':
            print(f"ğŸ› ï¸ ä½¿ç”¨ ModelScope æ¨¡å‹è¿›è¡Œè®­ç»ƒ: {self.training_model_identifier_or_path}")
            if self.training_model_identifier_or_path is None:
                 raise ValueError("å¯¹äº 'modelscope' æ¨¡å‹ç±»å‹ï¼Œtraining_model_identifier_or_path æ˜¯å¿…éœ€çš„ã€‚")
            self.contrastive_encoder = ContrastiveEncoder(
                model_type='modelscope',
                model_name_or_path=self.training_model_identifier_or_path,
                projection_hidden_dim=self.projection_config['hidden_dim'],
                projection_output_dim=self.projection_config['output_dim'],
                projection_dropout_rate=self.projection_config['dropout_rate']
            ).to(self.device)
             # --- æ–°å¢ï¼šåº”ç”¨PEFT/LoRAçš„é€»è¾‘ ---
            if self.use_peft:
                print("ğŸš€ åº”ç”¨PEFT (LoRA)åˆ°åŸºç¡€æ¨¡å‹...")
                
                # å®šä¹‰é»˜è®¤LoRAé…ç½®ï¼Œå¹¶ä¸ç”¨æˆ·ä¼ å…¥çš„é…ç½®åˆå¹¶
                default_lora_config = {
                    'r': 16,
                    'lora_alpha': 32,
                    'target_modules': ["query", "key", "value"],
                    'lora_dropout': 0.05,
                    'bias': "none",
                }
                final_lora_config_dict = {**default_lora_config, **(self.peft_config or {})}
                
                lora_config = LoraConfig(**final_lora_config_dict)
                
                # å°†åŸºç¡€æ¨¡å‹åŒ…è£…æˆPeftModel
                self.contrastive_encoder.base_model = get_peft_model(self.contrastive_encoder.base_model, lora_config)
                
                print("âœ… LoRAåº”ç”¨å®Œæˆã€‚å¯è®­ç»ƒå‚æ•°è¯¦æƒ…:")
                self.contrastive_encoder.base_model.print_trainable_parameters()
            # --- PEFTé€»è¾‘ç»“æŸ ---
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒæ¨¡å‹ç±»å‹: {self.training_model_type}ã€‚è¯·é€‰æ‹© 'modelscope' æˆ– 'textcnn'ã€‚")

        print(f"ğŸ” åˆå§‹åŒ–å‰ªææ¨¡å‹: {self.pruning_model_path}")
        # ä½¿ç”¨ä¸ºModelScopeå®šä¹‰çš„è¾…åŠ©å‡½æ•°åŠ è½½å‰ªææ¨¡å‹
        self.pruning_tokenizer = load_tokenizer_from_modelscope(self.pruning_model_path)
        self.pruning_model = load_model_from_modelscope(
            self.pruning_model_path,
            torch_dtype=torch.float32
        )
        self.pruning_model_on_gpu = False

        self.optimizer = torch.optim.AdamW([
            {'params': self.contrastive_encoder.base_model.parameters(), 'lr': base_lr, 'weight_decay': 1e-6, 'initial_lr': base_lr},
            {'params': self.contrastive_encoder.projection_head.parameters(), 'lr': projection_lr, 'weight_decay': 1e-4, 'initial_lr': projection_lr}
        ])

        self.loss_fn1 = ContrastiveLoss(temperature=0.07, loss_type='infonce', infonce_mode=infonce_mode)
        self.loss_fn2 = ContrastiveLoss(temperature=0.05, loss_type='infonce', infonce_mode=infonce_mode)

        self.training_history = defaultdict(list)
        self.training_history['dataset_sizes'] = {'dataset1': [], 'dataset2': []}
        if self.use_weighted_loss:
            self.training_history['weight_ds1'] = []
            self.training_history['weight_ds2'] = []
        print(f"ğŸš€ DynamicContrastiveTrainer åˆå§‹åŒ–å®Œæˆã€‚è®¾å¤‡: {self.device}")

    def _load_pruning_model_to_gpu(self):
        if not self.pruning_model_on_gpu and self.device.type == 'cuda':
            print("ğŸ”§ å°†å‰ªææ¨¡å‹åŠ è½½åˆ°GPU...")
            self.pruning_model.to(self.device)
            self.pruning_model_on_gpu = True

    def _unload_pruning_model_from_gpu(self):
        if self.pruning_model_on_gpu and self.device.type == 'cuda':
            print("ğŸ”§ ä»GPUå¸è½½å‰ªææ¨¡å‹...")
            self.pruning_model.to('cpu')
            self.pruning_model_on_gpu = False
            torch.cuda.empty_cache()

    def _get_pruning_embeddings(self, texts: List[str]) -> np.ndarray:
        if not texts:
            return np.array([])
        # self._load_pruning_model_to_gpu() # ç”±è°ƒç”¨è€…ç®¡ç†GPUåŠ è½½/å¸è½½
        texts = [str(t) if not isinstance(t, str) else t for t in texts]
        texts = [t if t else "<empty_text_placeholder>" for t in texts] # æ›¿æ¢ç©ºå­—ç¬¦ä¸²

        all_embeddings_list = []
        self.pruning_model.eval()
        with torch.no_grad():
            # ä½¿ç”¨tqdmåŒ…è£¹æ‰¹å¤„ç†å¾ªç¯
            for i in tqdm(range(0, len(texts), self.pruning_inference_batch_size), desc="è®¡ç®—å‰ªæåµŒå…¥", unit="batch"):
                batch_texts = texts[i:i + self.pruning_inference_batch_size]
                if not batch_texts: continue
                try:
                    inputs = self.pruning_tokenizer(
                        batch_texts, padding=True, truncation=True, return_tensors='pt', max_length=512
                    ).to(self.pruning_model.device)
                    outputs = self.pruning_model(**inputs)
                    batch_embeddings = outputs.last_hidden_state.mean(dim=1)
                    if batch_embeddings.dtype in [torch.bfloat16, torch.float16]:
                        batch_embeddings = batch_embeddings.float()
                    all_embeddings_list.append(batch_embeddings.cpu())
                except Exception as e:
                    print(f"è·å–å‰ªæåµŒå…¥æ—¶æ‰¹å¤„ç†é”™è¯¯: {e}. è·³è¿‡æ­¤æ‰¹æ¬¡ã€‚æ‰¹æ¬¡æ–‡æœ¬ç¤ºä¾‹: {batch_texts[0][:50] if batch_texts else 'N/A'}")
                    # æ ¹æ®éœ€è¦ï¼Œå¯ä»¥ä¸ºå¤±è´¥çš„æ‰¹æ¬¡æ·»åŠ å ä½ç¬¦åµŒå…¥ï¼Œæˆ–è€…ç®€å•åœ°è·³è¿‡
                    # ä¾‹å¦‚ï¼Œæ·»åŠ é›¶åµŒå…¥ï¼š
                    # output_dim = self.pruning_model.config.hidden_size # å‡è®¾HFæ¨¡å‹
                    # all_embeddings_list.append(torch.zeros((len(batch_texts), output_dim), dtype=torch.float32).cpu())


        if not all_embeddings_list: return np.array([])
        try:
            all_embeddings_np = torch.cat(all_embeddings_list, dim=0).numpy()
        except RuntimeError as e:
            print(f"è¿æ¥å‰ªæåµŒå…¥æ—¶å‡ºé”™: {e}")
            # å°è¯•æ‰¾å‡ºå“ªä¸ªåµŒå…¥å¯¼è‡´é—®é¢˜
            # for i, emb_tensor in enumerate(all_embeddings_list):
            # print(f"Tensor {i} shape: {emb_tensor.shape}, dtype: {emb_tensor.dtype}")
            return np.array([]) # è¿”å›ç©ºæ•°ç»„ä»¥é¿å…è¿›ä¸€æ­¥é”™è¯¯
        return all_embeddings_np

    def _build_and_log_datasets(self):
        print("ğŸ› ï¸ æ„å»º/é‡å»ºæ•°æ®é›†...")
        print("   æ”¶é›†æ‰€æœ‰è¯„è®ºç”¨äºå‰ªææ¨¡å‹åµŒå…¥...")
        all_comment_texts = []
        comment_nodes_references = []

        for post_id, post_container in self.post_storage.posts.items():
            # Path A: å°è¯•ä» 'comments' å­—å…¸è·å– (å¦‚æœå­˜åœ¨ä¸”è¢«å¡«å……)
            if hasattr(post_container, 'comments') and isinstance(post_container.comments, dict) and post_container.comments:
                # print(f"DEBUG: Post {post_id} - ä½¿ç”¨ 'comments' å­—å…¸è·¯å¾„æ‰¾åˆ° {len(post_container.comments)} æ¡è¯„è®ºã€‚")
                for comment_id, comment_node in post_container.comments.items():
                    content_str = str(comment_node.content) if comment_node.content is not None else ""
                    all_comment_texts.append(content_str)
                    comment_nodes_references.append(comment_node)
            # Path B: å°è¯•ä» 'root' å±æ€§éå† (ä¸ build_vocab_from_post_storage ä¸€è‡´)
            elif hasattr(post_container, 'root') and post_container.root:
                # print(f"DEBUG: Post {post_id} - ä½¿ç”¨ 'root' å±æ€§è·¯å¾„ã€‚")
                queue = [post_container.root] # ä½¿ç”¨ root
                visited_ids_in_post = set()
                while queue:
                    comment_node = queue.pop(0)
                    if comment_node.comment_id in visited_ids_in_post:
                        continue
                    visited_ids_in_post.add(comment_node.comment_id)
                    
                    content_str = str(comment_node.content) if comment_node.content is not None else ""
                    all_comment_texts.append(content_str)
                    comment_nodes_references.append(comment_node)
                    
                    if hasattr(comment_node, 'children') and comment_node.children: # ä½¿ç”¨ children
                        for child_node in comment_node.children: # ä½¿ç”¨ children
                            if child_node:
                                queue.append(child_node)
            # else:
                # print(f"DEBUG: Post {post_id} - æœªæ‰¾åˆ° 'comments' å­—å…¸æˆ– 'root' å±æ€§ã€‚")

        if all_comment_texts:
            # --- æ–°å¢ï¼šåœ¨è®¡ç®—å‰ªæåµŒå…¥å‰ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç† ---
            print(f"   å¯¹ {len(all_comment_texts)} æ¡è¯„è®ºè¿›è¡Œé¢„å¤„ç†ä»¥ç”¨äºå‰ªæ...")
            preprocessed_texts_for_pruning = [preprocess_text(text) for text in all_comment_texts]

            print(f"   è®¡ç®— {len(preprocessed_texts_for_pruning)} æ¡é¢„å¤„ç†åè¯„è®ºçš„å‰ªæåµŒå…¥...")
            self._load_pruning_model_to_gpu()
            pruning_embeddings_np = self._get_pruning_embeddings(preprocessed_texts_for_pruning)
            self._unload_pruning_model_from_gpu()

            if pruning_embeddings_np.ndim == 2 and pruning_embeddings_np.shape[0] == len(comment_nodes_references):
                for i, comment_node in enumerate(comment_nodes_references):
                    if hasattr(comment_node, 'set_embedding'):
                        comment_node.set_embedding(pruning_embeddings_np[i])
                    else: # åå¤‡æ–¹æ¡ˆ
                        comment_node.embedding = pruning_embeddings_np[i]
                print("   å‰ªæåµŒå…¥å·²ä¸ºPostStorageä¸­çš„æ‰€æœ‰è¯„è®ºè®¾ç½®ã€‚")
            else:
                print(f"   è­¦å‘Š: _get_pruning_embeddings çš„å½¢çŠ¶ä¸åŒ¹é…æˆ–ç»“æœä¸ºç©ºã€‚é¢„æœŸ ({len(comment_nodes_references)}, dim)ï¼Œå¾—åˆ° {pruning_embeddings_np.shape if isinstance(pruning_embeddings_np, np.ndarray) else 'Not an ndarray'}ã€‚è·³è¿‡å‰ªæåµŒå…¥æ›´æ–°ã€‚")
        else:
            print("   åœ¨PostStorageä¸­æœªæ‰¾åˆ°è¯„è®ºè¿›è¡Œå‰ªæåµŒå…¥ã€‚")

        build_pruned_forest(self.post_storage, self.similarity_threshold)

        print("   åˆ›å»º Dataset1...")
        self.dataset1 = ContrastiveDataset1(
            post_storage=self.post_storage,
            similarity_threshold=self.similarity_threshold,
            min_subtree_size=self.min_subtree_size_ds1,
            max_samples_per_post=self.max_samples_per_post_ds1
        )
        print("   åˆ›å»º Dataset2...")
        self.dataset2 = ContrastiveDataset2(
            post_storage=self.post_storage,
            min_subtree_size=self.min_subtree_size_ds2,
            max_samples_per_subtree=self.max_samples_per_subtree_ds2
        )

        ds1_size = len(self.dataset1)
        ds2_size = len(self.dataset2)
        self.training_history['dataset_sizes']['dataset1'].append(ds1_size)
        self.training_history['dataset_sizes']['dataset2'].append(ds2_size)
        print(f"   Dataset1 å¤§å°: {ds1_size}, Dataset2 å¤§å°: {ds2_size}")

        if ds1_size == 0 and ds2_size == 0:
            print("âš ï¸ è­¦å‘Š: ä¸¤ä¸ªæ•°æ®é›†éƒ½ä¸ºç©ºã€‚è®­ç»ƒå¯èƒ½æ— æ³•æœ‰æ•ˆè¿›è¡Œã€‚")

        collator_num_neg = self.num_negatives
        self.collator1 = ContrastiveDataCollator(self.dataset1, num_negatives=collator_num_neg)
        self.collator2 = ContrastiveDataCollator(self.dataset2, num_negatives=collator_num_neg)

        self.train_loader1 = DataLoader(self.dataset1, batch_size=self.batch_size, shuffle=True, collate_fn=self.collator1, num_workers=0, pin_memory=True if self.device.type == 'cuda' else False) if ds1_size > 0 else None
        self.train_loader2 = DataLoader(self.dataset2, batch_size=self.batch_size, shuffle=True, collate_fn=self.collator2, num_workers=0, pin_memory=True if self.device.type == 'cuda' else False) if ds2_size > 0 else None
        print("âœ… æ•°æ®é›†å’Œ DataLoader å·²å‡†å¤‡å°±ç»ªã€‚")

        # --- æ–°å¢ä»£ç ï¼šä¿å­˜æ„å»ºå¥½çš„æ•°æ®é›† ---
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜æ„å»ºå¥½çš„æ•°æ®é›†...")
        save_dir = "cl_dataset"
        os.makedirs(save_dir, exist_ok=True)

        # åˆ›å»ºåŠ¨æ€æ–‡ä»¶å
        sanitized_model_name = self.training_model_identifier_or_path.replace('/', '_')
        similarity_str = str(self.similarity_threshold)
        base_filename = f"{sanitized_model_name}_sim_{similarity_str}"

        # ä¿å­˜ Dataset1
        if ds1_size > 0:
            ds1_filepath = os.path.join(save_dir, f"{base_filename}_dataset1.pkl")
            try:
                with open(ds1_filepath, 'wb') as f:
                    pickle.dump(self.dataset1, f)
                print(f"   -> Dataset1 å·²ä¿å­˜è‡³: {ds1_filepath}")
            except Exception as e:
                print(f"   -> âŒ ä¿å­˜ Dataset1 å¤±è´¥: {e}")
        else:
            print("   -> Dataset1 ä¸ºç©ºï¼Œä¸è¿›è¡Œä¿å­˜ã€‚")

        # ä¿å­˜ Dataset2
        if ds2_size > 0:
            ds2_filepath = os.path.join(save_dir, f"{base_filename}_dataset2.pkl")
            try:
                with open(ds2_filepath, 'wb') as f:
                    pickle.dump(self.dataset2, f)
                print(f"   -> Dataset2 å·²ä¿å­˜è‡³: {ds2_filepath}")
            except Exception as e:
                print(f"   -> âŒ ä¿å­˜ Dataset2 å¤±è´¥: {e}")
        else:
            print("   -> Dataset2 ä¸ºç©ºï¼Œä¸è¿›è¡Œä¿å­˜ã€‚")

    def _process_batch(self, batch: Dict, loss_fn: ContrastiveLoss, dataset_name: str) -> Optional[torch.Tensor]:
        self.optimizer.zero_grad()

        anchor_texts = batch['anchor_texts']
        positive_texts_ds1 = batch.get('positive_texts_ds1', [])
        positive_content_lists_ds2 = batch.get('positive_content_lists_ds2', [])
        negative_texts_flat = batch.get('negative_texts', []) # æ‰å¹³åˆ—è¡¨
        num_negatives_per_anchor = batch.get('num_negatives', 0)

        if not anchor_texts: return None
        loss = None
        processed_anchors_count = 0 # å½“å‰æ‰¹æ¬¡ä¸­å®é™…å¤„ç†çš„é”šç‚¹æ•°é‡

        if dataset_name == 'dataset1':
            valid_indices = [i for i, txt in enumerate(positive_texts_ds1) if txt is not None]
            if not valid_indices: return None

            current_anchor_texts = [anchor_texts[i] for i in valid_indices]
            current_positive_texts = [positive_texts_ds1[i] for i in valid_indices]
            processed_anchors_count = len(current_anchor_texts)
            if processed_anchors_count == 0: return None


            anchor_emb = self.contrastive_encoder(current_anchor_texts)
            positive_emb = self.contrastive_encoder(current_positive_texts)

            neg_emb_reshaped = None
            if self.infonce_mode != 'in_batch' and num_negatives_per_anchor > 0 and negative_texts_flat:
                # ä»æ‰å¹³åˆ—è¡¨ä¸­æå–ä¸ valid_indices å¯¹åº”çš„è´Ÿæ ·æœ¬
                current_negative_texts_for_batch = []
                for original_batch_idx in valid_indices:
                    start_idx_flat = original_batch_idx * num_negatives_per_anchor
                    end_idx_flat = start_idx_flat + num_negatives_per_anchor
                    current_negative_texts_for_batch.extend(negative_texts_flat[start_idx_flat:end_idx_flat])

                if current_negative_texts_for_batch:
                    neg_emb_flat = self.contrastive_encoder(current_negative_texts_for_batch)
                    if neg_emb_flat.nelement() > 0:
                        try:
                            neg_emb_reshaped = neg_emb_flat.view(processed_anchors_count, num_negatives_per_anchor, -1)
                        except RuntimeError as e:
                            print(f"DS1 Reshape error: {e}. Anchors: {processed_anchors_count}, Neg per anchor: {num_negatives_per_anchor}, Flat neg shape: {neg_emb_flat.shape}")
                            return None # or handle differently

            if anchor_emb.nelement() > 0 and positive_emb.nelement() > 0:
                loss = loss_fn(anchor_emb, positive_emb, neg_emb_reshaped if neg_emb_reshaped is not None and neg_emb_reshaped.nelement() > 0 else None)

        elif dataset_name == 'dataset2':
            valid_indices = [i for i, lst in enumerate(positive_content_lists_ds2) if lst is not None and any(s and s.strip() for s in lst)]
            if not valid_indices: return None

            current_anchor_texts = [anchor_texts[i] for i in valid_indices]
            current_positive_lists = [positive_content_lists_ds2[i] for i in valid_indices]
            processed_anchors_count = len(current_anchor_texts)
            if processed_anchors_count == 0: return None

            anchor_emb = self.contrastive_encoder(current_anchor_texts)
            positive_emb_list_for_ds2 = []
            for text_list_for_one_anchor in current_positive_lists:
                valid_texts_in_list = [s for s in text_list_for_one_anchor if s and s.strip()]
                if valid_texts_in_list:
                    # è·å–åŸºç¡€åµŒå…¥ï¼Œç„¶åå¹³å‡ï¼Œç„¶åæŠ•å½±
                    node_base_embeddings = self.contrastive_encoder.get_base_embeddings(valid_texts_in_list)
                    if node_base_embeddings.nelement() > 0:
                        avg_node_base_embedding = node_base_embeddings.mean(dim=0, keepdim=True)
                        projected_avg_emb = self.contrastive_encoder.projection_head(avg_node_base_embedding)
                        positive_emb_list_for_ds2.append(projected_avg_emb)
                    else: # å¦‚æœåˆ—è¡¨ä¸­çš„æ‰€æœ‰æ–‡æœ¬éƒ½æ— æ•ˆ/ç©ºï¼Œåˆ™æ·»åŠ é›¶åµŒå…¥
                        proj_output_dim = self.contrastive_encoder.projection_head[-2].out_features
                        positive_emb_list_for_ds2.append(torch.zeros((1, proj_output_dim), device=self.device, dtype=anchor_emb.dtype))
                else: # å¦‚æœæ•´ä¸ªåˆ—è¡¨ä¸ºç©ºæˆ–ä»…åŒ…å«æ— æ•ˆå­—ç¬¦ä¸²
                    proj_output_dim = self.contrastive_encoder.projection_head[-2].out_features
                    positive_emb_list_for_ds2.append(torch.zeros((1, proj_output_dim), device=self.device, dtype=anchor_emb.dtype))

            if not positive_emb_list_for_ds2 or len(positive_emb_list_for_ds2) != processed_anchors_count:
                 print(f"DS2: positive_emb_list é•¿åº¦ ({len(positive_emb_list_for_ds2)}) ä¸é”šç‚¹æ•°é‡ ({processed_anchors_count}) ä¸åŒ¹é…ã€‚")
                 return None
            positive_emb = torch.cat(positive_emb_list_for_ds2, dim=0)

            neg_emb_reshaped = None
            if self.infonce_mode != 'in_batch' and num_negatives_per_anchor > 0 and negative_texts_flat:
                current_negative_texts_for_batch = []
                for original_batch_idx in valid_indices:
                    start_idx_flat = original_batch_idx * num_negatives_per_anchor
                    end_idx_flat = start_idx_flat + num_negatives_per_anchor
                    current_negative_texts_for_batch.extend(negative_texts_flat[start_idx_flat:end_idx_flat])

                if current_negative_texts_for_batch:
                    neg_emb_flat = self.contrastive_encoder(current_negative_texts_for_batch)
                    if neg_emb_flat.nelement() > 0:
                        try:
                            neg_emb_reshaped = neg_emb_flat.view(processed_anchors_count, num_negatives_per_anchor, -1)
                        except RuntimeError as e:
                            print(f"DS2 Reshape error: {e}. Anchors: {processed_anchors_count}, Neg per anchor: {num_negatives_per_anchor}, Flat neg shape: {neg_emb_flat.shape}")
                            return None


            if anchor_emb.nelement() > 0 and positive_emb.nelement() > 0:
                loss = loss_fn(anchor_emb, positive_emb, neg_emb_reshaped if neg_emb_reshaped is not None and neg_emb_reshaped.nelement() > 0 else None)

        if loss is not None and loss.requires_grad:
            effective_weight = self.loss_weights.get(dataset_name, 1.0) if self.use_weighted_loss else 1.0
            (loss * effective_weight).backward()
            torch.nn.utils.clip_grad_norm_(self.contrastive_encoder.parameters(), max_norm=1.0)
            self.optimizer.step()
            return loss # è¿”å›æœªç¼©æ”¾çš„æŸå¤±ç”¨äºè®°å½•
        return None

    def train(self, num_epochs: int, rebuild_frequency: int, scheduler_patience: int, min_improvement: float):
        self.contrastive_encoder.train()
        best_overall_loss = float('inf')
        patience_counter = 0

        # ç¡®ä¿ä¼˜åŒ–å™¨ä¸­çš„ initial_lr å·²è®¾ç½®
        for grp in self.optimizer.param_groups:
            if 'initial_lr' not in grp:
                grp['initial_lr'] = grp['lr']


        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5,
            patience=scheduler_patience, threshold=min_improvement
        )
        self._build_and_log_datasets() # åˆå§‹æ•°æ®é›†æ„å»º

        for epoch in range(num_epochs):
            print(f"\n--- Epoch {epoch+1}/{num_epochs} ---")
            if epoch > 0 and rebuild_frequency > 0 and epoch % rebuild_frequency == 0:
                print(f"Epoch {epoch+1}: é‡å»ºæ•°æ®é›†...")
                self._build_and_log_datasets()

            self.contrastive_encoder.to(self.device) # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            self.contrastive_encoder.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼

            epoch_losses_ds1 = []
            epoch_losses_ds2 = []

            # Dataset 1 è®­ç»ƒå¾ªç¯
            if self.train_loader1 and len(self.train_loader1) > 0:
                print(f"åœ¨ Dataset1 ä¸Šè®­ç»ƒ (å¤§å°: {len(self.dataset1)} æ ·æœ¬, {len(self.train_loader1)} æ‰¹æ¬¡)")
                progress_bar_ds1 = tqdm(self.train_loader1, desc=f"Epoch {epoch+1} DS1", leave=False, dynamic_ncols=True)
                for batch1 in progress_bar_ds1:
                    loss1_val = self._process_batch(batch1, self.loss_fn1, 'dataset1')
                    if loss1_val is not None:
                        epoch_losses_ds1.append(loss1_val.item())
                        progress_bar_ds1.set_postfix(loss=f"{loss1_val.item():.4f}")
            else:
                print("Dataset1 ä¸ºç©ºæˆ–æœªåŠ è½½ï¼Œè·³è¿‡è®­ç»ƒã€‚")


            # Dataset 2 è®­ç»ƒå¾ªç¯
            if self.train_loader2 and len(self.train_loader2) > 0:
                print(f"åœ¨ Dataset2 ä¸Šè®­ç»ƒ (å¤§å°: {len(self.dataset2)} æ ·æœ¬, {len(self.train_loader2)} æ‰¹æ¬¡)")
                progress_bar_ds2 = tqdm(self.train_loader2, desc=f"Epoch {epoch+1} DS2", leave=False, dynamic_ncols=True)
                for batch2 in progress_bar_ds2:
                    loss2_val = self._process_batch(batch2, self.loss_fn2, 'dataset2')
                    if loss2_val is not None:
                        epoch_losses_ds2.append(loss2_val.item())
                        progress_bar_ds2.set_postfix(loss=f"{loss2_val.item():.4f}")
            else:
                print("Dataset2 ä¸ºç©ºæˆ–æœªåŠ è½½ï¼Œè·³è¿‡è®­ç»ƒã€‚")


            avg_loss_ds1 = np.mean(epoch_losses_ds1) if epoch_losses_ds1 else 0.0
            avg_loss_ds2 = np.mean(epoch_losses_ds2) if epoch_losses_ds2 else 0.0
            current_epoch_combined_loss = 0.0
            w1, w2 = 0.0, 0.0 # åˆå§‹åŒ–æƒé‡

            if self.use_weighted_loss:
                w1_config = self.loss_weights.get('dataset1', 0.5)
                w2_config = self.loss_weights.get('dataset2', 0.5)

                active_datasets = 0
                if epoch_losses_ds1: active_datasets +=1
                if epoch_losses_ds2: active_datasets +=1

                if active_datasets == 0:
                    current_epoch_combined_loss = 0.0
                    w1, w2 = 0.0, 0.0
                elif active_datasets == 1:
                    if epoch_losses_ds1:
                        current_epoch_combined_loss = avg_loss_ds1
                        w1, w2 = 1.0, 0.0
                    else: # epoch_losses_ds2 must be active
                        current_epoch_combined_loss = avg_loss_ds2
                        w1, w2 = 0.0, 1.0
                else: # Both active
                    # Normalize configured weights
                    sum_config_w = w1_config + w2_config
                    if sum_config_w > 0:
                        w1 = w1_config / sum_config_w
                        w2 = w2_config / sum_config_w
                    else:
                        w1, w2 = 0.5, 0.5
                    current_epoch_combined_loss = (w1 * avg_loss_ds1) + (w2 * avg_loss_ds2)
            else: # ä¸ä½¿ç”¨åŠ æƒæŸå¤±ï¼Œç®€å•å¹³å‡æˆ–å–å•ä¸ª
                if epoch_losses_ds1 and epoch_losses_ds2:
                    current_epoch_combined_loss = (avg_loss_ds1 + avg_loss_ds2) / 2.0
                elif epoch_losses_ds1:
                    current_epoch_combined_loss = avg_loss_ds1
                elif epoch_losses_ds2:
                    current_epoch_combined_loss = avg_loss_ds2
                else:
                    current_epoch_combined_loss = 0.0 # ä¸¤ä¸ªæ•°æ®é›†éƒ½æ²¡æœ‰æŸå¤±

            print(f"Epoch {epoch+1} æ€»ç»“: å¹³å‡ DS1 æŸå¤±: {avg_loss_ds1:.4f}, å¹³å‡ DS2 æŸå¤±: {avg_loss_ds2:.4f}, ç»„åˆæŸå¤± (ç”¨äºè°ƒåº¦å™¨): {current_epoch_combined_loss:.4f}")

            self.training_history['epoch'].append(epoch + 1)
            self.training_history['loss_ds1'].append(avg_loss_ds1)
            self.training_history['loss_ds2'].append(avg_loss_ds2)
            self.training_history['combined_loss'].append(current_epoch_combined_loss)
            if self.use_weighted_loss:
                self.training_history['weight_ds1'].append(w1)
                self.training_history['weight_ds2'].append(w2)

            if self.adaptive_weighting and epoch_losses_ds1 and epoch_losses_ds2 and self.use_weighted_loss:
                # ç®€å•çš„åŸºäºæŸå¤±çš„è‡ªé€‚åº”æƒé‡è°ƒæ•´ (æ›´é«˜çº§çš„æ–¹æ³•å­˜åœ¨)
                # æŸå¤±è¶Šå¤§ï¼Œæƒé‡åº”è¯¥è¶Šå¤§ (å‡è®¾ä»»åŠ¡æ˜¯æœ€å°åŒ–æŸå¤±)
                # æˆ–è€…ï¼Œå¦‚æœä»»åŠ¡æ˜¯æœ€å¤§åŒ–æŸä¸ªæŒ‡æ ‡ï¼Œåˆ™æŒ‡æ ‡è¶Šå°ï¼Œæƒé‡è¶Šå¤§
                # è¿™é‡Œæˆ‘ä»¬æœ€å°åŒ–æŸå¤±ï¼Œæ‰€ä»¥æŸå¤±å¤§çš„æ•°æ®é›†åº”è¯¥è·å¾—æ›´å¤šå…³æ³¨ï¼ˆå³æ›´é«˜çš„æƒé‡ï¼‰
                loss_sum_for_weighting = avg_loss_ds1 + avg_loss_ds2
                if loss_sum_for_weighting > 1e-9: # é¿å…é™¤ä»¥é›¶
                    # æƒé‡ä¸æŸå¤±æˆæ­£æ¯”
                    raw_w1_adaptive = avg_loss_ds1 / loss_sum_for_weighting if avg_loss_ds1 > 0 else 0
                    raw_w2_adaptive = avg_loss_ds2 / loss_sum_for_weighting if avg_loss_ds2 > 0 else 0

                    # å¹³æ»‘æ›´æ–°ï¼Œalpha_smooth å†³å®šæ–°è®¡ç®—çš„æƒé‡å å¤šå¤§æ¯”é‡
                    alpha_smooth = 0.3 # 0 è¡¨ç¤ºå®Œå…¨ä½¿ç”¨åˆå§‹æƒé‡, 1 è¡¨ç¤ºå®Œå…¨ä½¿ç”¨å½“å‰è®¡ç®—çš„æƒé‡
                    self.loss_weights['dataset1'] = (1 - alpha_smooth) * self.initial_loss_weights['dataset1'] + alpha_smooth * raw_w1_adaptive

                    self.loss_weights['dataset2'] = (1 - alpha_smooth) * self.initial_loss_weights['dataset2'] + alpha_smooth * raw_w2_adaptive

                    # é‡æ–°å½’ä¸€åŒ–
                    current_sum_adapted_weights = self.loss_weights['dataset1'] + self.loss_weights['dataset2']
                    if current_sum_adapted_weights > 0:
                        self.loss_weights['dataset1'] /= current_sum_adapted_weights
                        self.loss_weights['dataset2'] /= current_sum_adapted_weights
                    else: # å¦‚æœä¸¤ä¸ªæƒé‡éƒ½å˜ä¸ºé›¶ï¼Œåˆ™å›é€€
                        self.loss_weights['dataset1'], self.loss_weights['dataset2'] = self.initial_loss_weights['dataset1'], self.initial_loss_weights['dataset2']
                    print(f"è‡ªé€‚åº”æƒé‡æ›´æ–°: DS1={self.loss_weights['dataset1']:.3f}, DS2={self.loss_weights['dataset2']:.3f}")


            scheduler.step(current_epoch_combined_loss)
            current_lr_base = self.optimizer.param_groups[0]['lr']
            current_lr_proj = self.optimizer.param_groups[1]['lr']
            self.training_history['learning_rate_base'].append(current_lr_base)
            self.training_history['learning_rate_proj'].append(current_lr_proj)
            print(f"å½“å‰å­¦ä¹ ç‡: Base={current_lr_base:.2e}, Projection={current_lr_proj:.2e}")


            if current_epoch_combined_loss < best_overall_loss - min_improvement:
                if epoch_losses_ds1 or epoch_losses_ds2: # ä»…å½“å®é™…å‘ç”Ÿè®­ç»ƒæ—¶æ‰ä¿å­˜
                    best_overall_loss = current_epoch_combined_loss
                    patience_counter = 0
                    print(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹! ç»„åˆæŸå¤±: {best_overall_loss:.4f}. ä¿å­˜æ¨¡å‹...")
                    self.save_checkpoint(epoch + 1, best_overall_loss, is_best=True)
                else:
                    print("æ­¤è½®æœªæ‰§è¡Œè®­ç»ƒæ­¥éª¤ã€‚è·³è¿‡æœ€ä½³æ¨¡å‹æ£€æŸ¥ã€‚")
            else:
                patience_counter += 1
                print(f"è€å¿ƒè®¡æ•°: {patience_counter}/{scheduler.patience}")

            if patience_counter > scheduler.patience: # æ³¨æ„ï¼šscheduler.patience æ˜¯ ReduceLROnPlateau çš„å‚æ•°
                print("ğŸ›‘ æ—©åœè§¦å‘ã€‚")
                break
            self.plot_training_progress(save_plot=False, show_plot=False) # ç”Ÿæˆç»˜å›¾æ•°æ®ä»¥å¤‡ä¿å­˜

        print("ğŸ è®­ç»ƒå®Œæˆã€‚")
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼Œæ— è®ºæ˜¯å¦æœ€ä½³
        # self.save_checkpoint(epoch + 1, current_epoch_combined_loss, is_best=False, final_save=True)
        self.plot_training_progress(save_plot=True, show_plot=True) # ä¿å­˜å¹¶æ˜¾ç¤ºæœ€ç»ˆç»˜å›¾


    def save_checkpoint(self, epoch_num, loss_val, is_best=False, final_save=False):
        # åªåœ¨æ‰¾åˆ°æ›´ä¼˜æ¨¡å‹æ—¶æ‰æ‰§è¡Œä¿å­˜æ“ä½œ
        if not is_best:
            return

        state = {
            'epoch': epoch_num,
            'contrastive_encoder_state_dict': self.contrastive_encoder.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': loss_val,
            'training_history': dict(self.training_history), # ä¿å­˜è®­ç»ƒå†å²çš„å‰¯æœ¬
            'training_model_type': self.training_model_type,
            'training_model_identifier_or_path': self.training_model_identifier_or_path,
            'projection_head_config': self.projection_config,
            'pruning_model_path': self.pruning_model_path,
            'similarity_threshold': self.similarity_threshold,
            'num_negatives': self.num_negatives,
            'batch_size': self.batch_size,
            'pruning_inference_batch_size': self.pruning_inference_batch_size,
            'base_lr_initial': self.optimizer.param_groups[0].get('initial_lr'),
            'projection_lr_initial': self.optimizer.param_groups[1].get('initial_lr'),
            'use_weighted_loss': self.use_weighted_loss,
            'loss_weights': self.loss_weights,
            'adaptive_weighting': self.adaptive_weighting,
            'infonce_mode': self.infonce_mode,
            # --- æ–°å¢PEFTçŠ¶æ€ ---
            'use_peft': self.use_peft,
            'peft_config': self.peft_config,
            # --------------------
            'min_subtree_size_ds1': self.min_subtree_size_ds1,
            'max_samples_per_post_ds1': self.max_samples_per_post_ds1,
            'min_subtree_size_ds2': self.min_subtree_size_ds2,
            'max_samples_per_subtree_ds2': self.max_samples_per_subtree_ds2
        }
        if self.training_model_type == 'textcnn':
            state['textcnn_config'] = self.textcnn_config
            state['vocab'] = self.vocab

        # æ ¹æ®æ¨¡å‹æ ‡è¯†ç¬¦åˆ›å»ºä¿å­˜ç›®å½•
        sanitized_model_name = self.training_model_identifier_or_path.replace('/', '_')
        save_dir = os.path.join("model", sanitized_model_name)
        os.makedirs(save_dir, exist_ok=True)

        # ç”ŸæˆæŸå¤±å›¾çš„PNGå­—èŠ‚
        fig_bytes = self.plot_training_progress(save_plot=False, show_plot=False, return_bytes=True)
        if fig_bytes:
            # å°†æŸå¤±å›¾å­—èŠ‚ä¿å­˜åˆ° state ä¸­ï¼ˆå¯é€‰ï¼Œä½†ä¿ç•™äº†åŸæœ‰é€»è¾‘ï¼‰
            state['loss_plot_png'] = fig_bytes
            
            # å°†æŸå¤±å›¾ä¿å­˜ä¸ºç‹¬ç«‹çš„PNGæ–‡ä»¶
            plot_filepath = os.path.join(save_dir, "training_loss_plot.png")
            with open(plot_filepath, 'wb') as f:
                f.write(fig_bytes)
            print(f"ğŸ“Š è®­ç»ƒæŸå¤±å›¾å·²ä¿å­˜è‡³: {plot_filepath}")

        # å®šä¹‰å¹¶ä¿å­˜æœ€ä¼˜æ¨¡å‹çš„checkpointæ–‡ä»¶
        filepath = os.path.join(save_dir, "best_contrastive_model.pth")
        torch.save(state, filepath)
        print(f"âœ… æœ€ä¼˜æ¨¡å‹å·²æ›´æ–°å¹¶ä¿å­˜è‡³: {filepath}")


    def plot_training_progress(self, save_plot=False, show_plot=True, return_bytes=False):
        if not self.training_history['epoch']:
            if return_bytes: return None
            return

        try:
            import matplotlib
            matplotlib.use('Agg') # ç¡®ä¿éäº¤äº’å¼åç«¯
            import matplotlib.pyplot as plt
            plt.style.use('seaborn-v0_8-whitegrid')
        except ImportError:
            print("Matplotlib æœªæ‰¾åˆ°ã€‚è·³è¿‡ç»˜å›¾ç”Ÿæˆã€‚")
            if return_bytes: return None
            return
        except UserWarning: pass # å¿½ç•¥seabornæ ·å¼è­¦å‘Š

        fig, ax1 = plt.subplots(figsize=(14, 8)) # è°ƒæ•´å›¾å½¢å¤§å°
        epochs_data = self.training_history['epoch']

        color_ds1_loss = 'orangered'
        color_ds2_loss = 'forestgreen'
        color_combined_loss = 'mediumblue'

        ax1.set_xlabel('Epoch', fontsize=12)
        ax1.set_ylabel('Loss', color='black', fontsize=12)

        if 'loss_ds1' in self.training_history and any(v is not None and v > 0 for v in self.training_history['loss_ds1']):
            ax1.plot(epochs_data, self.training_history['loss_ds1'], color=color_ds1_loss, linestyle='--', marker='.', markersize=6, label='DS1 Loss (çˆ¶å­)')
        if 'loss_ds2' in self.training_history and any(v is not None and v > 0 for v in self.training_history['loss_ds2']):
            ax1.plot(epochs_data, self.training_history['loss_ds2'], color=color_ds2_loss, linestyle=':', marker='x', markersize=6, label='DS2 Loss (èŠ‚ç‚¹-ä¸­å¿ƒ)')
        if 'combined_loss' in self.training_history and any(v is not None for v in self.training_history['combined_loss']):
            ax1.plot(epochs_data, self.training_history['combined_loss'], color=color_combined_loss, linewidth=2.5, marker='o', markersize=4, label='ç»„åˆæŸå¤± (è°ƒåº¦å™¨)')
        ax1.tick_params(axis='y', labelcolor='black', labelsize=10)
        ax1.tick_params(axis='x', labelsize=10)
        ax1.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)
        ax1.set_yscale('log') # å°è¯•å¯¹æ•°åˆ»åº¦ï¼Œå¦‚æœæŸå¤±èŒƒå›´å¾ˆå¤§

        ax2 = ax1.twinx()
        color_lr_base = 'purple'
        color_lr_proj = 'darkcyan'
        color_w1 = 'coral'
        color_w2 = 'lightgreen'

        ax2.set_ylabel('å­¦ä¹ ç‡ / æƒé‡', color='dimgray', fontsize=12)
        if 'learning_rate_base' in self.training_history and any(v is not None for v in self.training_history['learning_rate_base']):
            ax2.plot(epochs_data, self.training_history['learning_rate_base'], color=color_lr_base, linestyle='-.', marker='s', markersize=4, label='LR (Base)')
        if 'learning_rate_proj' in self.training_history and any(v is not None for v in self.training_history['learning_rate_proj']):
            ax2.plot(epochs_data, self.training_history['learning_rate_proj'], color=color_lr_proj, linestyle='-.', marker='D', markersize=3, label='LR (Proj)')

        if self.use_weighted_loss and 'weight_ds1' in self.training_history and 'weight_ds2' in self.training_history:
            if any(v is not None for v in self.training_history['weight_ds1']):
                 ax2.plot(epochs_data, self.training_history['weight_ds1'], color=color_w1, linestyle=(0, (3, 5, 1, 5)), marker='^', markersize=5, label='æƒé‡ DS1') # (0, (3, 5, 1, 5)) is dashdotdotted
            if any(v is not None for v in self.training_history['weight_ds2']):
                 ax2.plot(epochs_data, self.training_history['weight_ds2'], color=color_w2, linestyle=(0, (3, 5, 1, 5)), marker='v', markersize=5, label='æƒé‡ DS2')

        ax2.tick_params(axis='y', labelcolor='dimgray', labelsize=10)
        ax2.set_ylim(bottom=0) # å­¦ä¹ ç‡å’Œæƒé‡éè´Ÿ
        # ax2.set_yscale('log') # å¦‚æœå­¦ä¹ ç‡å˜åŒ–èŒƒå›´ä¹Ÿå¾ˆå¤§

        handles1, labels1 = ax1.get_legend_handles_labels()
        handles2, labels2 = ax2.get_legend_handles_labels()
        # å°†å›¾ä¾‹æ”¾åœ¨å›¾è¡¨ä¸‹æ–¹
        fig.legend(handles1 + handles2, labels1 + labels2, loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, fontsize=9)

        model_name_for_title = self.training_model_identifier_or_path.split('/')[-1]
        plt.title(f'è®­ç»ƒè¿›åº¦: {model_name_for_title} ({self.training_model_type.upper()})', fontsize=15, pad=25)
        fig.tight_layout(rect=[0, 0.08, 1, 0.95]) # è°ƒæ•´å¸ƒå±€ä¸ºå›¾ä¾‹ç•™å‡ºç©ºé—´

        plot_bytes_val = None
        if return_bytes or save_plot:
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=150, bbox_inches='tight') # bbox_inches='tight' ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½ä¿å­˜
            buf.seek(0)
            plot_bytes_val = buf.getvalue()
            buf.close()

        # if save_plot and plot_bytes_val:
        #     plot_filename = f"training_progress_{self.training_model_identifier_or_path.replace('/', '_')}_{self.training_model_type}.png"
        #     with open(plot_filename, 'wb') as f:
        #         f.write(plot_bytes_val)
        #     print(f"ğŸ“ˆ è®­ç»ƒè¿›åº¦å›¾å·²ä¿å­˜åˆ° {plot_filename}")

        # if show_plot:
        #     # ç”±äºä½¿ç”¨äº† 'Agg' åç«¯ï¼Œplt.show() ä¸ä¼šæ˜¾ç¤ºä»»ä½•å†…å®¹ã€‚
        #     # ç”¨æˆ·éœ€è¦æ‰“å¼€ä¿å­˜çš„PNGæ–‡ä»¶æ¥æŸ¥çœ‹å›¾åƒã€‚
        #     print("ç»˜å›¾å·²ç”Ÿæˆã€‚å¦‚æœ save_plot=Trueï¼Œè¯·æ£€æŸ¥ä¿å­˜çš„PNGæ–‡ä»¶ã€‚")

        plt.close(fig) # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜

        if return_bytes:
            return plot_bytes_val
        return None

def build_pruned_forest(post_storage: PostStorage, similarity_threshold: float):
    """
    åŸºäºç›¸ä¼¼åº¦é˜ˆå€¼æ„å»ºå‰ªæåçš„æ£®æ—
    """
    print("ğŸ”„ æ„å»ºå‰ªææ£®æ—...")
    post_storage.forests.clear()
    pruning_results = post_storage.prune_all_posts_by_similarity(
        similarity_threshold=similarity_threshold, show_progress=True
    )
    print(f"âœ… æ£®æ—æ„å»ºå®Œæˆ: {len(pruning_results)} ä¸ªå¸–å­")
    return pruning_results

def fine_tune_contrastive_model(
    model: ContrastiveEncoder,
    train_loader: DataLoader,
    optimizer: torch.optim.Optimizer,
    loss_fn: ContrastiveLoss,
    device: torch.device,
    num_epochs: int = 3,
    scheduler_patience: int = 2,
    min_improvement: float = 1e-5
):
    """
    å¯¹æ¯”æ¨¡å‹å¾®è°ƒ
    """
    model.train()
    best_loss = float('inf')
    patience_counter = 0
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=scheduler_patience, threshold=min_improvement
    )

    for epoch in range(num_epochs):
        epoch_loss = 0.0
        batches_processed = 0

        progress_bar = tqdm(train_loader, desc=f"å¾®è°ƒå¯¹æ¯”æ¨¡å‹ (Epoch {epoch+1}/{num_epochs})", leave=False)
        for batch in progress_bar:
            optimizer.zero_grad()
            
            anchor_texts = batch['anchor_texts']
            positive_texts_ds1 = batch['positive_texts_ds1']
            negative_texts = batch['negative_texts']
            num_negatives = batch['num_negatives']

            # è¿‡æ»¤æ‰ positive_texts_ds1 ä¸­çš„ None (æ¥è‡ªDataset2çš„å ä½ç¬¦)
            valid_indices_ds1 = [i for i, txt in enumerate(positive_texts_ds1) if txt is not None]
            
            if valid_indices_ds1:
                anchor_texts_ds1 = [anchor_texts[i] for i in valid_indices_ds1]
                positive_texts_ds1_f = [positive_texts_ds1[i] for i in valid_indices_ds1]

                if anchor_texts_ds1: # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                    anchor_emb = model(anchor_texts_ds1)
                    positive_emb_ds1 = model(positive_texts_ds1_f)
                    
                    # é‡æ„ä¸è¿‡æ»¤åæ ·æœ¬å¯¹åº”çš„è´Ÿæ ·æœ¬
                    neg_emb = None
                    if negative_texts and num_negatives > 0:
                        # ä»æ‰å¹³åˆ—è¡¨ä¸­æå–ä¸ valid_indices_ds1 å¯¹åº”çš„è´Ÿæ ·æœ¬
                        current_batch_neg_texts = []
                        original_batch_size_collator = len(anchor_texts) # collatorå¤„ç†å‰çš„batchå¤§å°
                        for orig_idx in valid_indices_ds1:
                            start = orig_idx * num_negatives
                            end = start + num_negatives
                            current_batch_neg_texts.extend(negative_texts[start:end])
                        
                        if current_batch_neg_texts:
                            neg_emb_flat = model(current_batch_neg_texts)
                            neg_emb = neg_emb_flat.view(len(anchor_texts_ds1), num_negatives, -1)
                    
                    if neg_emb is not None and neg_emb.nelement() > 0:
                        loss = loss_fn(anchor_emb, positive_emb_ds1, neg_emb)
                    else:
                        loss = loss_fn(anchor_emb, positive_emb_ds1)

                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()

                    epoch_loss += loss.item()
                    batches_processed += 1

            progress_bar.set_postfix(loss=epoch_loss / batches_processed if batches_processed > 0 else epoch_loss)

        avg_loss = epoch_loss / batches_processed if batches_processed > 0 else 0.0
        scheduler.step(avg_loss)

        if avg_loss < best_loss - min_improvement:
            best_loss = avg_loss
            patience_counter = 0
            print(f"ğŸ’¾ ä¿å­˜å½“å‰æœ€ä½³æ¨¡å‹ï¼ŒæŸå¤±: {best_loss:.4f}")
            # å¯ä»¥é€‰æ‹©ä¿å­˜æ¨¡å‹
            # torch.save(model.state_dict(), "best_contrastive_model.pth")
        else:
            patience_counter += 1
            print(f"â³ ç­‰å¾…æ›´ä¼˜æ¨¡å‹ï¼Œå½“å‰è®¡æ•°å™¨: {patience_counter}/{scheduler_patience}")

        if patience_counter >= scheduler_patience:
            print("ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
            break

def main_jina_training_pipeline():
    print("ğŸš€ å¼€å§‹è®­ç»ƒæµç¨‹...")
    # 1. å‡†å¤‡æ•°æ®
    # try:
    #     with open('comments_data.json', 'r', encoding='utf-8') as f:
    #         comment_data = json.load(f)
    #     with open('contents_data.json', 'r', encoding='utf-8') as f:
    #         post_data = json.load(f)
    # except FileNotFoundError:
    #     print("é”™è¯¯: comments_data.json æˆ– contents_data.json æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ã€‚")
    #     return

    # comment_df = pd.DataFrame(comment_data)
    # post_df = pd.DataFrame(post_data)

    # # é‡‡æ ·è¯„è®ºæ•°é‡æœ€å°‘çš„ä¸¤ä¸ªnote_idçš„æ•°æ®
    # # ç»Ÿè®¡æ¯ä¸ªnote_idçš„è¯„è®ºæ•°é‡
    # note_id_counts = comment_df['note_id'].value_counts()

    # # è·å–è¯„è®ºæ•°é‡æœ€å°‘çš„note_id
    # # å¦‚æœnote_idæ•°é‡å°‘äº2ï¼Œåˆ™å–æ‰€æœ‰
    # if len(note_id_counts) > 0:
    #     num_to_sample = min(2, len(note_id_counts))
    #     sampled_note_ids = note_id_counts.nsmallest(num_to_sample).index.tolist()
    #     print(f"é‡‡æ ·è¯„è®ºæ•°é‡æœ€å°‘çš„ {num_to_sample} ä¸ª note_id: {sampled_note_ids}")

    #     # æ ¹æ®é€‰ä¸­çš„note_idç­›é€‰æ•°æ®
    #     comment_df = comment_df[comment_df['note_id'].isin(sampled_note_ids)]
    #     post_df = post_df[post_df['note_id'].isin(sampled_note_ids)]
    #     print(f"é‡‡æ ·åï¼Œcomment_df å½¢çŠ¶: {comment_df.shape}, post_df å½¢çŠ¶: {post_df.shape}")
    # else:
    #     print("è­¦å‘Š: comment_df ä¸­æ²¡æœ‰ note_id å¯ä¾›é‡‡æ ·ã€‚ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ã€‚")

    # 1. å‡†å¤‡æ•°æ®
    try:
        comment_df = pd.read_csv('data_process/cl_data/train_comments_filtered.csv', encoding='utf-8')
        post_df = pd.read_csv('data_process/cl_data/train_posts_filtered.csv', encoding='utf-8')
    except FileNotFoundError:
        print("é”™è¯¯: comments_data.csv æˆ– contents_data.csv æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ã€‚")
        return      
    

    # ç¡®ä¿ note_id å’Œ comment_id æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä»¥é¿å…åç»­é—®é¢˜
    comment_df['note_id'] = comment_df['note_id'].astype(str)
    comment_df['comment_id'] = comment_df['comment_id'].astype(str)
    comment_df['parent_comment_id'] = comment_df['parent_comment_id'].astype(str)
    post_df['note_id'] = post_df['note_id'].astype(str)


    storage = PostStorage()
    # ç¡®ä¿å¸–å­å†…å®¹æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚æœ title ä¸å­˜åœ¨ï¼Œå°è¯• contentï¼Œå¦‚æœéƒ½ä¸ºç©ºï¼Œåˆ™ä¸ºç©ºå­—ç¬¦ä¸²
    for _, row in post_df.iterrows():
        post_content = str(row.get('title', '')) or str(row.get('content', '')) # ä¿è¯æ˜¯å­—ç¬¦ä¸²
        storage.add_post(post_id=str(row['note_id']), post_content=post_content)

    for _, row in comment_df.iterrows():
        post_id_str = str(row['note_id'])
        comment_id_str = str(row['comment_id'])
        content_str = str(row.get('content', '')) # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²
        parent_id_str = str(row['parent_comment_id']) if str(row['parent_comment_id']) != '0' else post_id_str
        
        try:
            storage.add_comment_to_post(post_id_str, comment_id_str, content_str, parent_id_str)
        except Exception as e:
            print(f"æ’å…¥è¯„è®ºå¤±è´¥: {e}, å¸–å­ID: {post_id_str}, è¯„è®ºID: {comment_id_str}")

    # 2. é€‰æ‹©è®­ç»ƒæ¨¡å‹ç±»å‹å¹¶é…ç½®è®­ç»ƒå™¨
    common_trainer_params = {
        'post_storage': storage,
        'pruning_model_path': "google-bert/bert-base-chinese", # 
        'similarity_threshold': 0.7, # è°ƒæ•´é˜ˆå€¼
        'num_negatives': 8,      # å¢åŠ è´Ÿæ ·æœ¬æ•°é‡
        'batch_size': 8,        # è°ƒæ•´æ‰¹é‡å¤§å°
        'pruning_inference_batch_size': 16, # <--- ä¸ºå‰ªææ¨¡å‹æ¨æ–­è®¾ç½®ä¸€ä¸ªåˆç†çš„æ‰¹å¤§å°
        'base_lr': 5e-6,         # è°ƒæ•´å­¦ä¹ ç‡
        'projection_lr': 5e-5,
        'use_weighted_loss': True,
        'loss_weights': {'dataset1': 1, 'dataset2': 0}, # è°ƒæ•´æƒé‡
        'adaptive_weighting': False, # å¯ç”¨è‡ªé€‚åº”æƒé‡
        'infonce_mode': 'bidirectional', # åŒå‘å¯¹æ¯”
        'projection_head_config': {'hidden_dim': 768, 'output_dim': 384, 'dropout_rate': 0.15}, # è°ƒæ•´æŠ•å½±å¤´
        'min_subtree_size_ds1': 2, 'max_samples_per_post_ds1': None,
        'min_subtree_size_ds2': 100000, 'max_samples_per_subtree_ds2': None,

        # --- æ–°å¢PEFTé…ç½® ---
        'use_peft': False,  # è®¾ç½®ä¸º True æ¥å¯ç”¨ LoRA
        'peft_config': {
            'r': 8,              # LoRAçš„ç§©ï¼Œè¶Šå°å‚æ•°è¶Šå°‘ï¼Œå¸¸ç”¨8, 16, 32
            'lora_alpha': 16,    # LoRAçš„ç¼©æ”¾å› å­ï¼Œé€šå¸¸æ˜¯rçš„ä¸¤å€
            'target_modules': ["query", "key", "value"], # å¯¹æ³¨æ„åŠ›çš„Q,K,Våº”ç”¨
            'lora_dropout': 0.1, # LoRAå±‚çš„dropoutç‡
            'bias': "none",      # "none", "all", "lora_only"
    }}

    # # ğŸ¯ é€‰é¡¹ 1: ModelScope æ¨¡å‹
    # print("\n--- é…ç½® ModelScope æ¨¡å‹è®­ç»ƒ ---")
    # trainer = DynamicContrastiveTrainer(
    #     training_model_type='modelscope',
    #     # ä½¿ç”¨å¦ä¸€ä¸ªModelScopeæ¨¡å‹ä½œä¸ºè®­ç»ƒç›®æ ‡
    #     training_model_identifier_or_path="google-bert/bert-base-chinese",
    #     **common_trainer_params
    # )

    # ğŸ¯ é€‰é¡¹ 2: è‡ªå®šä¹‰ TextCNN
    print("\n--- é…ç½® TextCNN è®­ç»ƒ ---")
    textcnn_specific_config = {
        'embedding_dim': 300,       
        'num_filters': 128,         
        'filter_sizes': [2, 3, 4],  
        'model_dropout_rate': 0.1,  
        'max_seq_length': 200,      # TextCNNåˆ†è¯å™¨çš„æœ€å¤§åºåˆ—é•¿åº¦
        'textcnn_output_dim': 768,  # TextCNNè¾“å‡ºç»´åº¦ (ä¸æŠ•å½±å¤´è¾“å‡ºåŒ¹é…æˆ–ä½œä¸ºå…¶è¾“å…¥)
        'min_vocab_freq': 1         # è¯æ±‡è¡¨æœ€å°è¯é¢‘
    }
    # ç¡®ä¿ TextCNN çš„è¾“å‡ºç»´åº¦ä¸æŠ•å½±å¤´çš„è¾“å…¥ç»´åº¦åŒ¹é…
    # common_trainer_params['projection_head_config']['hidden_dim'] å¯ä»¥åŸºäº textcnn_output_dim
    # æˆ–è€… textcnn_output_dim ç›´æ¥ä½œä¸ºæŠ•å½±å¤´çš„è¾“å…¥
    # è¿™é‡Œå‡è®¾ textcnn_output_dim æ˜¯æŠ•å½±å¤´çš„è¾“å…¥ï¼Œæ‰€ä»¥ base_dim ä¼šæ˜¯ textcnn_output_dim

    trainer = DynamicContrastiveTrainer(
        training_model_type='textcnn',
        training_model_identifier_or_path="model/my_custom_textcnn_v4_no_pruning_paircl", # è‡ªå®šä¹‰æ¨¡å‹æ ‡è¯†ç¬¦
        textcnn_config=textcnn_specific_config,
        **common_trainer_params
    )
    
    # 3. å¼€å§‹è®­ç»ƒ
    print("\n--- å¼€å§‹è®­ç»ƒ ---")
    trainer.train(
        num_epochs=2, # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œå‡å°‘äº†epochï¼ŒåŸä¸º100
        rebuild_frequency=2,  # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œå‡å°‘äº†é¢‘ç‡ï¼ŒåŸä¸º200
        scheduler_patience=7, # åŸä¸º2
        min_improvement=1e-5
    )
    
    print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆ!")
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å’Œè®­ç»ƒçŠ¶æ€å·²ä¿å­˜ã€‚è®­ç»ƒåçš„åŸºç¡€æ¨¡å‹éƒ¨åˆ†ä½äº 'trained_{trainer.training_model_type}_embedding_model' ç›®å½•ä¸­ã€‚")

def load_trained_model_and_tokenizer(checkpoint_path: str):
    """
    ä»checkpointåŠ è½½å®Œæ•´çš„è®­ç»ƒå™¨çŠ¶æ€ï¼Œå¹¶è¿”å›è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚
    """
    if not os.path.exists(checkpoint_path):
        print(f"é”™è¯¯: Checkpoint æ–‡ä»¶ {checkpoint_path} æœªæ‰¾åˆ°ã€‚")
        return None, None, None

    print(f"æ­£åœ¨ä» {checkpoint_path} åŠ è½½checkpoint...")
    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'),weights_only=False) # åŠ è½½åˆ°CPUä»¥é¿å…GPUé—®é¢˜

    model_type = checkpoint['training_model_type']
    model_identifier = checkpoint['training_model_identifier_or_path']
    proj_config = checkpoint['projection_head_config']

    # --- æ–°å¢ï¼šè·å–PEFTé…ç½® ---
    use_peft = checkpoint.get('use_peft', False)
    peft_config = checkpoint.get('peft_config', None)
    # -------------------------
    
    encoder = None
    if model_type == 'textcnn':
        textcnn_conf = checkpoint['textcnn_config']
        vocab_data = checkpoint['vocab']
        encoder = ContrastiveEncoder(
            model_type='textcnn',
            vocab=vocab_data,
            textcnn_config=textcnn_conf,
            projection_hidden_dim=proj_config['hidden_dim'],
            projection_output_dim=proj_config['output_dim'],
            projection_dropout_rate=proj_config['dropout_rate']
        )
    elif model_type == 'modelscope':
        encoder = ContrastiveEncoder(
            model_type='modelscope',
            model_name_or_path=model_identifier,
            projection_hidden_dim=proj_config['hidden_dim'],
            projection_output_dim=proj_config['output_dim'],
            projection_dropout_rate=proj_config['dropout_rate']
        )
        # --- æ–°å¢ï¼šå¦‚æœä½¿ç”¨äº†PEFTï¼Œé‡æ–°åŒ…è£…æ¨¡å‹ ---
        if use_peft:
            print("ğŸ”§ æ£€æµ‹åˆ°PEFTè®­ç»ƒçš„checkpointï¼Œæ­£åœ¨é‡æ–°åº”ç”¨LoRAé…ç½®...")
            lora_config = LoraConfig(**peft_config)
            encoder.base_model = get_peft_model(encoder.base_model, lora_config)
            print("âœ… LoRAé…ç½®å·²é‡æ–°åº”ç”¨ã€‚")
        # ------------------------------------
    else:
        print(f"é”™è¯¯: Checkpointä¸­æœªçŸ¥çš„æ¨¡å‹ç±»å‹ '{model_type}'")
        return None, None, None

    encoder.load_state_dict(checkpoint['contrastive_encoder_state_dict'])
    encoder.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    print(f"âœ… {model_type.upper()} ContrastiveEncoder åŠ è½½å®Œæˆå¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚")
    
    # è¿”å›åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨
    return encoder.base_model, encoder.tokenizer, model_type


if __name__ == "__main__":
    # # ç¡®ä¿jiebaå·²åˆå§‹åŒ–ï¼ˆå¦‚æœå®ƒæ˜¯æƒ°æ€§åŠ è½½çš„ï¼‰
    # try:
    #     _ = jieba.lcut("æµ‹è¯•jiebaåˆå§‹åŒ–")
    # except Exception as e:
    #     print(f"ç”±äºä»¥ä¸‹åŸå› åˆå§‹åŒ–jieba: {e}")
    #     jieba.initialize() # æ˜¾å¼åˆå§‹åŒ–

    main_jina_training_pipeline()






