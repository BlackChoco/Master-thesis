import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import os
import json
import random
from tqdm import tqdm
from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup
# --- å…³é”®ä¿®æ”¹: å¯¼å…¥ AutoModel å’Œ AutoTokenizer ---
from modelscope import AutoModel, AutoTokenizer 
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
from sklearn.model_selection import train_test_split # ç”¨äºä»è®­ç»ƒé›†ä¸­åˆ’åˆ†éªŒè¯é›†
from peft import get_peft_model, LoraConfig


# ä» cl_training.py å¯¼å…¥å¿…è¦çš„ç±»
# å‡è®¾ cl_training.py ä¸æ­¤è„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹
from cl_training_modelscope import ContrastiveEncoder, TextCNNModel, TextCNNTokenizer

# --- 1. æ•°æ®é›†å’Œæ¨¡å‹å®šä¹‰ ---

class SupervisedTextDataset(Dataset):
    """ç”¨äºæœ‰ç›‘ç£æ–‡æœ¬åˆ†ç±»çš„PyTorchæ•°æ®é›†ã€‚"""
    def __init__(self, texts: list, labels: list, tokenizer, label_to_id: dict, max_len: int = 256):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.label_to_id = label_to_id

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        # ä½¿ç”¨ä¸é¢„è®­ç»ƒæ—¶ç›¸åŒçš„åˆ†è¯å™¨
        # æ£€æŸ¥åˆ†è¯å™¨ç±»å‹ï¼Œå› ä¸º TextCNNTokenizer å’Œ HF Tokenizer çš„å‚æ•°ä¸åŒ
        if isinstance(self.tokenizer, TextCNNTokenizer):
            encoding = self.tokenizer(
                text,
                padding=True,
                truncation=True,
                return_tensors='pt',
                max_length=self.max_len
            )
        else: # å‡è®¾æ˜¯ HuggingFace Tokenizer
            encoding = self.tokenizer(
                text,
                add_special_tokens=True,
                max_length=self.max_len,
                return_token_type_ids=False,
                padding='max_length',
                truncation=True,
                return_attention_mask=True,
                return_tensors='pt',
            )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(self.label_to_id[label], dtype=torch.long)
        }

class SupervisedModel(nn.Module):
    """
    åŒ…è£…é¢„è®­ç»ƒçš„ç¼–ç å™¨å’Œä¸€ä¸ªåˆ†ç±»å¤´ã€‚
    """
    def __init__(self, base_encoder: nn.Module, num_labels: int, classifier_type: str = 'linear'):
        super().__init__()
        self.base_encoder = base_encoder
        
        # ä»åŸºç¡€ç¼–ç å™¨è·å–éšè—å±‚ç»´åº¦
        if hasattr(base_encoder, 'base_dim'): # é€‚ç”¨äºæˆ‘ä»¬è‡ªå®šä¹‰çš„TextCNNModel
            hidden_size = base_encoder.base_dim
        elif hasattr(base_encoder.config, 'hidden_size'): # é€‚ç”¨äºHuggingFace/ModelScopeæ¨¡å‹
            hidden_size = base_encoder.config.hidden_size
        else:
            # å°è¯•ä»æ¨¡å‹è¾“å‡ºè·å–ç»´åº¦ï¼ˆå¦‚æœæ¨¡å‹å·²åŠ è½½å‚æ•°ï¼‰
            try:
                # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè¾“å…¥æ¥æ¨æ–­ç»´åº¦
                dummy_input = {'input_ids': torch.randint(0, 100, (1, 10)), 'attention_mask': torch.ones(1, 10)}
                dummy_output = base_encoder(**dummy_input)
                
                # è°ƒè¯•ï¼šæ‰“å°è¾“å‡ºçš„æ‰€æœ‰é”®
                print(f"è°ƒè¯•: æ¨¡å‹è¾“å‡ºé”®: {dummy_output.keys()}")

                # ModelScope æ¨¡å‹é€šå¸¸è¿”å›å­—å…¸ï¼Œå°è¯•ä¸åŒçš„é”®
                if 'last_hidden_state' in dummy_output:
                    hidden_size = dummy_output['last_hidden_state'].shape[-1]
                elif 'hidden_states' in dummy_output:
                    hidden_size = dummy_output['hidden_states'].shape[-1]
                else:
                    raise KeyError("åœ¨æ¨¡å‹è¾“å‡ºä¸­æ‰¾ä¸åˆ° 'last_hidden_state' æˆ– 'hidden_states'ã€‚")

            except Exception as e:
                raise ValueError(f"æ— æ³•è‡ªåŠ¨ç¡®å®šåŸºç¡€ç¼–ç å™¨çš„è¾“å‡ºç»´åº¦: {e}")

        print(f"åˆ†ç±»å™¨æ¥æ”¶çš„éšè—å±‚ç»´åº¦: {hidden_size}")

        if classifier_type == 'linear':
            self.classifier = nn.Linear(hidden_size, num_labels)
        elif classifier_type == 'mlp':
            self.classifier = nn.Sequential(
                nn.Linear(hidden_size, hidden_size // 2),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(hidden_size // 2, num_labels)
                
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†ç±»å™¨ç±»å‹: {classifier_type}ã€‚è¯·é€‰æ‹© 'linear' æˆ– 'mlp'ã€‚")

    def forward(self, input_ids, attention_mask):
        # åŸºç¡€ç¼–ç å™¨è¾“å‡º
        # ModelScope æ¨¡å‹éœ€è¦å…³é”®å­—å‚æ•°
        base_output = self.base_encoder(input_ids=input_ids, attention_mask=attention_mask)
        
        # æ ¹æ®åŸºç¡€ç¼–ç å™¨çš„è¾“å‡ºç±»å‹æå–ç‰¹å¾
        # ModelScope æ¨¡å‹é€šå¸¸è¿”å›ä¸€ä¸ªå­—å…¸
        if isinstance(base_output, dict):
            if 'last_hidden_state' in base_output:
                # [CLS] token representation
                features = base_output['last_hidden_state'][:, 0, :]
            elif 'hidden_states' in base_output:
                # æœ‰äº›æ¨¡å‹å¯èƒ½åªè¿”å› hidden_states
                features = base_output['hidden_states'][:, 0, :]
            elif 'pooler_output' in base_output and base_output['pooler_output'] is not None:
                features = base_output['pooler_output']
            else:
                # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºé”™è¯¯
                raise KeyError(f"åœ¨æ¨¡å‹è¾“å‡ºå­—å…¸ä¸­æ‰¾ä¸åˆ°å¯ç”¨çš„ç‰¹å¾é”®ã€‚å¯ç”¨é”®: {base_output.keys()}")
        elif hasattr(base_output, 'pooler_output') and base_output.pooler_output is not None:
            features = base_output.pooler_output
        elif hasattr(base_output, 'last_hidden_state'):
            features = base_output.last_hidden_state[:, 0, :]
        else:
            features = base_output

        # --- ä¿®æ­£ï¼šç¡®ä¿ features æ˜¯ float32 ---
        if features.dtype != torch.float32:
            features = features.to(torch.float32)
        # --------------------------------------

        logits = self.classifier(features)
        return logits

    def freeze_encoder(self):
        """å†»ç»“åŸºç¡€ç¼–ç å™¨çš„æ‰€æœ‰å‚æ•°ã€‚"""
        print("ğŸ§Š æ­£åœ¨å†»ç»“åŸºç¡€ç¼–ç å™¨çš„å‚æ•°...")
        for param in self.base_encoder.parameters():
            param.requires_grad = False
        print("âœ… åŸºç¡€ç¼–ç å™¨å·²å†»ç»“ã€‚")

    def unfreeze_encoder(self):
        """è§£å†»åŸºç¡€ç¼–ç å™¨çš„æ‰€æœ‰å‚æ•°ã€‚"""
        print("ğŸ”¥ æ­£åœ¨è§£å†»åŸºç¡€ç¼–ç å™¨çš„å‚æ•°...")
        for param in self.base_encoder.parameters():
            param.requires_grad = True
        print("âœ… åŸºç¡€ç¼–ç å™¨å·²è§£å†»ã€‚")


# --- 2. è¾…åŠ©å‡½æ•° ---

def set_seed(seed_value=42):
    """ä¸ºæ‰€æœ‰ç›¸å…³åº“è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§ã€‚"""
    random.seed(seed_value)
    np.random.seed(seed_value)
    torch.manual_seed(seed_value)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed_value)

def load_data(train_path, test_path):
    """åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ã€‚"""
    try:
        df_train = pd.read_csv(train_path)
        df_test = pd.read_csv(test_path)
        print(f"åŠ è½½æ•°æ®: è®­ç»ƒé›† {len(df_train)} è¡Œ, æµ‹è¯•é›† {len(df_test)} è¡Œã€‚")
        return df_train, df_test
    except FileNotFoundError as e:
        print(f"é”™è¯¯: æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ° - {e}")
        return None, None

def load_pretrained_encoder(checkpoint_path: str):
    """
    ä»å¯¹æ¯”å­¦ä¹ é˜¶æ®µçš„checkpointåŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œæˆ–ç›´æ¥ä»ModelScope HubåŠ è½½ã€‚
    """
    if os.path.exists(checkpoint_path):
        print(f"æ­£åœ¨ä»æœ¬åœ°checkpoint {checkpoint_path} åŠ è½½...")
        checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'), weights_only=False)

        model_type = checkpoint.get('training_model_type', 'hf')
        model_identifier = checkpoint.get('training_model_identifier_or_path')
        proj_config = checkpoint.get('projection_head_config')
        use_peft = checkpoint.get('use_peft', False)
        peft_config = checkpoint.get('peft_config', None)

        temp_encoder = None
        if model_type == 'textcnn':
            textcnn_conf = checkpoint['textcnn_config']
            vocab_data = checkpoint['vocab']
            temp_encoder = ContrastiveEncoder(
                model_type='textcnn', vocab=vocab_data, textcnn_config=textcnn_conf,
                projection_hidden_dim=proj_config['hidden_dim'],
                projection_output_dim=proj_config['output_dim'],
                projection_dropout_rate=proj_config['dropout_rate']
            )
        elif model_type in ['hf', 'modelscope']:
            temp_encoder = ContrastiveEncoder(
                model_type='modelscope', model_name_or_path=model_identifier,
                projection_hidden_dim=proj_config['hidden_dim'],
                projection_output_dim=proj_config['output_dim'],
                projection_dropout_rate=proj_config['dropout_rate']
            )
            # --- LoRA/PEFTæ¨¡å‹ç‰¹æ®Šå¤„ç† ---
            if use_peft and peft_config is not None:
                print("æ£€æµ‹åˆ°PEFT/LoRAæ¨¡å‹ï¼Œæ­£åœ¨åº”ç”¨LoRAç»“æ„...")
                lora_config = LoraConfig(**peft_config)
                temp_encoder.base_model = get_peft_model(temp_encoder.base_model, lora_config)
                print("LoRAç»“æ„å·²åº”ç”¨ã€‚")
        else:
            print(f"é”™è¯¯: Checkpointä¸­æœªçŸ¥çš„æ¨¡å‹ç±»å‹ '{model_type}'")
            return None, None, None

        # åŠ è½½æƒé‡æ—¶å…è®¸strict=Falseï¼Œå…¼å®¹LoRAæƒé‡
        temp_encoder.load_state_dict(checkpoint['contrastive_encoder_state_dict'], strict=False)
        print(f"âœ… Checkpoint åŠ è½½æˆåŠŸã€‚æ¨¡å‹ç±»å‹: {model_type.upper()}")

        return temp_encoder.base_model, temp_encoder.tokenizer, model_type
    
    # å¦‚æœä¸æ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œåˆ™å°è¯•ä» ModelScope Hub åŠ è½½
    else:
        print(f"æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œå°è¯•ä» ModelScope Hub åŠ è½½æ¨¡å‹: {checkpoint_path}")
        try:
            # --- å…³é”®ä¿®æ”¹: ä½¿ç”¨ AutoModel å’Œ AutoTokenizer ---
            base_model = AutoModel.from_pretrained(checkpoint_path, trust_remote_code=True)
            tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)
            print(f"âœ… æˆåŠŸä» ModelScope Hub åŠ è½½åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚")
            return base_model, tokenizer, 'ms' # è¿”å› 'ms' ä½œä¸ºæ¨¡å‹ç±»å‹
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•ä» ModelScope Hub åŠ è½½æ¨¡å‹ '{checkpoint_path}': {e}")
            return None, None, None


# --- 3. è®­ç»ƒå’Œè¯„ä¼°é€»è¾‘ ---

def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):
    """æ‰§è¡Œä¸€ä¸ªè®­ç»ƒè½®æ¬¡ã€‚"""
    model.train()
    total_loss = 0
    for batch in tqdm(data_loader, desc="è®­ç»ƒä¸­", leave=False):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        optimizer.zero_grad()
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        loss = loss_fn(outputs, labels)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()
        total_loss += loss.item()
    return total_loss / len(data_loader)

def evaluate_model(model, data_loader, loss_fn, device, id_to_label: dict):
    """åœ¨éªŒè¯é›†æˆ–æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ã€‚"""
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(data_loader, desc="è¯„ä¼°ä¸­", leave=False):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            loss = loss_fn(outputs, labels)
            total_loss += loss.item()

            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())

    # --- è®¡ç®—æ•´ä½“æŒ‡æ ‡ ---
    avg_loss = total_loss / len(data_loader)
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
    
    # --- è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ ---
    class_ids = sorted(id_to_label.keys())
    # ä½¿ç”¨åŸå§‹æ ‡ç­¾ä½œä¸ºæŠ¥å‘Šä¸­çš„åç§°
    target_names = [f"class_{id_to_label[cid]}" for cid in class_ids]
    report_dict = classification_report(
        all_labels, 
        all_preds, 
        labels=class_ids,
        target_names=target_names,
        output_dict=True, 
        zero_division=0
    )
    # æå–æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ï¼Œå¹¶ç§»é™¤ 'support'
    per_class_metrics = {}
    for name in target_names:
        if name in report_dict:
            metrics = report_dict[name].copy()
            metrics.pop('support', None)
            per_class_metrics[name] = metrics

    return {
        "loss": avg_loss,
        "accuracy": accuracy,
        "f1_score": f1,
        "precision": precision,
        "recall": recall,
        "per_class_metrics": per_class_metrics
    }

# --- 4. ä¸»å®éªŒæµç¨‹ ---

def run_experiment(config):
    """è¿è¡Œå•æ¬¡å®Œæ•´çš„å®éªŒï¼ˆç»™å®šé…ç½®å’Œç§å­ï¼‰ã€‚"""
    
    # è®¾ç½®éšæœºç§å­
    set_seed(config['seed'])
    print(f"\n--- è¿è¡Œå®éªŒ: æ¨¡å‹={config['model_name']}, æ–¹æ³•={config['method']}, "
          f"æ•°æ®æ¯”ä¾‹={config['data_fraction']*100}%, ç§å­={config['seed']} ---")

    # åŠ è½½æ•°æ®
    df_train_full, df_test = load_data(config['train_data_path'], config['test_data_path'])
    if df_train_full is None: 
        return None

    # è¿‡æ»¤æ‰ label ä¸º 5 çš„æ ·æœ¬ï¼ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½è¦è¿‡æ»¤ï¼‰
    df_train_full = df_train_full[df_train_full['label'] != 5].reset_index(drop=True)
    df_test = df_test[df_test['label'] != 5].reset_index(drop=True)

    # 1. å…ˆä»å®Œæ•´è®­ç»ƒæ•°æ®ä¸­åˆ’åˆ†å‡ºå›ºå®šçš„éªŒè¯é›†
    from sklearn.model_selection import train_test_split
    df_train_prelim, df_val = train_test_split(
        df_train_full,
        test_size=0.1, # éªŒè¯é›†å å®Œæ•´è®­ç»ƒé›†çš„10%
        random_state=config['seed'],
        stratify=df_train_full['label']
    )

    # 2. å†ä»åˆ’åˆ†åçš„è®­ç»ƒé›†ä¸­è¿›è¡Œé‡‡æ ·ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
    if config['data_fraction'] < 1.0:
        # åˆ†å±‚é‡‡æ ·
        df_train = df_train_prelim.groupby('label', group_keys=False).apply(
            lambda x: x.sample(frac=config['data_fraction'], random_state=config['seed'])
        ).reset_index(drop=True)
    else:
        df_train = df_train_prelim.reset_index(drop=True) # å½“ä½¿ç”¨å…¨éƒ¨æ•°æ®æ—¶ï¼Œä¹Ÿé‡ç½®ç´¢å¼•

    # é‡æ–°ç”Ÿæˆæ ‡ç­¾æ˜ å°„ï¼ˆåªåŒ…å«å‰©ä¸‹çš„æ ‡ç­¾ï¼‰
    unique_labels = sorted(df_train_full['label'].unique())
    label_to_id = {label: i for i, label in enumerate(unique_labels)}
    id_to_label = {i: label for label, i in label_to_id.items()}
    num_labels = len(unique_labels)

    # åŠ è½½é¢„è®­ç»ƒçš„ç¼–ç å™¨å’Œåˆ†è¯å™¨
    base_encoder, tokenizer, _ = load_pretrained_encoder(config['checkpoint_path'])
    if base_encoder is None: return None
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = SupervisedTextDataset(df_train['content'].tolist(), df_train['label'].tolist(), tokenizer, label_to_id)
    val_dataset = SupervisedTextDataset(df_val['content'].tolist(), df_val['label'].tolist(), tokenizer, label_to_id)
    test_dataset = SupervisedTextDataset(df_test['content'].tolist(), df_test['label'].tolist(), tokenizer, label_to_id)

    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])
    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'])

    # æ„å»ºç›‘ç£æ¨¡å‹
    model = SupervisedModel(
        base_encoder=base_encoder,
        num_labels=num_labels,
        classifier_type='mlp' if config['method'] == 'fine_tune' else 'linear'
    ).to(device)

    # æ ¹æ®é…ç½®å†»ç»“æˆ–è§£å†»ç¼–ç å™¨
    if config['freeze_encoder']:
        model.freeze_encoder()
        optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=config['lr'])
    else: # fine_tune
        model.unfreeze_encoder()
        optimizer = AdamW(model.parameters(), lr=config['lr'])

    # å‡†å¤‡è®­ç»ƒ
    loss_fn = nn.CrossEntropyLoss()
    total_steps = len(train_loader) * config['epochs']
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

    best_val_f1 = -1
    best_model_state = None

    # è®­ç»ƒå¾ªç¯
    for epoch in range(config['epochs']):
        print(f"  Epoch {epoch + 1}/{config['epochs']}")
        train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler)
        val_metrics = evaluate_model(model, val_loader, loss_fn, device, id_to_label)
        print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f} | éªŒè¯æŸå¤±: {val_metrics['loss']:.4f} | éªŒè¯F1: {val_metrics['f1_score']:.4f}")

        if val_metrics['f1_score'] > best_val_f1:
            best_val_f1 = val_metrics['f1_score']
            best_model_state = model.state_dict()
            print(f"  ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯F1åˆ†æ•°: {best_val_f1:.4f}")

    # ä½¿ç”¨æœ€ä½³æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    if best_model_state:
        model.load_state_dict(best_model_state)
    print("ğŸ§ª ä½¿ç”¨æœ€ä½³æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
    test_metrics = evaluate_model(model, test_loader, loss_fn, device, id_to_label)
    print(f"  æµ‹è¯•é›†ç»“æœ -> æŸå¤±: {test_metrics['loss']:.4f}, å‡†ç¡®ç‡: {test_metrics['accuracy']:.4f}, F1åˆ†æ•°: {test_metrics['f1_score']:.4f}")
    
    return test_metrics


# --- 5. ä¸»å‡½æ•° ---

if __name__ == '__main__':
    # --- å®éªŒé…ç½® ---
    # å®šä¹‰æ‰€æœ‰å®éªŒçš„é€šç”¨é…ç½®
    BASE_CONFIG = {
        'train_data_path': 'data_process/sup_train_data/trainset.csv',
        'test_data_path': 'data_process/sup_train_data/testset.csv',
        'epochs': 50,
        'batch_size': 16,
        # 'lr' is now defined in METHODS_CONFIG
    }
    
    # å®šä¹‰è¦è¿è¡Œçš„å¯¹æ¯”å­¦ä¹ æ¨¡å‹
    # key: ä¸€ä¸ªæè¿°æ€§åç§°, value: checkpointæ–‡ä»¶çš„è·¯å¾„æˆ–ModelScopeæ¨¡å‹æ ‡è¯†ç¬¦
    EXPERIMENT_MODELS = {
        # "jina_embed_none":'jinaai/jina-embeddings-v3',
        
        # "TextCNN_CL_bert_random": "model/model_random_init/best_contrastive_model.pth",
        # 'TextCNN_CL_bert':'model/my_custom_textcnn_v3_bert_pruning_paircl/best_contrastive_model.pth',
        # æ¨èä½¿ç”¨ModelScopeåŸç”Ÿæ”¯æŒçš„ç‰¹å¾æå–æ¨¡å‹ï¼Œä½†AutoModelä¹Ÿèƒ½å¤„ç†bert-base-chinese
        
        'lora_bert_base_chinese_cl': 'model/google-bert_bert-base-chinese/best_contrastive_model.pth',
        "Bert_base_chinese_nocl": "google-bert/bert-base-chinese", 
        # 'TextCNN_CL_no_pruing':'model/my_custom_textcnn_v3_no_pruning_paircl/best_contrastive_model.pth'
    }

    # å®šä¹‰è¦è¿è¡Œçš„è¯„ä¼°æ–¹æ³•é…ç½®
    METHODS_CONFIG = [
        {'name': 'linear_probe', 'freeze_encoder': True, 'lr': 1e-3},
        # {'name': 'fine_tune', 'freeze_encoder': False, 'lr': 2e-5}, 
    ]
    
    # å®šä¹‰æ•°æ®æ¯”ä¾‹å’Œéšæœºç§å­
    DATA_FRACTIONS = [1, 0.5, 0.2, 0.1, 0.05]
    SEEDS = [42, 123, 456, 789, 101, 20, 30, 40, 50, 60]  # å¢åŠ æ›´å¤šç§å­ä»¥æé«˜ç»“æœçš„ç¨³å®šæ€§

    # --- å®éªŒæ‰§è¡Œ ---
    all_results = []

    for model_name, checkpoint_path in EXPERIMENT_MODELS.items():
        for method_config in METHODS_CONFIG:
            method_name = method_config['name']
            
            results_for_method = {
                "model_name": model_name,
                "method": method_name,
                "freeze_encoder": method_config['freeze_encoder'],
                "epochs": BASE_CONFIG['epochs'],
                "batch_size": BASE_CONFIG['batch_size'],
                "learning_rate": method_config['lr'],
                "results_by_fraction": {}
            }

            for fraction in DATA_FRACTIONS:
                
                fraction_key = f"{int(fraction*100)}%"
                print(f"\n======================================================================")
                print(f"å¼€å§‹å®éªŒç³»åˆ—: æ¨¡å‹='{model_name}', æ–¹æ³•='{method_name}', å†»ç»“={method_config['freeze_encoder']}, æ•°æ®æ¯”ä¾‹='{fraction_key}'")
                print(f"======================================================================\n")

                run_metrics = []
                for seed in SEEDS:
                    config = BASE_CONFIG.copy()
                    config.update({
                        "model_name": model_name,
                        "checkpoint_path": checkpoint_path,
                        "method": method_name,
                        "freeze_encoder": method_config['freeze_encoder'],
                        "data_fraction": fraction,
                        "seed": seed,
                        "lr": method_config['lr']
                    })
                    
                    metrics = run_experiment(config)
                    if metrics:
                        run_metrics.append(metrics)
                
                # è®¡ç®—å‡å€¼å’Œæ–¹å·®
                if run_metrics:
                    # æ‰å¹³åŒ–ç»“æœä»¥è®¡ç®—ç»Ÿè®¡æ•°æ®
                    flattened_metrics_list = []
                    for m in run_metrics:
                        flat_m = {}
                        # å¤åˆ¶é¡¶çº§æŒ‡æ ‡
                        for k, v in m.items():
                            if k != 'per_class_metrics':
                                flat_m[k] = v
                        # æ‰å¹³åŒ–æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
                        if 'per_class_metrics' in m:
                            for class_name, class_stats in m['per_class_metrics'].items():
                                for metric_name, value in class_stats.items():
                                    flat_m[f"{class_name}_{metric_name}"] = value
                        flattened_metrics_list.append(flat_m)

                    df_metrics = pd.DataFrame(flattened_metrics_list)
                    mean_metrics = df_metrics.mean().to_dict()
                    std_metrics = df_metrics.std().to_dict()
                    
                    results_for_method["results_by_fraction"][fraction_key] = {
                        "mean": mean_metrics,
                        "std": std_metrics,
                        "runs": run_metrics # ä¿å­˜æ¯æ¬¡è¿è¡Œçš„åŸå§‹ç»“æ„åŒ–ç»“æœ
                    }

            all_results.append(results_for_method)

            # --- ä¿å­˜ç»“æœ ---
            output_dir = "result"
            os.makedirs(output_dir, exist_ok=True)
            
 # ä¸ºå½“å‰æ¨¡å‹å’Œæ–¹æ³•çš„ç»“æœåˆ›å»ºä¸€ä¸ªå•ç‹¬çš„æ–‡ä»¶ï¼Œæ–‡ä»¶ååŒ…å«å†»ç»“çŠ¶æ€å’Œè®­ç»ƒå‚æ•°
            result_filename = (
                f"{model_name}_{method_name}_freeze_{method_config['freeze_encoder']}"
                f"_epoch{BASE_CONFIG['epochs']}_bs{BASE_CONFIG['batch_size']}_lr{method_config['lr']}_results.json"
            )
            result_filepath = os.path.join(output_dir, result_filename)
            
            with open(result_filepath, 'w', encoding='utf-8') as f:
                json.dump(results_for_method, f, ensure_ascii=False, indent=4)
            
            print(f"\nâœ… å®éªŒç³»åˆ—ç»“æœå·²ä¿å­˜åˆ°: {result_filepath}")

    print("\n\nğŸ‰ æ‰€æœ‰å®éªŒå·²å®Œæˆï¼")