import pandas as pd
from Tree_data_model import PostStorage
from cl_training import DynamicContrastiveTrainer

def main_training_pipeline():
    print("å¼€å§‹è®­ç»ƒæµç¨‹...")
    # 1. å‡†å¤‡æ•°æ®
    try:
        comment_df = pd.read_csv('data/cl_data/train_comments_filtered.csv', encoding='utf-8')
        post_df = pd.read_csv('data/cl_data/train_posts_filtered.csv', encoding='utf-8')
    except FileNotFoundError:
        print("é”™è¯¯: comments_data.csv æˆ– contents_data.csv æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ã€‚")
        return      
    

    # ç¡®ä¿ note_id å’Œ comment_id æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä»¥é¿å…åç»­é—®é¢˜
    comment_df['note_id'] = comment_df['note_id'].astype(str)
    comment_df['comment_id'] = comment_df['comment_id'].astype(str)
    comment_df['parent_comment_id'] = comment_df['parent_comment_id'].astype(str)
    post_df['note_id'] = post_df['note_id'].astype(str)


    storage = PostStorage()
    # ç¡®ä¿å¸–å­å†…å®¹æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚æœ title ä¸å­˜åœ¨ï¼Œå°è¯• contentï¼Œå¦‚æœéƒ½ä¸ºç©ºï¼Œåˆ™ä¸ºç©ºå­—ç¬¦ä¸²
    for _, row in post_df.iterrows():
        post_content = str(row.get('title', '')) or str(row.get('content', '')) # ä¿è¯æ˜¯å­—ç¬¦ä¸²
        storage.add_post(post_id=str(row['note_id']), post_content=post_content)

    for _, row in comment_df.iterrows():
        post_id_str = str(row['note_id'])
        comment_id_str = str(row['comment_id'])
        content_str = str(row.get('content', '')) # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²
        parent_id_str = str(row['parent_comment_id']) if str(row['parent_comment_id']) != '0' else post_id_str
        
        try:
            storage.add_comment_to_post(post_id_str, comment_id_str, content_str, parent_id_str)
        except Exception as e:
            print(f"æ’å…¥è¯„è®ºå¤±è´¥: {e}, å¸–å­ID: {post_id_str}, è¯„è®ºID: {comment_id_str}")

    # 2. é€‰æ‹©è®­ç»ƒæ¨¡å‹ç±»å‹å¹¶é…ç½®è®­ç»ƒå™¨
    common_trainer_params = {
        'post_storage': storage,
        'pruning_model_path': "google-bert/bert-base-chinese", # 
        'similarity_threshold': 0.75, # è°ƒæ•´é˜ˆå€¼
        'num_negatives': 8,      # å¢åŠ è´Ÿæ ·æœ¬æ•°é‡
        'batch_size': 8,        # è°ƒæ•´æ‰¹é‡å¤§å°
        'pruning_inference_batch_size': 16, # <--- ä¸ºå‰ªææ¨¡å‹æ¨æ–­è®¾ç½®ä¸€ä¸ªåˆç†çš„æ‰¹å¤§å°
        'base_lr': 5e-6,         # è°ƒæ•´å­¦ä¹ ç‡
        'projection_lr': 5e-5,
        'use_weighted_loss': True,
        'loss_weights': {'dataset1': 1, 'dataset2': 0}, # è°ƒæ•´æƒé‡
        'adaptive_weighting': False, # å¯ç”¨è‡ªé€‚åº”æƒé‡
        'infonce_mode': 'bidirectional', # åŒå‘å¯¹æ¯”
        'projection_head_config': {'hidden_dim': 768, 'output_dim': 384, 'dropout_rate': 0.15}, # è°ƒæ•´æŠ•å½±å¤´
        'min_subtree_size_ds1': 2, 'max_samples_per_post_ds1': None,
        'min_subtree_size_ds2': 100000, 'max_samples_per_subtree_ds2': None,

        # --- æ–°å¢PEFTé…ç½® ---
        'use_peft': True,  # è®¾ç½®ä¸º True æ¥å¯ç”¨ LoRA
        'peft_config': {
            'r': 8,              # LoRAçš„ç§©ï¼Œè¶Šå°å‚æ•°è¶Šå°‘ï¼Œå¸¸ç”¨8, 16, 32
            'lora_alpha': 16,    # LoRAçš„ç¼©æ”¾å› å­ï¼Œé€šå¸¸æ˜¯rçš„ä¸¤å€
            'target_modules': ["query", "key", "value"], # å¯¹æ³¨æ„åŠ›çš„Q,K,Våº”ç”¨
            'lora_dropout': 0.1, # LoRAå±‚çš„dropoutç‡
            'bias': "none",      # "none", "all", "lora_only"
        },
        
        # --- æ–°å¢ï¼šæ­£è´Ÿæ ·æœ¬å¯¹æ„é€ ç­–ç•¥é€‰æ‹© ---
        'positive_pair_strategy': 'simcse_dropout',  # å¯é€‰: 'comment_reply', 'simcse_dropout', 'hybrid'
        'simcse_temperature': 0.07,  # SimCSEçš„æ¸©åº¦å‚æ•°
        'simcse_remove_duplicates': True,  # æ–°å¢ï¼šæ˜¯å¦å»é‡ç›¸åŒæ–‡æœ¬
        'hybrid_ratio': 0.5,  # æ··åˆç­–ç•¥ä¸­SimCSE vs è¯„è®ºå›å¤çš„æ¯”ä¾‹ (0.0-1.0)
        # ---------------------------------------
    }

    # æ ¹æ®é€‰æ‹©çš„ç­–ç•¥æ‰“å°ä¿¡æ¯
    strategy = common_trainer_params['positive_pair_strategy']
    print(f"\næ­£æ ·æœ¬å¯¹æ„é€ ç­–ç•¥: {strategy}")
    if strategy == 'comment_reply':
        print("   - ä½¿ç”¨è¯„è®º-å›å¤å…³ç³»æ„é€ æ­£æ ·æœ¬å¯¹")
        print("   - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦è¿‡æ»¤")
    elif strategy == 'simcse_dropout':
        print("   - ä½¿ç”¨SimCSE dropoutç­–ç•¥æ„é€ æ­£æ ·æœ¬å¯¹")
        print("   - å……åˆ†åˆ©ç”¨æ‰€æœ‰æ–‡æœ¬ï¼šçˆ¶è¯„è®º+å­è¯„è®º")
        print("   - åŒä¸€æ–‡æœ¬é€šè¿‡ä¸åŒdropoutç”Ÿæˆæ­£æ ·æœ¬å¯¹")
        print(f"   - æ¸©åº¦å‚æ•°: {common_trainer_params['simcse_temperature']}")
        print(f"   - å»é‡è®¾ç½®: {common_trainer_params['simcse_remove_duplicates']}")
    elif strategy == 'hybrid':
        print("   - ä½¿ç”¨æ··åˆç­–ç•¥æ„é€ æ­£æ ·æœ¬å¯¹")
        print(f"   - SimCSEæ¯”ä¾‹: {common_trainer_params['hybrid_ratio']}")
        print(f"   - è¯„è®ºå›å¤æ¯”ä¾‹: {1 - common_trainer_params['hybrid_ratio']}")
    print()

    # é€‰é¡¹ 1: ModelScope æ¨¡å‹
    print("\n--- é…ç½® ModelScope æ¨¡å‹è®­ç»ƒ ---")
    trainer = DynamicContrastiveTrainer(
        training_model_type='modelscope',
        # ä½¿ç”¨å¦ä¸€ä¸ªModelScopeæ¨¡å‹ä½œä¸ºè®­ç»ƒç›®æ ‡
        training_model_identifier_or_path="google-bert/bert-base-chinese",
        **common_trainer_params
    )

    # # é€‰é¡¹ 2: è‡ªå®šä¹‰ TextCNN
    # print("\n--- é…ç½® TextCNN è®­ç»ƒ ---")
    # textcnn_specific_config = {
    #     'embedding_dim': 300,       
    #     'num_filters': 128,         
    #     'filter_sizes': [2, 3, 4],  
    #     'model_dropout_rate': 0.1,  
    #     'max_seq_length': 200,      # TextCNNåˆ†è¯å™¨çš„æœ€å¤§åºåˆ—é•¿åº¦
    #     'textcnn_output_dim': 768,  # TextCNNè¾“å‡ºç»´åº¦ (ä¸æŠ•å½±å¤´è¾“å‡ºåŒ¹é…æˆ–ä½œä¸ºå…¶è¾“å…¥)
    #     'min_vocab_freq': 1         # è¯æ±‡è¡¨æœ€å°è¯é¢‘
    # }
    
    # ç¡®ä¿ TextCNN çš„è¾“å‡ºç»´åº¦ä¸æŠ•å½±å¤´çš„è¾“å…¥ç»´åº¦åŒ¹é…
    # common_trainer_params['projection_head_config']['hidden_dim'] å¯ä»¥åŸºäº textcnn_output_dim
    # æˆ–è€… textcnn_output_dim ç›´æ¥ä½œä¸ºæŠ•å½±å¤´çš„è¾“å…¥
    # è¿™é‡Œå‡è®¾ textcnn_output_dim æ˜¯æŠ•å½±å¤´çš„è¾“å…¥ï¼Œæ‰€ä»¥ base_dim ä¼šæ˜¯ textcnn_output_dim

    # trainer = DynamicContrastiveTrainer(
    #     training_model_type='textcnn',
    #     training_model_identifier_or_path="model/my_custom_textcnn_v4_no_pruning_paircl", # è‡ªå®šä¹‰æ¨¡å‹æ ‡è¯†ç¬¦
    #     textcnn_config=textcnn_specific_config,
    #     **common_trainer_params
    # )
    
    # 3. å¼€å§‹è®­ç»ƒ
    print("\n--- å¼€å§‹è®­ç»ƒ ---")
    trainer.train(
        num_epochs=200, # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œå‡å°‘äº†epochï¼ŒåŸä¸º100
        rebuild_frequency=200,  # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œå‡å°‘äº†é¢‘ç‡ï¼ŒåŸä¸º200
        scheduler_patience=7, # åŸä¸º2
        min_improvement=1e-5
    )
    
    print("è®­ç»ƒæµç¨‹å®Œæˆ!")
    
    # æ˜¾ç¤ºå®éªŒä¿å­˜ä¿¡æ¯
    model_name = trainer.training_model_identifier_or_path.replace('/', '_').replace('-', '_')
    strategy_name = trainer.positive_pair_strategy
    if trainer.positive_pair_strategy == 'hybrid':
        strategy_name = f"hybrid_ratio{trainer.hybrid_ratio}"
    similarity_str = str(trainer.similarity_threshold).replace('.', 'p')
    experiment_folder = f"{model_name}_{strategy_name}_sim{similarity_str}"
    
    print(f"å®éªŒç»“æœå·²ä¿å­˜åˆ°: model/{experiment_folder}/")
    print(f"å®éªŒé…ç½®:")
    print(f"   - æ¨¡å‹: {trainer.training_model_identifier_or_path}")
    print(f"   - ç­–ç•¥: {trainer.positive_pair_strategy}")
    print(f"   - ç›¸ä¼¼åº¦é˜ˆå€¼: {trainer.similarity_threshold}")
    print(f"   - æ–‡ä»¶å¤¹: {experiment_folder}")
    print(f"åŸºç¡€æ¨¡å‹ä½äº: model/{experiment_folder}/trained_{trainer.training_model_type}_embedding_model/")


def run_stage1_contrastive_training(config: dict, output_dir: str, full_config: dict = None) -> str:
    """
    æ ‡å‡†åŒ–æ¥å£ï¼šè¿è¡ŒStage 1å¯¹æ¯”å­¦ä¹ è®­ç»ƒï¼ˆæ”¯æŒè¶…å‚æ•°ç½‘æ ¼æœç´¢ï¼‰

    Args:
        config: Stage 1é…ç½®å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        full_config: å®Œæ•´é…ç½®å­—å…¸ï¼ˆåŒ…å« supervised_learning ç­‰ï¼Œç”¨äº Grid Search è¯„ä¼°ï¼‰

    Returns:
        æœ€ä½³æ¨¡å‹è·¯å¾„
    """
    import sys
    import os
    import pickle
    import shutil
    from argparse import Namespace
    import pandas as pd
    from Tree_data_model import PostStorage
    import itertools
    import json
    import torch

    print(f"[Stage 1] Stage 1å¯¹æ¯”å­¦ä¹ æ¥å£è°ƒç”¨")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")

    # ========== æ£€æµ‹æ˜¯å¦éœ€è¦è¶…å‚æ•°ç½‘æ ¼æœç´¢ ==========
    hyperparams_to_search = {
        'infonce_temperature': config.get('infonce_temperature', [0.07]),
        'simcse_temperature': config.get('simcse_temperature', [0.07]),
        'base_lr': config.get('base_lr', [5e-5]),
        'projection_lr': config.get('projection_lr', [5e-4]),
        'epochs': config.get('epochs', [100]),
        'batch_size': config.get('batch_size', [16])
    }

    # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå¹¶è½¬æ¢ç±»å‹
    for key in hyperparams_to_search:
        if not isinstance(hyperparams_to_search[key], list):
            hyperparams_to_search[key] = [hyperparams_to_search[key]]

        # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®ï¼ˆé˜²æ­¢ YAML ä¸­çš„ç§‘å­¦è®¡æ•°æ³•è¢«è§£æä¸ºå­—ç¬¦ä¸²ï¼‰
        if key in ['base_lr', 'projection_lr', 'infonce_temperature', 'simcse_temperature']:
            hyperparams_to_search[key] = [float(v) for v in hyperparams_to_search[key]]
        elif key in ['epochs', 'batch_size']:
            hyperparams_to_search[key] = [int(v) for v in hyperparams_to_search[key]]

    # è®¡ç®—æ€»æœç´¢æ¬¡æ•°
    param_combinations = list(itertools.product(
        hyperparams_to_search['infonce_temperature'],
        hyperparams_to_search['simcse_temperature'],
        hyperparams_to_search['base_lr'],
        hyperparams_to_search['projection_lr'],
        hyperparams_to_search['epochs'],
        hyperparams_to_search['batch_size']
    ))

    total_runs = len(param_combinations)

    if total_runs > 1:
        print(f"\nğŸ” æ£€æµ‹åˆ°è¶…å‚æ•°ç½‘æ ¼æœç´¢æ¨¡å¼")
        print(f"   å‚æ•°ç»„åˆæ•°: {total_runs}")
        print(f"   æœç´¢å‚æ•°:")
        for key, values in hyperparams_to_search.items():
            if len(values) > 1:
                print(f"     - {key}: {values}")
    else:
        print(f"\nğŸ“Œ å•æ¬¡è®­ç»ƒæ¨¡å¼")

    # ========== å¦‚æœåªæœ‰ä¸€æ¬¡è¿è¡Œï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘ ==========
    if total_runs == 1:
        return _run_single_stage1_training(config, output_dir)

    # ========== æ£€æŸ¥æ˜¯å¦æœ‰ full_configï¼ˆGrid Search éœ€è¦ï¼‰ ==========
    if full_config is None:
        print("\nâš ï¸  è­¦å‘Š: Grid Search æ¨¡å¼ä½†æœªæä¾› full_config")
        print("   å°†æ— æ³•è¿è¡Œ Topic Pair è¯„ä¼°å’Œ Supervised Training")
        print("   å¦‚éœ€å®Œæ•´è¯„ä¼°ï¼Œè¯·åœ¨è°ƒç”¨æ—¶ä¼ å…¥ full_config å‚æ•°")
        print("   ç»§ç»­è¿è¡Œ Grid Searchï¼ˆä»…åŸºäº loss é€‰æ‹©ï¼‰...\n")

    # ========== è¶…å‚æ•°ç½‘æ ¼æœç´¢ ==========
    print(f"\nğŸš€ å¼€å§‹è¶…å‚æ•°ç½‘æ ¼æœç´¢...")

    # æ ¹æ®æ˜¯å¦æœ‰ full_config è°ƒæ•´æç¤ºä¿¡æ¯
    if full_config is not None:
        print(f"   æ¯ä¸ªç»„åˆå°†è¿è¡Œ: CLè®­ç»ƒ + å¿«é€ŸSupervised Trainingï¼ˆä»…éªŒè¯é›†ï¼‰")
        print(f"   é€‰æ‹©æ ‡å‡†: Val F1ï¼ˆéªŒè¯é›†F1åˆ†æ•°ï¼‰")
        print(f"   é¢„è®¡æ—¶é—´: {total_runs * 1.0:.1f}-{total_runs * 1.5:.1f} å°æ—¶\n")
    else:
        print(f"   æ¯ä¸ªç»„åˆå°†è¿è¡Œ: CLè®­ç»ƒ")
        print(f"   é€‰æ‹©æ ‡å‡†: è®­ç»ƒ Lossï¼ˆé™çº§æ¨¡å¼ï¼‰")
        print(f"   é¢„è®¡æ—¶é—´: {total_runs * 0.8:.1f}-{total_runs * 1.0:.1f} å°æ—¶\n")

    all_results = []
    best_auc = -1.0  # è¿½è¸ªæœ€ä½³ Val F1ï¼ˆå¤ç”¨å˜é‡å best_aucï¼‰
    best_loss = float('inf')  # è¿½è¸ªæœ€ä½³ lossï¼ˆé™çº§æ¨¡å¼ï¼‰
    best_model_path = None
    best_result = None

    for run_idx, (infonce_temp, simcse_temp, base_lr, proj_lr, epochs, batch_size) in enumerate(param_combinations, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ è¿è¡Œ {run_idx}/{total_runs}")
        print(f"   infonce_temperature={infonce_temp}, simcse_temperature={simcse_temp}")
        print(f"   base_lr={base_lr}, projection_lr={proj_lr}")
        print(f"   epochs={epochs}, batch_size={batch_size}")
        print(f"{'='*80}\n")

        # åˆ›å»ºå­ç›®å½•
        run_name = f"run{run_idx}_infotau{infonce_temp}_simtau{simcse_temp}_blr{float(base_lr):.0e}_plr{float(proj_lr):.0e}_ep{epochs}_bs{batch_size}"
        run_output_dir = os.path.join(output_dir, 'grid_search', run_name)
        os.makedirs(run_output_dir, exist_ok=True)

        # åˆ›å»ºæœ¬æ¬¡è¿è¡Œçš„é…ç½®
        run_config = config.copy()
        run_config['infonce_temperature'] = infonce_temp
        run_config['simcse_temperature'] = simcse_temp
        run_config['base_lr'] = base_lr
        run_config['projection_lr'] = proj_lr
        run_config['epochs'] = epochs
        run_config['batch_size'] = batch_size

        try:
            # 1. è¿è¡Œå¯¹æ¯”å­¦ä¹ è®­ç»ƒï¼ˆè½»é‡çº§æ¨¡å¼ï¼šåªä¿å­˜æ¨¡å‹æƒé‡ï¼‰
            print(f"[æ­¥éª¤ 1/2] å¯¹æ¯”å­¦ä¹ è®­ç»ƒï¼ˆè½»é‡çº§æ¨¡å¼ï¼‰...")
            model_path = _run_single_stage1_training(run_config, run_output_dir, lightweight_mode=True)

            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")

            # 2. å¿«é€Ÿ Supervised Training è¯„ä¼°ï¼ˆä»…éªŒè¯é›†ï¼‰
            print(f"\n[æ­¥éª¤ 2/2] å¿«é€Ÿ Supervised Training è¯„ä¼°ï¼ˆä»…éªŒè¯é›†ï¼‰...")
            try:
                if full_config is not None:
                    sup_metrics = _run_quick_supervised_eval(
                        model_path,
                        run_output_dir,
                        full_config  # ä¼ å…¥å®Œæ•´é…ç½®
                    )
                    val_f1 = sup_metrics['val_f1']
                    val_acc = sup_metrics['val_acc']
                    val_precision = sup_metrics['val_precision']
                    val_recall = sup_metrics['val_recall']
                else:
                    print("   è·³è¿‡ï¼ˆæœªæä¾› full_configï¼‰")
                    val_f1 = 0.0
                    val_acc = 0.0
                    val_precision = 0.0
                    val_recall = 0.0
            except Exception as e:
                print(f"âš ï¸  Supervised Training è¯„ä¼°å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                val_f1 = 0.0
                val_acc = 0.0
                val_precision = 0.0
                val_recall = 0.0

            # âœ… 3. æ¸…ç†æ¨¡å‹æ–‡ä»¶ï¼ˆGrid Search ä¸ä¿å­˜æ¨¡å‹ï¼‰
            print(f"\n[æ¸…ç†] åˆ é™¤æ¨¡å‹æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´...")
            try:
                if os.path.exists(model_path):
                    os.remove(model_path)
                    print(f"   âœ… å·²åˆ é™¤: {os.path.basename(model_path)}")

                # åˆ é™¤ quick_sup_eval ä¸­çš„æ¨¡å‹æ–‡ä»¶
                quick_sup_dir = os.path.join(run_output_dir, 'quick_sup_eval', 'saved_models')
                if os.path.exists(quick_sup_dir):
                    shutil.rmtree(quick_sup_dir)
                    print(f"   âœ… å·²åˆ é™¤: quick_sup_eval/saved_models/")

                # åˆ é™¤ç¼–ç å™¨ç¼“å­˜ï¼ˆå¦‚æœæœ‰ï¼‰
                cache_dir = os.path.join(run_output_dir, 'quick_sup_eval', 'encoder_cache')
                if os.path.exists(cache_dir):
                    shutil.rmtree(cache_dir)
                    print(f"   âœ… å·²åˆ é™¤: encoder_cache/")

            except Exception as e:
                print(f"   âš ï¸  æ¸…ç†å¤±è´¥: {e}")

            # 5. è®°å½•ç»“æœï¼ˆä¸åŒ…å« model_pathï¼‰
            result = {
                'run_idx': run_idx,
                'hyperparameters': {
                    'infonce_temperature': infonce_temp,
                    'simcse_temperature': simcse_temp,
                    'base_lr': base_lr,
                    'projection_lr': proj_lr,
                    'epochs': epochs,
                    'batch_size': batch_size
                },

                # éªŒè¯é›†æŒ‡æ ‡ï¼ˆGrid Search åªç”¨éªŒè¯é›†ï¼‰
                'val_f1': val_f1,
                'val_accuracy': val_acc,
                'val_precision': val_precision,
                'val_recall': val_recall,

                'status': 'success'
            }

            all_results.append(result)

            # 6. æ›´æ–°æœ€ä½³ç»“æœï¼ˆåªè®°å½•è¶…å‚æ•°ï¼Œä¸è®°å½•æ¨¡å‹è·¯å¾„ï¼‰
            if full_config is not None:
                # å®Œæ•´æ¨¡å¼ï¼šåŸºäº Val F1 é€‰æ‹©
                if val_f1 > best_auc:  # å˜é‡åä¿ç•™ best_aucï¼Œä½†å®é™…å­˜å‚¨çš„æ˜¯ best_val_f1
                    best_auc = val_f1
                    best_result = result
                    print(f"\nâœ¨ æ–°çš„æœ€ä½³ Val F1: {best_auc:.4f}")
            else:
                # é™çº§æ¨¡å¼ï¼šåŸºäº loss é€‰æ‹©ï¼ˆä»è¯„ä¼°å‰çš„ checkpoint è¯»å–ï¼‰
                print(f"\nâš ï¸  é™çº§æ¨¡å¼ä¸æ”¯æŒï¼ˆéœ€è¦ full_configï¼‰")

        except Exception as e:
            print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            all_results.append({
                'run_idx': run_idx,
                'hyperparameters': {
                    'infonce_temperature': infonce_temp,
                    'simcse_temperature': simcse_temp,
                    'base_lr': base_lr,
                    'projection_lr': proj_lr,
                    'epochs': epochs,
                    'batch_size': batch_size
                },
                'val_f1': 0.0,
                'val_accuracy': 0.0,
                'val_precision': 0.0,
                'val_recall': 0.0,
                'status': 'error',
                'error': str(e)
            })

    # ========== ä¿å­˜ç½‘æ ¼æœç´¢ç»“æœ ==========
    print(f"\n{'='*80}")
    print("ğŸ“Š ç½‘æ ¼æœç´¢å®Œæˆï¼Œä¿å­˜ç»“æœ...")
    print(f"{'='*80}\n")

    # ç”Ÿæˆ JSON ç»“æœ
    results_summary = {
        'total_runs': total_runs,
        'successful_runs': sum(1 for r in all_results if r['status'] == 'success'),
        'failed_runs': sum(1 for r in all_results if r['status'] != 'success'),
        'evaluation_mode': 'validation_only',  # Grid Search åªä½¿ç”¨éªŒè¯é›†

        # âœ… åŸºäº Val F1 çš„æœ€ä½³è¶…å‚æ•°
        'best_hyperparameters': {
            'val_f1': best_auc,  # best_auc å®é™…å­˜å‚¨çš„æ˜¯ best_val_f1
            'run_idx': best_result['run_idx'] if best_result else None,
            'hyperparameters': best_result['hyperparameters'] if best_result else {},
            'validation_metrics': {
                'val_f1': best_result['val_f1'] if best_result else 0.0,
                'val_accuracy': best_result['val_accuracy'] if best_result else 0.0,
                'val_precision': best_result['val_precision'] if best_result else 0.0,
                'val_recall': best_result['val_recall'] if best_result else 0.0
            }
        } if best_result and full_config is not None else None,

        'all_results': all_results,
        'hyperparameter_space': hyperparams_to_search
    }

    # ä¿å­˜ JSON
    results_json_path = os.path.join(output_dir, 'grid_search_results.json')
    with open(results_json_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)

    # ç”Ÿæˆ CSVï¼ˆæ–¹ä¾¿ Excel æŸ¥çœ‹ï¼‰
    import csv
    csv_path = os.path.join(output_dir, 'grid_search_results.csv')
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)

        # è¡¨å¤´ï¼ˆåªåŒ…å«éªŒè¯é›†æŒ‡æ ‡ï¼‰
        writer.writerow([
            'run_idx',
            'infonce_temp', 'simcse_temp', 'base_lr', 'epochs', 'batch_size',
            'val_f1', 'val_acc', 'val_precision', 'val_recall',
            'status'
        ])

        # æ•°æ®è¡Œ
        for r in all_results:
            if r['status'] == 'success':
                hp = r['hyperparameters']
                writer.writerow([
                    r['run_idx'],
                    hp['infonce_temperature'], hp['simcse_temperature'],
                    hp['base_lr'],
                    hp['epochs'], hp['batch_size'],
                    r['val_f1'],
                    r['val_accuracy'],
                    r['val_precision'],
                    r['val_recall'],
                    r['status']
                ])
            else:
                hp = r['hyperparameters']
                writer.writerow([
                    r['run_idx'],
                    hp['infonce_temperature'], hp['simcse_temperature'],
                    hp['base_lr'],
                    hp['epochs'], hp['batch_size'],
                    'FAILED', 'FAILED', 'FAILED', 'FAILED',
                    f"error: {r.get('error', 'Unknown error')}"
                ])

    print(f"âœ… ç»“æœå·²ä¿å­˜:")
    print(f"   JSON: {results_json_path}")
    print(f"   CSV:  {csv_path}")

    # æ‰“å°æœ€ä½³ç»“æœ
    if best_result:
        if full_config is not None:
            # åªæ˜¾ç¤ºéªŒè¯é›†æŒ‡æ ‡
            print(f"\nğŸ† æœ€ä½³è¶…å‚æ•°ç»„åˆ (åŸºäº Val F1):")
            print(f"   Run: {best_result['run_idx']}")
            print(f"   Val F1: {best_result['val_f1']:.4f}")
            print(f"   Val Accuracy: {best_result['val_accuracy']:.4f}")
            print(f"   Val Precision: {best_result['val_precision']:.4f}")
            print(f"   Val Recall: {best_result['val_recall']:.4f}")
        else:
            # é™çº§æ¨¡å¼
            print(f"\nğŸ† æœ€ä½³è¶…å‚æ•°ç»„åˆ:")
            print(f"   Run: {best_result['run_idx']}")
            print(f"   âš ï¸  æ³¨æ„ï¼šæœªè¿è¡ŒéªŒè¯é›†è¯„ä¼°")

        print(f"   è¶…å‚æ•°:")
        for key, value in best_result['hyperparameters'].items():
            print(f"     - {key}: {value}")

    # âœ… Grid Search å®Œæˆï¼Œç›´æ¥è¿”å›ç»“æœ
    print(f"\n{'='*80}")
    print(f"âœ… Grid Search å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜:")
    print(f"   - {results_json_path}")
    print(f"   - {csv_path}")
    print(f"\nğŸ’¡ ä½¿ç”¨æ‰«æå·¥å…·æŸ¥çœ‹è¯¦ç»†ç»“æœ:")
    print(f"   python scan_grid_search_results.py {output_dir}")
    print(f"{'='*80}\n")

    # âœ… è¿”å›ç»“æœæ±‡æ€»ï¼ˆä¸è¿”å›æ¨¡å‹è·¯å¾„ï¼‰
    return {
        'mode': 'grid_search',
        'total_runs': total_runs,
        'successful_runs': sum(1 for r in all_results if r['status'] == 'success'),
        'best_hyperparameters': best_result['hyperparameters'] if best_result else None,
        'best_metrics': {
            'val_f1': best_result['val_f1'] if best_result else 0.0,
            'val_accuracy': best_result['val_accuracy'] if best_result else 0.0,
            'val_precision': best_result['val_precision'] if best_result else 0.0,
            'val_recall': best_result['val_recall'] if best_result else 0.0
        } if best_result else None,
        'results_file': results_json_path
    }


def _run_single_stage1_training(config: dict, output_dir: str, lightweight_mode: bool = False) -> str:
    """
    è¿è¡Œå•æ¬¡ Stage 1 å¯¹æ¯”å­¦ä¹ è®­ç»ƒï¼ˆå†…éƒ¨å‡½æ•°ï¼‰

    Args:
        config: Stage 1é…ç½®å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        lightweight_mode: è½»é‡çº§æ¨¡å¼ï¼ˆGrid Searchç”¨ï¼Œåªä¿å­˜æ¨¡å‹æƒé‡ï¼‰

    Returns:
        æ¨¡å‹è·¯å¾„
    """
    import sys
    import os
    import pickle
    from argparse import Namespace
    import pandas as pd
    from Tree_data_model import PostStorage

    print(f"[Stage 1] å•æ¬¡è®­ç»ƒæ¨¡å¼")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")

    # æ„å»ºPostStorageå¯¹è±¡
    print("åŠ è½½å¯¹æ¯”å­¦ä¹ æ•°æ®...")

    # ä»é…ç½®è·å–æ•°æ®è·¯å¾„
    comments_path = config.get('cl_comments_data', 'data/cl_data/train_comments_filtered.csv')
    posts_path = config.get('cl_posts_data', 'data/cl_data/train_posts_filtered.csv')

    try:
        comment_df = pd.read_csv(comments_path, encoding='utf-8')
        post_df = pd.read_csv(posts_path, encoding='utf-8')
        print(f"   [æˆåŠŸ] åŠ è½½è¯„è®ºæ•°æ®: {len(comment_df)} æ¡")
        print(f"   [æˆåŠŸ] åŠ è½½å¸–å­æ•°æ®: {len(post_df)} æ¡")
    except FileNotFoundError as e:
        print(f"[é”™è¯¯] æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        raise

    # ç¡®ä¿IDå­—æ®µæ˜¯å­—ç¬¦ä¸²ç±»å‹
    comment_df['note_id'] = comment_df['note_id'].astype(str)
    comment_df['comment_id'] = comment_df['comment_id'].astype(str)
    comment_df['parent_comment_id'] = comment_df['parent_comment_id'].astype(str)
    post_df['note_id'] = post_df['note_id'].astype(str)

    # æ„å»ºPostStorage
    storage = PostStorage()

    # æ·»åŠ å¸–å­
    for _, row in post_df.iterrows():
        post_content = str(row.get('title', '')) or str(row.get('content', ''))
        storage.add_post(post_id=str(row['note_id']), post_content=post_content)

    # æ·»åŠ è¯„è®º
    for _, row in comment_df.iterrows():
        post_id_str = str(row['note_id'])
        comment_id_str = str(row['comment_id'])
        content_str = str(row.get('content', ''))
        parent_id_str = str(row['parent_comment_id']) if str(row['parent_comment_id']) != '0' else post_id_str

        try:
            storage.add_comment_to_post(post_id_str, comment_id_str, content_str, parent_id_str)
        except Exception as e:
            print(f"æ’å…¥è¯„è®ºå¤±è´¥: {e}, å¸–å­ID: {post_id_str}, è¯„è®ºID: {comment_id_str}")

    print(f"   [æˆåŠŸ] PostStorageæ„å»ºå®Œæˆ")

    # æ„é€ å‚æ•°
    args = Namespace(
        # æ•°æ®ç›¸å…³ï¼ˆä¸å†éœ€è¦tree_data_pathï¼‰
        similarity_threshold=config.get('similarity_threshold', 0.75),
        pruning_model_path=config.get('pruning_model_path', 'google-bert/bert-base-chinese'),
        pruning_inference_batch_size=config.get('pruning_inference_batch_size', 128),
        min_subtree_size_ds1=config.get('min_subtree_size_ds1', 2),
        max_samples_per_post_ds1=config.get('max_samples_per_post_ds1', None),
        min_subtree_size_ds2=config.get('min_subtree_size_ds2', 3),
        max_samples_per_subtree_ds2=config.get('max_samples_per_subtree_ds2', 30),

        # æ¨¡å‹ç›¸å…³
        model_type='modelscope',
        model_name_or_path=config.get('model_name_or_path', 'google-bert/bert-base-chinese'),

        # è®­ç»ƒç›¸å…³
        batch_size=config.get('batch_size', 16),
        epochs=config.get('epochs', 100),
        base_lr=float(config.get('base_lr', 5e-5)),
        projection_lr=float(config.get('projection_lr', 5e-4)),
        warmup_steps=config.get('warmup_steps', 1000),

        # å¯¹æ¯”å­¦ä¹ ç›¸å…³
        positive_pair_strategy=config.get('positive_pair_strategy', 'comment_reply'),
        num_negatives=config.get('num_negatives', 2),
        infonce_mode=config.get('infonce_mode', 'in_batch'),
        infonce_temperature=config.get('infonce_temperature', 0.07),  # InfoNCEæ¸©åº¦ç³»æ•°
        simcse_temperature=config.get('simcse_temperature', 0.07),    # SimCSEæ¸©åº¦ç³»æ•°
        simcse_dropout_rate=config.get('simcse_dropout_rate', 0.1),
        simcse_remove_duplicates=config.get('simcse_remove_duplicates', True),
        hybrid_ratio=config.get('hybrid_ratio', 0.5),
        bidirectional_loss=config.get('bidirectional_loss', True),  # æ–°å¢ï¼šåŒå‘æŸå¤±æ§åˆ¶

        # PEFTç›¸å…³ï¼ˆåŒ…å«å®Œæ•´çš„LoRAé…ç½®ï¼‰
        use_peft=config.get('use_peft', True),
        lora_r=config.get('lora_r', 8),
        lora_alpha=config.get('lora_alpha', 16),
        lora_dropout=config.get('lora_dropout', 0.1),
        lora_target_modules=config.get('lora_target_modules', ["query", "key", "value", "dense"]),
        lora_bias=config.get('lora_bias', 'none'),

        # è¾“å‡ºç›¸å…³
        model_save_name=config.get('model_save_name', 'stage1_cl_model'),
        save_frequency=config.get('save_frequency', 20),

        # å…¶ä»–
        device='auto',
        resume_from=None
    )

    try:
        # è°ƒç”¨åŸæœ‰çš„è®­ç»ƒé€»è¾‘
        from cl_training import DynamicContrastiveTrainer

        # åˆ›å»ºè®­ç»ƒå™¨ï¼Œä½¿ç”¨PostStorage
        trainer = DynamicContrastiveTrainer(
            post_storage=storage,  # ä½¿ç”¨æ„å»ºå¥½çš„PostStorage
            seed=config.get('seed', 42),  # âœ… æ–°å¢ï¼šä»é…ç½®è¯»å–éšæœºç§å­
            training_model_type=args.model_type,
            training_model_identifier_or_path=args.model_name_or_path,
            output_dir=output_dir,  # ä¼ å…¥è¾“å‡ºç›®å½•
            lightweight_mode=lightweight_mode,  # âœ… æ–°å¢ï¼šè½»é‡çº§æ¨¡å¼
            # å‰ªæå’Œæ•°æ®æ„å»ºå‚æ•°
            pruning_model_path=args.pruning_model_path,
            similarity_threshold=args.similarity_threshold,
            pruning_inference_batch_size=args.pruning_inference_batch_size,
            min_subtree_size_ds1=args.min_subtree_size_ds1,
            max_samples_per_post_ds1=args.max_samples_per_post_ds1,
            min_subtree_size_ds2=args.min_subtree_size_ds2,
            max_samples_per_subtree_ds2=args.max_samples_per_subtree_ds2,
            # è®­ç»ƒå‚æ•°
            batch_size=args.batch_size,
            base_lr=args.base_lr,
            projection_lr=args.projection_lr,
            # å¯¹æ¯”å­¦ä¹ å‚æ•°
            positive_pair_strategy=args.positive_pair_strategy,
            num_negatives=args.num_negatives,
            infonce_mode=args.infonce_mode,
            infonce_temperature=args.infonce_temperature,  # InfoNCEæ¸©åº¦ç³»æ•°
            simcse_temperature=args.simcse_temperature,    # SimCSEæ¸©åº¦ç³»æ•°
            simcse_dropout_rate=args.simcse_dropout_rate,
            simcse_remove_duplicates=args.simcse_remove_duplicates,
            hybrid_ratio=args.hybrid_ratio,
            bidirectional_loss=args.bidirectional_loss,  # æ–°å¢ï¼šåŒå‘æŸå¤±æ§åˆ¶
            # PEFTå‚æ•°
            use_peft=args.use_peft,
            peft_config={
                'r': args.lora_r,
                'lora_alpha': args.lora_alpha,
                'target_modules': args.lora_target_modules,
                'lora_dropout': args.lora_dropout,
                'bias': args.lora_bias
            } if args.use_peft else None
        )

        # è®­ç»ƒæ¨¡å‹
        trainer.train(
            num_epochs=args.epochs,
            rebuild_frequency=config.get('rebuild_frequency', 200),
            scheduler_patience=config.get('scheduler_patience', 15),  # ä»é…ç½®è¯»å–ï¼Œé»˜è®¤15
            min_improvement=float(config.get('min_improvement', 1e-5))  # ç¡®ä¿æ˜¯æµ®ç‚¹æ•°
        )

        # ä¿å­˜ç”Ÿæˆçš„æ•°æ®é›†åˆ°å®éªŒç›®å½•ï¼ˆä»…éè½»é‡çº§æ¨¡å¼ï¼‰
        if not lightweight_mode:
            if hasattr(trainer, 'dataset1') and trainer.dataset1:
                dataset_path = os.path.join(output_dir, f'dataset1_sim_{args.similarity_threshold}.pkl')
                with open(dataset_path, 'wb') as f:
                    pickle.dump(trainer.dataset1, f)
                print(f"æ•°æ®é›†1å·²ä¿å­˜: {dataset_path}")

            if hasattr(trainer, 'dataset2') and trainer.dataset2:
                dataset_path = os.path.join(output_dir, f'dataset2_sim_{args.similarity_threshold}.pkl')
                with open(dataset_path, 'wb') as f:
                    pickle.dump(trainer.dataset2, f)
                print(f"æ•°æ®é›†2å·²ä¿å­˜: {dataset_path}")
        else:
            print(f"[è½»é‡çº§æ¨¡å¼] è·³è¿‡æ•°æ®é›†ä¿å­˜")

        # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
        best_model_path = os.path.join(output_dir, "best_contrastive_model.pth")
        if not os.path.exists(best_model_path):
            # æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
            for file in os.listdir(output_dir):
                if file.endswith('.pth'):
                    best_model_path = os.path.join(output_dir, file)
                    break

        if lightweight_mode:
            print(f"[è½»é‡çº§æ¨¡å¼] Stage 1è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜ï¼ˆä»…æƒé‡ï¼‰")
        else:
            print(f"[æˆåŠŸ] Stage 1è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜åœ¨: {best_model_path}")

        return best_model_path

    except Exception as e:
        print(f"[é”™è¯¯] Stage 1è®­ç»ƒå¤±è´¥: {e}")
        raise


def _evaluate_topic_pair_auc(
    encoder_path: str,
    run_output_dir: str,
    full_config: dict
) -> dict:
    """
    è¯„ä¼°ç¼–ç å™¨çš„ Topic Pair AUC

    Args:
        encoder_path: ç¼–ç å™¨æ¨¡å‹è·¯å¾„
        run_output_dir: å½“å‰è¿è¡Œçš„è¾“å‡ºç›®å½•
        full_config: å®Œæ•´é…ç½®ï¼ˆåŒ…å« supervised_learningï¼‰

    Returns:
        {
            'auc': float,
            'accuracy': float,
            'best_threshold': float,
            'precision_at_k': {10: float, 50: float, ...}
        }
    """
    import os
    import json
    import torch
    import torch.nn.functional as F
    import numpy as np
    from evaluate_encoder_topic_pairs import (
        load_and_split_data,
        construct_topic_pairs,
        load_encoder,
        encode_texts,
        compute_metrics
    )

    print(f"\n{'='*80}")
    print(f"ğŸ“Š Topic Pair AUC è¯„ä¼°")
    print(f"{'='*80}")

    # ğŸ” è°ƒè¯•ï¼šæ‰“å° full_config çš„ç»“æ„
    print(f"\n[DEBUG] full_config çš„é¡¶å±‚é”®: {list(full_config.keys()) if full_config else 'None'}")
    if full_config:
        if 'defaults' in full_config:
            print(f"[DEBUG] full_config['defaults'] çš„é”®: {list(full_config['defaults'].keys())}")
        if 'supervised_learning' in full_config:
            print(f"[DEBUG] full_config['supervised_learning'] å­˜åœ¨")
        else:
            print(f"[DEBUG] âš ï¸  full_config['supervised_learning'] ä¸å­˜åœ¨")

    # 1. ä» supervised_learning é…ç½®ä¸­æå–æ•°æ®å‚æ•°
    # âœ… ä¿®æ”¹ï¼šå…ˆå°è¯•ä» defaults.supervised_learning è¯»å–ï¼Œå†å°è¯•é¡¶å±‚ supervised_learning
    if 'defaults' in full_config and 'supervised_learning' in full_config['defaults']:
        sup_config = full_config['defaults']['supervised_learning']
        print(f"[INFO] ä» full_config['defaults']['supervised_learning'] è¯»å–é…ç½®")
    elif 'supervised_learning' in full_config:
        sup_config = full_config['supervised_learning']
        print(f"[INFO] ä» full_config['supervised_learning'] è¯»å–é…ç½®")
    else:
        sup_config = {}

    # âœ… éªŒè¯å¿…è¦çš„é…ç½®å‚æ•°æ˜¯å¦å­˜åœ¨
    if not sup_config:
        raise ValueError("é…ç½®é”™è¯¯ï¼šfull_config ä¸­ç¼ºå°‘ 'supervised_learning' é…ç½®ï¼ˆæ—¢ä¸åœ¨é¡¶å±‚ä¹Ÿä¸åœ¨ defaults ä¸­ï¼‰")

    # âœ… ç›´æ¥ä½¿ç”¨ YAML é…ç½®ï¼Œä¸æä¾›ç¡¬ç¼–ç é»˜è®¤å€¼ï¼ˆå¼ºåˆ¶ä» YAML è¯»å–ï¼‰
    eval_config = {
        'train_csv': sup_config.get('train_data_path', 'data/sup_train_data/balanced_trainset.csv'),
        'test_csv': sup_config.get('test_data_path', 'data/sup_train_data/balanced_testset.csv'),

        # âœ… å…³é”®ä¿®æ”¹ï¼šç›´æ¥ä» YAML è¯»å–ï¼Œä¸æä¾›åå¤‡é»˜è®¤å€¼
        'use_fixed_split': sup_config.get('use_fixed_split', True),
        'train_per_label': sup_config.get('train_samples_per_label', 500),
        'val_per_label': sup_config.get('val_samples_per_label'),  # âœ… ç§»é™¤é»˜è®¤å€¼ 200
        'test_per_label': sup_config.get('test_samples_per_label'),
        'use_test_for_val_and_test': sup_config.get('use_test_for_val_and_test', False),
        'split_random_seed': sup_config.get('split_random_seed', 42),
        'validation_split': sup_config.get('validation_split', 0.2)
    }

    # âœ… æ‰“å°å®é™…ä½¿ç”¨çš„é…ç½®ï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"\n[Topic Pair AUC] ä½¿ç”¨çš„æ•°æ®åˆ†å‰²é…ç½®:")
    print(f"  train_per_label: {eval_config['train_per_label']}")
    print(f"  val_per_label: {eval_config['val_per_label']}")
    print(f"  test_per_label: {eval_config['test_per_label']}")
    print(f"  use_fixed_split: {eval_config['use_fixed_split']}")
    print(f"  split_random_seed: {eval_config['split_random_seed']}\n")

    # 2. åŠ è½½æ•°æ®ï¼ˆä¸ supervised training å®Œå…¨ä¸€è‡´çš„åˆ†å‰²ï¼‰
    train_df, dev_df, test_df = load_and_split_data(
        eval_config['train_csv'],
        eval_config['test_csv'],
        eval_config
    )
    print(f"ä½¿ç”¨éªŒè¯é›†: {len(dev_df)} æ¡")

    # 3. æ„é€  topic pairs
    pair_indices, ground_truth, pair_stats = construct_topic_pairs(
        dev_df,
        P_pos=1,
        P_neg=1,
        random_seed=eval_config['split_random_seed'],
        shuffle_order=True
    )

    # 4. åŠ è½½ç¼–ç å™¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    encoder, tokenizer, model_type = load_encoder(encoder_path, device)

    # 5. ç¼–ç æ–‡æœ¬
    texts = dev_df['content'].tolist()
    embeddings = encode_texts(
        texts, encoder, tokenizer, device,
        batch_size=64,
        max_len=256
    )

    # 6. è®¡ç®—ç›¸ä¼¼åº¦
    embeddings_tensor = torch.tensor(embeddings)
    indices1 = [i for i, j in pair_indices]
    indices2 = [j for i, j in pair_indices]

    embeddings1 = embeddings_tensor[indices1]
    embeddings2 = embeddings_tensor[indices2]

    cosine_sim = F.cosine_similarity(embeddings1, embeddings2).numpy()

    # 7. è®¡ç®—æŒ‡æ ‡
    metrics = compute_metrics(ground_truth, cosine_sim, k_values=[10, 50, 100, 500])

    # 8. ä¿å­˜ç»“æœ
    result_path = os.path.join(run_output_dir, 'topic_pair_auc.json')
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)

    print(f"âœ… Topic Pair AUC: {metrics['auc']:.4f}")
    print(f"   Accuracy: {metrics['accuracy']:.4f}")
    print(f"   Precision@100: {metrics['precision_at_k'].get(100, 'N/A')}")

    return metrics


def _run_quick_supervised_eval(
    encoder_path: str,
    run_output_dir: str,
    full_config: dict
) -> dict:
    """
    å¿«é€Ÿç›‘ç£å­¦ä¹ è¯„ä¼°ï¼ˆç”¨äº Grid Searchï¼‰

    ç­–ç•¥ï¼š
    - å†»ç»“ç¼–ç å™¨
    - åªç”¨çº¿æ€§åˆ†ç±»å™¨
    - å›ºå®šè¶…å‚æ•°ï¼ˆå‡å°‘æœç´¢ç©ºé—´ï¼‰
    - å¿«é€Ÿè®­ç»ƒ 10 epoch

    Args:
        encoder_path: ç¼–ç å™¨æ¨¡å‹è·¯å¾„
        run_output_dir: å½“å‰è¿è¡Œçš„è¾“å‡ºç›®å½•
        full_config: å®Œæ•´é…ç½®ï¼ˆåŒ…å« supervised_learningï¼‰

    Returns:
        {
            'val_f1': float,
            'val_acc': float,
            'test_f1': float,
            'test_acc': float
        }
    """
    import os
    import json
    from sup_training import run_supervised_training_interface

    print(f"\n{'='*80}")
    print(f"ğŸš€ å¿«é€Ÿ Supervised Training è¯„ä¼°")
    print(f"{'='*80}")

    # ğŸ” è°ƒè¯•ï¼šæ‰“å° full_config çš„ç»“æ„
    print(f"\n[DEBUG] full_config çš„é¡¶å±‚é”®: {list(full_config.keys()) if full_config else 'None'}")
    if full_config:
        if 'defaults' in full_config:
            print(f"[DEBUG] full_config['defaults'] çš„é”®: {list(full_config['defaults'].keys())}")
        if 'supervised_learning' in full_config:
            print(f"[DEBUG] full_config['supervised_learning'] å­˜åœ¨")
        else:
            print(f"[DEBUG] âš ï¸  full_config['supervised_learning'] ä¸å­˜åœ¨")

    # ä» supervised_learning é…ç½®ä¸­æå–å‚æ•°
    # âœ… ä¿®æ”¹ï¼šå…ˆå°è¯•ä» defaults.supervised_learning è¯»å–ï¼Œå†å°è¯•é¡¶å±‚ supervised_learning
    if 'defaults' in full_config and 'supervised_learning' in full_config['defaults']:
        sup_config = full_config['defaults']['supervised_learning']
        print(f"[INFO] ä» full_config['defaults']['supervised_learning'] è¯»å–é…ç½®")
    elif 'supervised_learning' in full_config:
        sup_config = full_config['supervised_learning']
        print(f"[INFO] ä» full_config['supervised_learning'] è¯»å–é…ç½®")
    else:
        sup_config = {}

    # âœ… éªŒè¯å¿…è¦çš„é…ç½®å‚æ•°æ˜¯å¦å­˜åœ¨
    if not sup_config:
        raise ValueError("é…ç½®é”™è¯¯ï¼šfull_config ä¸­ç¼ºå°‘ 'supervised_learning' é…ç½®ï¼ˆæ—¢ä¸åœ¨é¡¶å±‚ä¹Ÿä¸åœ¨ defaults ä¸­ï¼‰")

    # âœ… æ„é€ å¿«é€Ÿè¯„ä¼°é…ç½®
    # ğŸ“Œ ä¼˜å…ˆä» quick_eval å­é…ç½®è¯»å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼æˆ–ä»å®Œæ•´é…ç½®ä¸­å–ç¬¬ä¸€ä¸ªå€¼

    def _get_first_value(param):
        """æå–å‚æ•°çš„ç¬¬ä¸€ä¸ªå€¼ï¼ˆå¦‚æœæ˜¯åˆ—è¡¨åˆ™å–é¦–å…ƒç´ ï¼Œå¦åˆ™åŸæ ·è¿”å›ï¼‰"""
        if isinstance(param, list) and len(param) > 0:
            return param[0]
        return param

    # âœ… æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ quick_eval ä¸“ç”¨é…ç½®
    quick_eval_config = sup_config.get('quick_eval', {})

    if quick_eval_config:
        print(f"\n[Quick Eval] ä½¿ç”¨ YAML ä¸­çš„ quick_eval ä¸“ç”¨é…ç½®")
    else:
        print(f"\n[Quick Eval] æœªæ‰¾åˆ° quick_eval é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼æˆ–å®Œæ•´é…ç½®çš„ç¬¬ä¸€ä¸ªå€¼")

    quick_config = {
        # æ•°æ®è·¯å¾„
        'train_data_path': sup_config.get('train_data_path', 'data/sup_train_data/balanced_trainset.csv'),
        'test_data_path': sup_config.get('test_data_path', 'data/sup_train_data/balanced_testset.csv'),

        # âœ… æ•°æ®åˆ†å‰²å‚æ•°ï¼ˆç›´æ¥ä» YAML è¯»å–ï¼‰
        'use_fixed_split': sup_config.get('use_fixed_split', True),
        'train_samples_per_label': sup_config.get('train_samples_per_label', 500),
        'val_samples_per_label': sup_config.get('val_samples_per_label'),
        'test_samples_per_label': sup_config.get('test_samples_per_label'),
        'use_test_for_val_and_test': sup_config.get('use_test_for_val_and_test', False),
        'split_random_seed': sup_config.get('split_random_seed', 42),
        'validation_split': sup_config.get('validation_split', 0.2),

        # âœ… è®­ç»ƒè¶…å‚æ•°ï¼ˆä¼˜å…ˆä» quick_eval è¯»å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        'data_fractions': [quick_eval_config.get('data_fraction', 1.0)],
        'epochs': [quick_eval_config.get('epochs', _get_first_value(sup_config.get('epochs', [10])))],
        'batch_size': [quick_eval_config.get('batch_size', _get_first_value(sup_config.get('batch_size', [64])))],
        'learning_rate': [quick_eval_config.get('learning_rate', _get_first_value(sup_config.get('learning_rate', [1e-3])))],
        'seeds': quick_eval_config.get('seeds', [42]),
        'classifier_types': quick_eval_config.get('classifier_types', ['linear']),
        'mlp_hidden_neurons': [quick_eval_config.get('mlp_hidden_neurons', 384)],
        'freeze_encoder': quick_eval_config.get('freeze_encoder', [True]),
        'use_encoder_cache': quick_eval_config.get('use_encoder_cache', True),
        'cache_batch_size': quick_eval_config.get('cache_batch_size', 64),

        # âœ… Grid Search ä¸“ç”¨ï¼šåªåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        'skip_test_eval': True  # æ–°å¢å‚æ•°ï¼Œå‘Šè¯‰ sup_training è·³è¿‡æµ‹è¯•é›†è¯„ä¼°
    }

    # âœ… æ‰“å°å®é™…ä½¿ç”¨çš„é…ç½®ï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"\n[Quick Eval] ä½¿ç”¨çš„æ•°æ®åˆ†å‰²é…ç½®:")
    print(f"  train_samples_per_label: {quick_config['train_samples_per_label']}")
    print(f"  val_samples_per_label: {quick_config['val_samples_per_label']}")
    print(f"  test_samples_per_label: {quick_config['test_samples_per_label']}")
    print(f"  use_fixed_split: {quick_config['use_fixed_split']}")
    print(f"  split_random_seed: {quick_config['split_random_seed']}")

    print(f"\n[Quick Eval] ä½¿ç”¨çš„è®­ç»ƒè¶…å‚æ•°ï¼ˆå›ºå®šå•ä¸€å€¼ï¼‰:")
    print(f"  epochs: {quick_config['epochs'][0]}")
    print(f"  batch_size: {quick_config['batch_size'][0]}")
    print(f"  learning_rate: {quick_config['learning_rate'][0]}")
    print(f"  classifier_type: {quick_config['classifier_types'][0]}")
    print(f"  freeze_encoder: {quick_config['freeze_encoder'][0]}")
    print(f"  è¶…å‚æ•°ç»„åˆæ•°: 1 (å›ºå®šé…ç½®ï¼Œæ— ç½‘æ ¼æœç´¢)\n")

    # è¿è¡Œç›‘ç£å­¦ä¹ 
    sup_output_dir = os.path.join(run_output_dir, 'quick_sup_eval')
    os.makedirs(sup_output_dir, exist_ok=True)

    result = run_supervised_training_interface(
        encoder_path,
        quick_config,
        sup_output_dir
    )

    # æå–å…³é”®æŒ‡æ ‡ï¼ˆåªç”¨éªŒè¯é›†ï¼‰
    metrics = result['metrics']

    # âœ… åªæå–éªŒè¯é›†æŒ‡æ ‡
    output = {
        'val_f1': metrics['dev']['f1_score'],
        'val_acc': metrics['dev']['accuracy'],
        'val_precision': metrics['dev']['precision'],
        'val_recall': metrics['dev']['recall']
    }

    print(f"âœ… Val F1: {output['val_f1']:.4f}, Val Acc: {output['val_acc']:.4f}")

    # âœ… ä¿å­˜ç»“æœåˆ° quick_sup_eval/results.jsonï¼ˆä¾›æ‰«æå·¥å…·ä½¿ç”¨ï¼‰
    results_json_path = os.path.join(sup_output_dir, 'results.json')
    with open(results_json_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"   ç»“æœå·²ä¿å­˜: {results_json_path}")

    return output


if __name__ == "__main__":
    main_training_pipeline()