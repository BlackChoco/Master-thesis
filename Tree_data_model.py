import numpy as np
from typing import List, Callable, Optional, Dict, Tuple
import copy
import torch
from tqdm import tqdm
import random

class CommentNode:
    """
    è¡¨ç¤ºä¸€æ¡è¯„è®ºæˆ–å›å¤çš„èŠ‚ç‚¹ã€‚
    """
    def __init__(self, comment_id, content, parent_id=None):
        self.comment_id = comment_id      # è¯„è®ºå”¯ä¸€ID
        self.content = content            # è¯„è®ºå†…å®¹
        self.parent_id = parent_id        # çˆ¶è¯„è®ºIDï¼ˆæ ¹è¯„è®ºä¸ºNoneæˆ–å¸–å­IDï¼‰
        self.children = []                # å­è¯„è®ºåˆ—è¡¨
        self.embedding = None             # å­˜å‚¨èŠ‚ç‚¹çš„å‘é‡è¡¨ç¤º
        self.similarity_scores = {}       # å­˜å‚¨ä¸å…¶ä»–èŠ‚ç‚¹çš„ç›¸ä¼¼åº¦åˆ†æ•°

    def add_child(self, child_node):
        """
        æ·»åŠ ä¸€ä¸ªå­è¯„è®ºèŠ‚ç‚¹ã€‚
        """
        self.children.append(child_node)
    
    def set_embedding(self, embedding):
        """
        è®¾ç½®èŠ‚ç‚¹çš„å‘é‡è¡¨ç¤º
        """
        self.embedding = embedding
    
    def calculate_similarity(self, other_node, similarity_func=None):
        """
        è®¡ç®—ä¸å¦ä¸€ä¸ªèŠ‚ç‚¹çš„ç›¸ä¼¼åº¦
        
        å‚æ•°:
            other_node: å¦ä¸€ä¸ªCommentNodeå¯¹è±¡
            similarity_func: è‡ªå®šä¹‰ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°ï¼Œé»˜è®¤ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
        
        è¿”å›:
            ç›¸ä¼¼åº¦åˆ†æ•°(0-1ä¹‹é—´)
        """
        if self.embedding is None or other_node.embedding is None:
            raise ValueError("èŠ‚ç‚¹ç¼ºå°‘å‘é‡è¡¨ç¤ºï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦")
        
        if similarity_func is None:
            # é»˜è®¤ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            return self._cosine_similarity(self.embedding, other_node.embedding)
        else:
            return similarity_func(self.embedding, other_node.embedding)
    
    def _cosine_similarity(self, vec1, vec2):
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        """
        vec1_norm = vec1 / np.linalg.norm(vec1)
        vec2_norm = vec2 / np.linalg.norm(vec2)
        return np.dot(vec1_norm, vec2_norm)
    
    def deep_copy(self):
        """
        æ·±åº¦å¤åˆ¶èŠ‚ç‚¹åŠå…¶æ‰€æœ‰å­èŠ‚ç‚¹
        """
        copied_node = CommentNode(self.comment_id, self.content, self.parent_id)
        copied_node.embedding = self.embedding.copy() if self.embedding is not None else None
        copied_node.similarity_scores = self.similarity_scores.copy()
        
        for child in self.children:
            copied_child = child.deep_copy()
            copied_node.add_child(copied_child)
        
        return copied_node

class ForestManager:
    """
    ç®¡ç†å‰ªè¾¹åäº§ç”Ÿçš„å¤šæ£µå­æ ‘çš„æ£®æ—
    """
    def __init__(self, original_post_tree=None):
        self.original_post_tree = original_post_tree  # åŸå§‹å¸–å­æ ‘
        self.subtrees = []  # å­˜å‚¨æ‰€æœ‰å­æ ‘ï¼ˆä¸€çº§è¯„è®ºåŠå…¶å­æ ‘ï¼‰
        self.cut_edges = []  # å­˜å‚¨è¢«å‰ªæ‰çš„è¾¹ä¿¡æ¯
        self.similarity_threshold = 0.0  # ç›¸ä¼¼åº¦é˜ˆå€¼
    
    def add_subtree(self, subtree_root, original_parent_id=None):
        """
        æ·»åŠ ä¸€æ£µå­æ ‘åˆ°æ£®æ—
        """
        subtree_info = {
            'root': subtree_root,
            'original_parent_id': original_parent_id,
            'size': self._count_nodes(subtree_root),
            'depth': self._get_tree_depth(subtree_root)
        }
        self.subtrees.append(subtree_info)
    
    def record_cut_edge(self, parent_id, child_id, similarity_score, reason="low_similarity"):
        """
        è®°å½•è¢«å‰ªæ‰çš„è¾¹ä¿¡æ¯
        
        å‚æ•°:
            parent_id: çˆ¶èŠ‚ç‚¹ID
            child_id: å­èŠ‚ç‚¹ID  
            similarity_score: ç›¸ä¼¼åº¦åˆ†æ•°
            reason: å‰ªè¾¹åŸå› 
        """
        edge_info = {
            'parent_id': parent_id,
            'child_id': child_id,
            'similarity_score': similarity_score,
            'threshold': self.similarity_threshold,
            'reason': reason,
            'timestamp': None  # å¯ä»¥æ·»åŠ æ—¶é—´æˆ³
        }
        self.cut_edges.append(edge_info)
    
    def get_subtree_count(self):
        """è·å–å­æ ‘æ•°é‡"""
        return len(self.subtrees)
    
    def get_subtree_by_index(self, index):
        """é€šè¿‡ç´¢å¼•è·å–å­æ ‘"""
        if 0 <= index < len(self.subtrees):
            return self.subtrees[index]
        return None
    
    def get_largest_subtrees(self, n=5):
        """è·å–æœ€å¤§çš„næ£µå­æ ‘"""
        sorted_subtrees = sorted(self.subtrees, key=lambda x: x['size'], reverse=True)
        return sorted_subtrees[:n]
    
    def get_cut_edges_count(self):
        """è·å–è¢«å‰ªæ‰çš„è¾¹æ•°é‡"""
        return len(self.cut_edges)
    
    def get_cut_edges_by_similarity_range(self, min_sim=0.0, max_sim=1.0):
        """è·å–æŒ‡å®šç›¸ä¼¼åº¦èŒƒå›´å†…è¢«å‰ªæ‰çš„è¾¹"""
        return [edge for edge in self.cut_edges 
                if min_sim <= edge['similarity_score'] <= max_sim]
    
    def get_cut_edges_statistics(self):
        """è·å–å‰ªè¾¹çš„ç»Ÿè®¡ä¿¡æ¯"""
        if not self.cut_edges:
            return {"error": "æ²¡æœ‰å‰ªè¾¹è®°å½•"}
        
        similarities = [edge['similarity_score'] for edge in self.cut_edges 
                       if edge['similarity_score'] >= 0]  # æ’é™¤æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦çš„æƒ…å†µ
        
        if not similarities:
            return {"error": "æ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼åº¦è®°å½•"}
        
        return {
            'total_cut_edges': len(self.cut_edges),
            'valid_similarity_count': len(similarities),
            'avg_similarity': np.mean(similarities),
            'min_similarity': min(similarities),
            'max_similarity': max(similarities),
            'std_similarity': np.std(similarities),
            'median_similarity': np.median(similarities)
        }
    
    def _count_nodes(self, node):
        """è®¡ç®—èŠ‚ç‚¹æ•°é‡"""
        count = 1
        for child in node.children:
            count += self._count_nodes(child)
        return count
    
    def _get_tree_depth(self, node, depth=0):
        """è®¡ç®—æ ‘çš„æœ€å¤§æ·±åº¦"""
        if not node.children:
            return depth
        return max(self._get_tree_depth(child, depth + 1) for child in node.children)
    
    def get_forest_statistics(self):
        """è·å–æ£®æ—çš„ç»Ÿè®¡ä¿¡æ¯"""
        if not self.subtrees:
            return {}
        
        sizes = [subtree['size'] for subtree in self.subtrees]
        depths = [subtree['depth'] for subtree in self.subtrees]
        
        return {
            'subtree_count': len(self.subtrees),
            'total_nodes': sum(sizes),
            'avg_subtree_size': np.mean(sizes),
            'max_subtree_size': max(sizes),
            'min_subtree_size': min(sizes),
            'avg_depth': np.mean(depths),
            'max_depth': max(depths),
            'cut_edges_count': len(self.cut_edges)
        }
    
    def analyze_node_distribution(self):
        """
        åˆ†ææ£®æ—ä¸­èŠ‚ç‚¹åˆ†å¸ƒæƒ…å†µ
        
        è¿”å›:
            åŒ…å«è¯¦ç»†èŠ‚ç‚¹åˆ†å¸ƒä¿¡æ¯çš„å­—å…¸
        """
        if not self.subtrees:
            return {
                'total_nodes': 0,
                'subtree_count': 0,
                'avg_nodes_per_subtree': 0,
                'max_subtree_size': 0,
                'min_subtree_size': 0,
                'histogram': {},
                'size_distribution': {},
                'detailed_stats': {}
            }
        
        # æ”¶é›†æ‰€æœ‰å­æ ‘çš„èŠ‚ç‚¹æ•°é‡
        tree_sizes = [subtree['size'] for subtree in self.subtrees]
        
        # åŸºæœ¬ç»Ÿè®¡
        total_nodes = sum(tree_sizes)
        subtree_count = len(tree_sizes)
        avg_size = total_nodes / subtree_count
        max_size = max(tree_sizes)
        min_size = min(tree_sizes)
        
        # è®¡ç®—ç›´æ–¹å›¾ - æŒ‰èŠ‚ç‚¹æ•°é‡èŒƒå›´åˆ†ç»„
        histogram_ranges = [1, 2, 3, 5, 10, 20, 50, 100]
        histogram = {}
        
        for i in range(len(histogram_ranges)):
            if i == 0:
                range_key = f"1"
                count = len([s for s in tree_sizes if s == 1])
            elif i == len(histogram_ranges) - 1:
                range_key = f"{histogram_ranges[i]}+"
                count = len([s for s in tree_sizes if s >= histogram_ranges[i]])
            else:
                prev_range = histogram_ranges[i-1]
                curr_range = histogram_ranges[i]
                range_key = f"{prev_range+1}-{curr_range}"
                count = len([s for s in tree_sizes if prev_range < s <= curr_range])
            
            histogram[range_key] = {
                'count': count,
                'percentage': (count / subtree_count * 100) if subtree_count > 0 else 0
            }
        
        # æŒ‰è§„æ¨¡åˆ†ç±»å­æ ‘
        small_trees = len([s for s in tree_sizes if s <= 3])  # å°å‹ï¼š1-3ä¸ªèŠ‚ç‚¹
        medium_trees = len([s for s in tree_sizes if 3 < s <= 10])  # ä¸­å‹ï¼š4-10ä¸ªèŠ‚ç‚¹
        large_trees = len([s for s in tree_sizes if s > 10])  # å¤§å‹ï¼š>10ä¸ªèŠ‚ç‚¹
        
        size_distribution = {
            'small_trees': {
                'count': small_trees,
                'percentage': (small_trees / subtree_count * 100) if subtree_count > 0 else 0,
                'description': '1-3ä¸ªèŠ‚ç‚¹'
            },
            'medium_trees': {
                'count': medium_trees,
                'percentage': (medium_trees / subtree_count * 100) if subtree_count > 0 else 0,
                'description': '4-10ä¸ªèŠ‚ç‚¹'
            },
            'large_trees': {
                'count': large_trees,
                'percentage': (large_trees / subtree_count * 100) if subtree_count > 0 else 0,
                'description': '>10ä¸ªèŠ‚ç‚¹'
            }
        }
        
        # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        detailed_stats = {
            'median_size': np.median(tree_sizes),
            'std_size': np.std(tree_sizes),
            'percentiles': {
                '25th': np.percentile(tree_sizes, 25),
                '75th': np.percentile(tree_sizes, 75),
                '90th': np.percentile(tree_sizes, 90),
                '95th': np.percentile(tree_sizes, 95)
            },
            'size_frequency': {size: tree_sizes.count(size) for size in set(tree_sizes)}
        }
        
        return {
            'total_nodes': total_nodes,
            'subtree_count': subtree_count,
            'avg_nodes_per_subtree': avg_size,
            'max_subtree_size': max_size,
            'min_subtree_size': min_size,
            'histogram': histogram,
            'size_distribution': size_distribution,
            'detailed_stats': detailed_stats
        }
    
    def print_node_distribution_report(self):
        """
        æ‰“å°æ ¼å¼åŒ–çš„èŠ‚ç‚¹åˆ†å¸ƒæŠ¥å‘Š
        """
        analysis = self.analyze_node_distribution()
        
        print("=" * 80)
        print("ğŸŒ² æ£®æ—èŠ‚ç‚¹åˆ†å¸ƒåˆ†ææŠ¥å‘Š")
        print("=" * 80)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {analysis['total_nodes']}")
        print(f"   å­æ ‘æ•°é‡: {analysis['subtree_count']}")
        print(f"   å¹³å‡æ¯æ£µå­æ ‘èŠ‚ç‚¹æ•°: {analysis['avg_nodes_per_subtree']:.2f}")
        print(f"   æœ€å¤§å­æ ‘èŠ‚ç‚¹æ•°: {analysis['max_subtree_size']}")
        print(f"   æœ€å°å­æ ‘èŠ‚ç‚¹æ•°: {analysis['min_subtree_size']}")
        
        # è¯¦ç»†ç»Ÿè®¡
        detailed = analysis['detailed_stats']
        print(f"\nğŸ“ˆ è¯¦ç»†ç»Ÿè®¡:")
        print(f"   ä¸­ä½æ•°: {detailed['median_size']:.2f}")
        print(f"   æ ‡å‡†å·®: {detailed['std_size']:.2f}")
        print(f"   25thç™¾åˆ†ä½: {detailed['percentiles']['25th']:.2f}")
        print(f"   75thç™¾åˆ†ä½: {detailed['percentiles']['75th']:.2f}")
        print(f"   90thç™¾åˆ†ä½: {detailed['percentiles']['90th']:.2f}")
        print(f"   95thç™¾åˆ†ä½: {detailed['percentiles']['95th']:.2f}")
        
        # ç›´æ–¹å›¾
        print(f"\nğŸ“Š èŠ‚ç‚¹æ•°é‡åˆ†å¸ƒç›´æ–¹å›¾:")
        for range_key, data in analysis['histogram'].items():
            if data['count'] > 0:
                bar = "â–ˆ" * min(50, data['count'])
                print(f"   {range_key:>8} èŠ‚ç‚¹ | {bar} ({data['count']} æ£µ, {data['percentage']:.1f}%)")
        
        # è§„æ¨¡åˆ†ç±»
        print(f"\nğŸ·ï¸  å­æ ‘è§„æ¨¡åˆ†ç±»:")
        for category, data in analysis['size_distribution'].items():
            category_name = {
                'small_trees': 'å°å‹å­æ ‘',
                'medium_trees': 'ä¸­å‹å­æ ‘', 
                'large_trees': 'å¤§å‹å­æ ‘'
            }.get(category, category)
            
            print(f"   {category_name} ({data['description']}): {data['count']} æ£µ ({data['percentage']:.1f}%)")
        
        # ç²¾ç¡®é¢‘ç‡åˆ†å¸ƒï¼ˆä»…æ˜¾ç¤ºå‰10ä¸ªæœ€å¸¸è§çš„å¤§å°ï¼‰
        print(f"\nğŸ” ç²¾ç¡®èŠ‚ç‚¹æ•°é¢‘ç‡åˆ†å¸ƒ (å‰10å):")
        sorted_freq = sorted(detailed['size_frequency'].items(), key=lambda x: x[1], reverse=True)
        for size, freq in sorted_freq[:10]:
            percentage = (freq / analysis['subtree_count'] * 100) if analysis['subtree_count'] > 0 else 0
            print(f"   {size} ä¸ªèŠ‚ç‚¹: {freq} æ£µå­æ ‘ ({percentage:.1f}%)")
        
        if len(sorted_freq) > 10:
            print(f"   ... è¿˜æœ‰ {len(sorted_freq) - 10} ç§ä¸åŒçš„èŠ‚ç‚¹æ•°é‡")
        
        print("=" * 80)
    
    def get_subtrees_by_size_range(self, min_size=1, max_size=float('inf')):
        """
        è·å–æŒ‡å®šå¤§å°èŒƒå›´å†…çš„å­æ ‘
        
        å‚æ•°:
            min_size: æœ€å°èŠ‚ç‚¹æ•°
            max_size: æœ€å¤§èŠ‚ç‚¹æ•°
        
        è¿”å›:
            ç¬¦åˆæ¡ä»¶çš„å­æ ‘åˆ—è¡¨
        """
        return [subtree for subtree in self.subtrees 
                if min_size <= subtree['size'] <= max_size]
    
    def get_distribution_summary(self):
        """
        è·å–åˆ†å¸ƒæ‘˜è¦ä¿¡æ¯
        
        è¿”å›:
            ç®€åŒ–çš„åˆ†å¸ƒæ‘˜è¦
        """
        analysis = self.analyze_node_distribution()
        
        return {
            'summary': f"æ£®æ—åŒ…å« {analysis['subtree_count']} æ£µå­æ ‘ï¼Œæ€»è®¡ {analysis['total_nodes']} ä¸ªèŠ‚ç‚¹",
            'avg_size': f"å¹³å‡æ¯æ£µå­æ ‘ {analysis['avg_nodes_per_subtree']:.1f} ä¸ªèŠ‚ç‚¹",
            'size_range': f"å­æ ‘å¤§å°èŒƒå›´: {analysis['min_subtree_size']}-{analysis['max_subtree_size']} ä¸ªèŠ‚ç‚¹",
            'dominant_category': self._get_dominant_category(analysis['size_distribution']),
            'fragmentation_level': self._calculate_fragmentation_level(analysis)
        }
    
    def _get_dominant_category(self, size_distribution):
        """è·å–å ä¸»å¯¼åœ°ä½çš„å­æ ‘ç±»åˆ«"""
        max_category = max(size_distribution.items(), key=lambda x: x[1]['count'])
        category_name = {
            'small_trees': 'å°å‹å­æ ‘',
            'medium_trees': 'ä¸­å‹å­æ ‘',
            'large_trees': 'å¤§å‹å­æ ‘'
        }.get(max_category[0], max_category[0])
        
        return f"{category_name} å ä¸»å¯¼ ({max_category[1]['percentage']:.1f}%)"
    
    def _calculate_fragmentation_level(self, analysis):
        """è®¡ç®—æ£®æ—çš„ç¢ç‰‡åŒ–ç¨‹åº¦"""
        if analysis['subtree_count'] <= 1:
            return "æ— ç¢ç‰‡åŒ–"
        
        # åŸºäºå­æ ‘æ•°é‡å’Œå¹³å‡å¤§å°è®¡ç®—ç¢ç‰‡åŒ–ç¨‹åº¦
        avg_size = analysis['avg_nodes_per_subtree']
        subtree_count = analysis['subtree_count']
        
        if avg_size >= 10:
            return "ä½ç¢ç‰‡åŒ–"
        elif avg_size >= 5:
            return "ä¸­ç­‰ç¢ç‰‡åŒ–"
        elif avg_size >= 2:
            return "é«˜ç¢ç‰‡åŒ–"
        else:
            return "æé«˜ç¢ç‰‡åŒ–"

class PostTree:
    """
    è¡¨ç¤ºä¸€ä¸ªå¸–å­åŠå…¶æ‰€æœ‰è¯„è®ºçš„æ ‘ç»“æ„ã€‚
    """
    def __init__(self, post_id, post_content):
        self.post_id = post_id                    # å¸–å­å”¯ä¸€ID
        self.root = CommentNode(post_id, post_content, parent_id=None)  # å¸–å­æœ¬èº«ä½œä¸ºæ ¹èŠ‚ç‚¹

    def add_comment(self, comment_id, content, parent_id):
        """
        æ·»åŠ è¯„è®ºæˆ–å›å¤åˆ°æ ‘ä¸­ã€‚
        """
        parent_node = self.find_comment(self.root, parent_id)
        if parent_node:
            new_comment = CommentNode(comment_id, content, parent_id)
            parent_node.add_child(new_comment)
            return new_comment
        else:
            raise ValueError(f"çˆ¶è¯„è®ºID {parent_id} æœªæ‰¾åˆ°")

    def find_comment(self, node, comment_id):
        """
        é€’å½’æŸ¥æ‰¾æŒ‡å®šIDçš„è¯„è®ºèŠ‚ç‚¹ã€‚
        """
        if node.comment_id == comment_id:
            return node
        for child in node.children:
            result = self.find_comment(child, comment_id)
            if result:
                return result
        return None
    
    def set_embeddings(self, embedding_model, batch_size=16):
        """
        ä¸ºæ‰€æœ‰èŠ‚ç‚¹è®¡ç®—å¹¶è®¾ç½®å‘é‡è¡¨ç¤ºï¼Œåˆ©ç”¨GPUåŠ é€Ÿå¹¶æ˜¾ç¤ºè¿›åº¦æ¡
        
        å‚æ•°:
            embedding_model: é¢„è®­ç»ƒçš„åµŒå…¥æ¨¡å‹
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        
        # ç¡®ä¿æ¨¡å‹åœ¨GPUä¸Šè¿è¡Œ(å¦‚æœå¯ç”¨)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        embedding_model = embedding_model.to(device)
        
        # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„å†…å®¹
        all_nodes = []
        all_contents = []
        
        def collect_nodes(node):
            all_nodes.append(node)
            all_contents.append(node.content)
            for child in node.children:
                collect_nodes(child)
        
        collect_nodes(self.root)
        
        # æ‰¹é‡è®¡ç®—åµŒå…¥ï¼Œå¹¶ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        all_embeddings = []
        total_batches = (len(all_contents) + batch_size - 1) // batch_size
        
        for i in tqdm(range(0, len(all_contents), batch_size), desc="Calculating embeddings", total=total_batches):
            batch_contents = all_contents[i:i + batch_size]
            
            with torch.no_grad():  # é¿å…è®¡ç®—æ¢¯åº¦
                batch_embeddings = embedding_model.encode(batch_contents)
            
            all_embeddings.extend(batch_embeddings)
        
        # ä¸ºæ¯ä¸ªèŠ‚ç‚¹è®¾ç½®åµŒå…¥
        for node, embedding in zip(all_nodes, all_embeddings):
            node.set_embedding(embedding)
    
    def prune_by_similarity(self, similarity_threshold=0.5, similarity_func=None):
        """
        åŸºäºç›¸ä¼¼åº¦å¯¹ä¸€çº§è¯„è®ºçš„å­æ ‘è¿›è¡Œå‰ªè¾¹ï¼Œè¿”å›æ£®æ—
        
        å‚æ•°:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„è¾¹å°†è¢«å‰ªæ‰
            similarity_func: è‡ªå®šä¹‰ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
        
        è¿”å›:
            ForestManagerå¯¹è±¡ï¼ŒåŒ…å«å‰ªè¾¹åçš„æ£®æ—
        """
        forest = ForestManager(self)
        forest.similarity_threshold = similarity_threshold
        
        # éå†æ‰€æœ‰ä¸€çº§è¯„è®ºï¼ˆå¸–å­çš„ç›´æ¥å­èŠ‚ç‚¹ï¼‰
        for first_level_comment in self.root.children:
            # å¯¹æ¯ä¸ªä¸€çº§è¯„è®ºçš„å­æ ‘è¿›è¡Œå‰ªè¾¹
            pruned_subtree = self._prune_subtree_by_similarity(
                first_level_comment, 
                similarity_threshold, 
                similarity_func,
                forest  # ä¼ é€’forestå¯¹è±¡ç”¨äºè®°å½•å‰ªè¾¹
            )
            
            # å°†å‰ªè¾¹åçš„ä¸»å­æ ‘æ·»åŠ åˆ°æ£®æ—
            forest.add_subtree(pruned_subtree, self.root.comment_id)
        
        return forest
    
    def _prune_subtree_by_similarity(self, subtree_root, threshold, similarity_func, forest):
        """
        å¯¹å•ä¸ªå­æ ‘è¿›è¡ŒåŸºäºç›¸ä¼¼åº¦çš„å‰ªè¾¹
        
        å‚æ•°:
            subtree_root: å­æ ‘çš„æ ¹èŠ‚ç‚¹
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            similarity_func: ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
            forest: ForestManagerå¯¹è±¡ï¼Œç”¨äºè®°å½•å‰ªè¾¹ä¿¡æ¯
        
        è¿”å›:
            å‰ªè¾¹åçš„å­æ ‘æ ¹èŠ‚ç‚¹
        """
        # æ·±åº¦å¤åˆ¶å­æ ‘æ ¹èŠ‚ç‚¹
        pruned_root = subtree_root.deep_copy()
        
        # æ¸…ç©ºå­èŠ‚ç‚¹ï¼Œé‡æ–°æ„å»º
        pruned_root.children = []
        
        # é€’å½’å¤„ç†æ¯ä¸ªå­èŠ‚ç‚¹
        for child in subtree_root.children:
            # è®¡ç®—çˆ¶å­èŠ‚ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦
            try:
                similarity = subtree_root.calculate_similarity(child, similarity_func)
                
                if similarity >= threshold:
                    # ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œä¿ç•™è¾¹ï¼Œé€’å½’å¤„ç†å­èŠ‚ç‚¹
                    pruned_child = self._prune_subtree_by_similarity(
                        child, threshold, similarity_func, forest
                    )
                    pruned_root.add_child(pruned_child)
                else:
                    # ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ï¼Œå‰ªæ‰è¿™æ¡è¾¹å¹¶è®°å½•
                    forest.record_cut_edge(
                        parent_id=subtree_root.comment_id,
                        child_id=child.comment_id,
                        similarity_score=similarity,
                        reason="similarity_below_threshold"
                    )
                    
                    # å°†è¢«å‰ªæ‰çš„å­æ ‘ä½œä¸ºç‹¬ç«‹å­æ ‘æ·»åŠ åˆ°æ£®æ—ä¸­
                    orphaned_subtree = self._prune_subtree_by_similarity(
                        child, threshold, similarity_func, forest
                    )
                    forest.add_subtree(orphaned_subtree, subtree_root.comment_id)
            
            except ValueError as e:
                # å¦‚æœæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå¦‚ç¼ºå°‘åµŒå…¥ï¼‰ï¼Œé»˜è®¤ä¿ç•™è¾¹ä½†è®°å½•åŸå› 
                pruned_child = self._prune_subtree_by_similarity(
                    child, threshold, similarity_func, forest
                )
                pruned_root.add_child(pruned_child)
                
                # è®°å½•æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦çš„æƒ…å†µ
                forest.record_cut_edge(
                    parent_id=subtree_root.comment_id,
                    child_id=child.comment_id,
                    similarity_score=-1,  # ç‰¹æ®Šå€¼è¡¨ç¤ºæ— æ³•è®¡ç®—
                    reason="embedding_missing"
                )
    
        return pruned_root
    
    def analyze_similarity_distribution(self):
        """
        åˆ†ææ ‘ä¸­æ‰€æœ‰çˆ¶å­èŠ‚ç‚¹å¯¹çš„ç›¸ä¼¼åº¦åˆ†å¸ƒ
        
        è¿”å›:
            ç›¸ä¼¼åº¦åˆ†å¸ƒçš„ç»Ÿè®¡ä¿¡æ¯
        """
        similarities = []
        
        def collect_similarities(node):
            for child in node.children:
                try:
                    similarity = node.calculate_similarity(child)
                    similarities.append(similarity)
                except ValueError:
                    pass  # è·³è¿‡æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦çš„èŠ‚ç‚¹å¯¹
                collect_similarities(child)
        
        # åªåˆ†æä¸€çº§è¯„è®ºåŠå…¶å­æ ‘ä¸­çš„ç›¸ä¼¼åº¦
        for first_level_comment in self.root.children:
            collect_similarities(first_level_comment)
        
        if not similarities:
            return {"error": "æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦ï¼Œè¯·ç¡®ä¿èŠ‚ç‚¹æœ‰åµŒå…¥è¡¨ç¤º"}
        
        similarities = np.array(similarities)
        
        return {
            'count': len(similarities),
            'mean': np.mean(similarities),
            'std': np.std(similarities),
            'min': np.min(similarities),
            'max': np.max(similarities),
            'median': np.median(similarities),
            'percentiles': {
                '25': np.percentile(similarities, 25),
                '75': np.percentile(similarities, 75),
                '90': np.percentile(similarities, 90),
                '95': np.percentile(similarities, 95)
            }
        }

class PostStorage:
    """
    ç®¡ç†å’Œå­˜å‚¨å¤šä¸ªå¸–å­æ ‘çš„æ•°æ®å¯¹è±¡æ¨¡å‹ã€‚
    """
    def __init__(self):
        self.posts = {}  # {post_id: PostTree} åŸå§‹æ ‘å­˜å‚¨
        self.forests = {}  # {post_id: ForestManager} æ£®æ—å­˜å‚¨

    def add_post(self, post_id, post_content):
        """
        æ–°å¢ä¸€ä¸ªå¸–å­ã€‚
        """
        if post_id in self.posts:
            raise ValueError(f"å¸–å­ID {post_id} å·²å­˜åœ¨")
        self.posts[post_id] = PostTree(post_id, post_content)

    def get_post(self, post_id):
        """
        è·å–æŒ‡å®šIDçš„å¸–å­æ ‘ã€‚
        """
        return self.posts.get(post_id)

    def add_comment_to_post(self, post_id, comment_id, content, parent_id):
        """
        å‘æŒ‡å®šå¸–å­æ·»åŠ è¯„è®ºæˆ–å›å¤ã€‚
        """
        post_tree = self.get_post(post_id)
        if not post_tree:
            raise ValueError(f"å¸–å­ID {post_id} æœªæ‰¾åˆ°")
        return post_tree.add_comment(comment_id, content, parent_id)
    
    def set_embeddings_for_post(self, post_id, embedding_model, batch_size=16):
        """
        ä¸ºæŒ‡å®šå¸–å­çš„æ‰€æœ‰èŠ‚ç‚¹è®¾ç½®åµŒå…¥è¡¨ç¤º
        """
        post_tree = self.get_post(post_id)
        if not post_tree:
            raise ValueError(f"å¸–å­ID {post_id} æœªæ‰¾åˆ°")
        post_tree.set_embeddings(embedding_model, batch_size)
    
    def set_embeddings_for_all_posts(self, embedding_model, batch_size=16):
        """
        ä¸ºæ‰€æœ‰å¸–å­è®¾ç½®åµŒå…¥è¡¨ç¤º
        """
        for post_id in self.posts:
            self.set_embeddings_for_post(post_id, embedding_model, batch_size)
    
    def prune_post_by_similarity(self, post_id, similarity_threshold=0.5, similarity_func=None):
        """
        å¯¹æŒ‡å®šå¸–å­è¿›è¡ŒåŸºäºç›¸ä¼¼åº¦çš„å‰ªè¾¹ï¼Œç”Ÿæˆæ£®æ—
        
        å‚æ•°:
            post_id: å¸–å­ID
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            similarity_func: è‡ªå®šä¹‰ç›¸ä¼¼åº¦å‡½æ•°
        
        è¿”å›:
            ForestManagerå¯¹è±¡
        """
        post_tree = self.get_post(post_id)
        if not post_tree:
            raise ValueError(f"å¸–å­ID {post_id} æœªæ‰¾åˆ°")
        
        forest = post_tree.prune_by_similarity(similarity_threshold, similarity_func)
        self.forests[post_id] = forest
        return forest
    
    def get_forest(self, post_id):
        """
        è·å–æŒ‡å®šå¸–å­çš„æ£®æ—
        """
        return self.forests.get(post_id)
    
    def get_all_forests(self):
        """
        è·å–æ‰€æœ‰æ£®æ—
        """
        return self.forests.copy()
    
    def analyze_all_similarity_distributions(self):
        """
        åˆ†ææ‰€æœ‰å¸–å­çš„ç›¸ä¼¼åº¦åˆ†å¸ƒ
        
        è¿”å›:
            dict: åŒ…å«å„ä¸ªå¸–å­åˆ†å¸ƒå’Œæ€»ä½“åˆ†å¸ƒçš„å­—å…¸
        """
        all_distributions = {}
        all_similarities = []  # æ”¶é›†æ‰€æœ‰å¸–å­çš„ç›¸ä¼¼åº¦æ•°æ®
        
        # åˆ†ææ¯ä¸ªå¸–å­çš„ç›¸ä¼¼åº¦åˆ†å¸ƒ
        for post_id, post_tree in self.posts.items():
            distribution = post_tree.analyze_similarity_distribution()
            all_distributions[post_id] = distribution
            
            # æ”¶é›†è¯¥å¸–å­çš„ç›¸ä¼¼åº¦æ•°æ®ç”¨äºæ€»ä½“ç»Ÿè®¡
            if 'error' not in distribution:
                similarities = []
                
                def collect_similarities(node):
                    for child in node.children:
                        try:
                            similarity = node.calculate_similarity(child)
                            similarities.append(similarity)
                        except ValueError:
                            pass  # è·³è¿‡æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦çš„èŠ‚ç‚¹å¯¹
                        collect_similarities(child)
                
                # åªåˆ†æä¸€çº§è¯„è®ºåŠå…¶å­æ ‘ä¸­çš„ç›¸ä¼¼åº¦
                for first_level_comment in post_tree.root.children:
                    collect_similarities(first_level_comment)
                
                all_similarities.extend(similarities)
        
        # è®¡ç®—æ‰€æœ‰å¸–å­åŠ æ€»çš„ç›¸ä¼¼åº¦åˆ†å¸ƒ
        if all_similarities:
            all_similarities = np.array(all_similarities)
            overall_distribution = {
                'count': len(all_similarities),
                'mean': np.mean(all_similarities),
                'std': np.std(all_similarities),
                'min': np.min(all_similarities),
                'max': np.max(all_similarities),
                'median': np.median(all_similarities),
                'percentiles': {
                    '25': np.percentile(all_similarities, 25),
                    '75': np.percentile(all_similarities, 75),
                    '90': np.percentile(all_similarities, 90),
                    '95': np.percentile(all_similarities, 95)
                }
            }
        else:
            overall_distribution = {"error": "æ— æ³•è®¡ç®—æ€»ä½“ç›¸ä¼¼åº¦ï¼Œè¯·ç¡®ä¿èŠ‚ç‚¹æœ‰åµŒå…¥è¡¨ç¤º"}
        
        return {
            'individual_distributions': all_distributions,
            'overall_distribution': overall_distribution,
            'summary': {
                'total_posts': len(self.posts),
                'posts_with_valid_similarities': len([d for d in all_distributions.values() if 'error' not in d]),
                'total_similarity_pairs': len(all_similarities) if len(all_similarities) > 0 else 0
            }
        }

    def print_similarity_distributions_report(self):
        """
        æ‰“å°æ‰€æœ‰å¸–å­ç›¸ä¼¼åº¦åˆ†å¸ƒçš„è¯¦ç»†æŠ¥å‘Š
        """
        analysis = self.analyze_all_similarity_distributions()
        
        print("=" * 100)
        print("ğŸ“Š æ‰€æœ‰å¸–å­ç›¸ä¼¼åº¦åˆ†å¸ƒåˆ†ææŠ¥å‘Š")
        print("=" * 100)
        
        # æ€»ä½“æ‘˜è¦
        summary = analysis['summary']
        print(f"ğŸ“‹ æ€»ä½“æ‘˜è¦:")
        print(f"   åˆ†æå¸–å­æ•°: {summary['total_posts']}")
        print(f"   æœ‰æ•ˆç›¸ä¼¼åº¦å¸–å­æ•°: {summary['posts_with_valid_similarities']}")
        print(f"   æ€»ç›¸ä¼¼åº¦å¯¹æ•°: {summary['total_similarity_pairs']}")
        
        # æ€»ä½“åˆ†å¸ƒç»Ÿè®¡
        overall = analysis['overall_distribution']
        if 'error' not in overall:
            print(f"\nğŸ¯ æ‰€æœ‰å¸–å­åŠ æ€»ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
            print(f"   æ ·æœ¬æ•°é‡: {overall['count']}")
            print(f"   å¹³å‡å€¼: {overall['mean']:.4f}")
            print(f"   æ ‡å‡†å·®: {overall['std']:.4f}")
            print(f"   ä¸­ä½æ•°: {overall['median']:.4f}")
            print(f"   èŒƒå›´: {overall['min']:.4f} - {overall['max']:.4f}")
            print(f"   25thç™¾åˆ†ä½: {overall['percentiles']['25']:.4f}")
            print(f"   75thç™¾åˆ†ä½: {overall['percentiles']['75']:.4f}")
            print(f"   90thç™¾åˆ†ä½: {overall['percentiles']['90']:.4f}")
            print(f"   95thç™¾åˆ†ä½: {overall['percentiles']['95']:.4f}")
        else:
            print(f"\nâŒ æ€»ä½“åˆ†å¸ƒ: {overall['error']}")
        
        # å„å¸–å­è¯¦ç»†åˆ†å¸ƒï¼ˆæ˜¾ç¤ºå‰10ä¸ªï¼‰
        individual = analysis['individual_distributions']
        valid_posts = [(post_id, dist) for post_id, dist in individual.items() if 'error' not in dist]
        
        if valid_posts:
            print(f"\nğŸ“‹ å„å¸–å­è¯¦ç»†åˆ†å¸ƒ (å‰10ä¸ª):")
            print("-" * 100)
            print(f"{'å¸–å­ID':<20} {'æ ·æœ¬æ•°':<8} {'å¹³å‡å€¼':<10} {'æ ‡å‡†å·®':<10} {'ä¸­ä½æ•°':<10} {'èŒƒå›´':<20}")
            print("-" * 100)
            
            for i, (post_id, dist) in enumerate(valid_posts[:10]):
                post_id_short = post_id[:17] + "..." if len(post_id) > 20 else post_id
                range_str = f"{dist['min']:.3f}-{dist['max']:.3f}"
                print(f"{post_id_short:<20} {dist['count']:<8} {dist['mean']:<10.4f} "
                      f"{dist['std']:<10.4f} {dist['median']:<10.4f} {range_str:<20}")
            
            if len(valid_posts) > 10:
                print(f"... è¿˜æœ‰ {len(valid_posts) - 10} ä¸ªå¸–å­")
        
        # åˆ†å¸ƒå·®å¼‚åˆ†æ
        if len(valid_posts) > 1:
            print(f"\nğŸ“ˆ åˆ†å¸ƒå·®å¼‚åˆ†æ:")
            means = [dist['mean'] for _, dist in valid_posts]
            stds = [dist['std'] for _, dist in valid_posts]
            
            print(f"   å„å¸–å­å¹³å‡å€¼èŒƒå›´: {min(means):.4f} - {max(means):.4f}")
            print(f"   å„å¸–å­æ ‡å‡†å·®èŒƒå›´: {min(stds):.4f} - {max(stds):.4f}")
            print(f"   å¹³å‡å€¼çš„æ ‡å‡†å·®: {np.std(means):.4f}")
            print(f"   æ ‡å‡†å·®çš„æ ‡å‡†å·®: {np.std(stds):.4f}")
        
        print("=" * 100)
    
    def prune_all_posts_by_similarity(self, similarity_threshold=0.5, similarity_func=None, show_progress=True):
        """
        å¯¹æ‰€æœ‰å¸–å­è¿›è¡ŒåŸºäºç›¸ä¼¼åº¦çš„å‰ªè¾¹ï¼Œç”Ÿæˆæ£®æ—
        
        å‚æ•°:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            similarity_func: è‡ªå®šä¹‰ç›¸ä¼¼åº¦å‡½æ•°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
        è¿”å›:
            dict: {post_id: ForestManager} æ‰€æœ‰å¸–å­çš„æ£®æ—å­—å…¸
        """
        if not self.posts:
            print("æ²¡æœ‰å¸–å­éœ€è¦å‰ªæ")
            return {}
        
        print(f"\nå¼€å§‹å¯¹ {len(self.posts)} ä¸ªå¸–å­è¿›è¡Œç›¸ä¼¼åº¦å‰ªæ...")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_threshold}")
        
        # ä½¿ç”¨è¿›åº¦æ¡éå†æ‰€æœ‰å¸–å­
        post_items = list(self.posts.items())
        if show_progress:
            from tqdm import tqdm
            
            post_items = tqdm(post_items, desc="å‰ªæå¸–å­", unit="ä¸ªå¸–å­")
        
        results = {}
        failed_posts = []
        
        for post_id, post_tree in post_items:
            try:
                # å¯¹æ¯ä¸ªå¸–å­è¿›è¡Œå‰ªæ
                forest = post_tree.prune_by_similarity(similarity_threshold, similarity_func)
                self.forests[post_id] = forest
                results[post_id] = forest
                
                if show_progress and not isinstance(post_items, list):
                    # æ›´æ–°è¿›åº¦æ¡æè¿°
                    stats = forest.get_forest_statistics()
                    post_items.set_postfix({
                        'å­æ ‘æ•°': stats.get('subtree_count', 0),
                        'å‰ªè¾¹æ•°': stats.get('cut_edges_count', 0)
                    })
                    
            except Exception as e:
                failed_posts.append((post_id, str(e)))
                print(f"\nè­¦å‘Š: å¸–å­ {post_id} å‰ªæå¤±è´¥: {e}")
        
        # æ‰“å°æ€»ç»“
        print(f"\nå‰ªæå®Œæˆï¼")
        print(f"âœ… æˆåŠŸå‰ªæ: {len(results)} ä¸ªå¸–å­")
        if failed_posts:
            print(f"âŒ å¤±è´¥: {len(failed_posts)} ä¸ªå¸–å­")
            for post_id, error in failed_posts:
                print(f"   - {post_id}: {error}")
        
        return results
    
    def get_all_forest_statistics(self):
        """
        è·å–æ‰€æœ‰æ£®æ—çš„ç»Ÿè®¡ä¿¡æ¯
        
        è¿”å›:
            dict: åŒ…å«æ€»ä½“ç»Ÿè®¡å’Œå„ä¸ªå¸–å­è¯¦ç»†ç»Ÿè®¡çš„å­—å…¸
        """
        if not self.forests:
            return {"error": "æ²¡æœ‰æ£®æ—æ•°æ®"}
        
        # æ”¶é›†æ‰€æœ‰æ£®æ—çš„ç»Ÿè®¡ä¿¡æ¯
        all_stats = {}
        total_subtrees = 0
        total_nodes = 0
        total_cut_edges = 0
        
        for post_id, forest in self.forests.items():
            stats = forest.get_forest_statistics()
            all_stats[post_id] = stats
            
            total_subtrees += stats.get('subtree_count', 0)
            total_nodes += stats.get('total_nodes', 0)
            total_cut_edges += stats.get('cut_edges_count', 0)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        avg_subtrees_per_post = total_subtrees / len(self.forests) if self.forests else 0
        avg_nodes_per_post = total_nodes / len(self.forests) if self.forests else 0
        avg_cut_edges_per_post = total_cut_edges / len(self.forests) if self.forests else 0
        
        return {
            'total_posts': len(self.forests),
            'total_subtrees': total_subtrees,
            'total_nodes': total_nodes,
            'total_cut_edges': total_cut_edges,
            'avg_subtrees_per_post': avg_subtrees_per_post,
            'avg_nodes_per_post': avg_nodes_per_post,
            'avg_cut_edges_per_post': avg_cut_edges_per_post,
            'individual_stats': all_stats
        }
    
    def print_all_forest_statistics(self):
        """
        æ‰“å°æ‰€æœ‰æ£®æ—çš„ç»Ÿè®¡æŠ¥å‘Š
        """
        stats = self.get_all_forest_statistics()
        
        if 'error' in stats:
            print(stats['error'])
            return
        
        print("=" * 100)
        print("ğŸŒ³ æ‰€æœ‰å¸–å­æ£®æ—ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 100)
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   å¤„ç†å¸–å­æ•°: {stats['total_posts']}")
        print(f"   æ€»å­æ ‘æ•°: {stats['total_subtrees']}")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
        print(f"   æ€»å‰ªè¾¹æ•°: {stats['total_cut_edges']}")
        print(f"   å¹³å‡æ¯ä¸ªå¸–å­å­æ ‘æ•°: {stats['avg_subtrees_per_post']:.2f}")
        print(f"   å¹³å‡æ¯ä¸ªå¸–å­èŠ‚ç‚¹æ•°: {stats['avg_nodes_per_post']:.2f}")
        print(f"   å¹³å‡æ¯ä¸ªå¸–å­å‰ªè¾¹æ•°: {stats['avg_cut_edges_per_post']:.2f}")
        
        # å„å¸–å­è¯¦ç»†ç»Ÿè®¡ï¼ˆåªæ˜¾ç¤ºå‰10ä¸ªï¼‰
        print(f"\nğŸ“‹ å„å¸–å­è¯¦ç»†ç»Ÿè®¡ (å‰10ä¸ª):")
        print("-" * 100)
        print(f"{'å¸–å­ID':<20} {'å­æ ‘æ•°':<8} {'èŠ‚ç‚¹æ•°':<8} {'å‰ªè¾¹æ•°':<8} {'å¹³å‡å­æ ‘å¤§å°':<12}")
        print("-" * 100)
        
        count = 0
        for post_id, post_stats in stats['individual_stats'].items():
            if count >= 10:
                remaining = len(stats['individual_stats']) - 10
                print(f"... è¿˜æœ‰ {remaining} ä¸ªå¸–å­")
                break
            
            post_id_short = post_id[:17] + "..." if len(post_id) > 20 else post_id
            print(f"{post_id_short:<20} {post_stats.get('subtree_count', 0):<8} "
                  f"{post_stats.get('total_nodes', 0):<8} {post_stats.get('cut_edges_count', 0):<8} "
                  f"{post_stats.get('avg_subtree_size', 0):<12.2f}")
            count += 1
        
        print("=" * 100)
    
    def analyze_all_forests_distribution(self):
        """
        åˆ†ææ‰€æœ‰æ£®æ—çš„èŠ‚ç‚¹åˆ†å¸ƒæƒ…å†µ
        
        è¿”å›:
            ç»¼åˆçš„åˆ†å¸ƒåˆ†æç»“æœ
        """
        if not self.forests:
            return {"error": "æ²¡æœ‰æ£®æ—æ•°æ®"}
        
        # æ”¶é›†æ‰€æœ‰æ£®æ—çš„åˆ†å¸ƒæ•°æ®
        all_tree_sizes = []
        size_distributions = {'small_trees': 0, 'medium_trees': 0, 'large_trees': 0}
        
        for forest in self.forests.values():
            analysis = forest.analyze_node_distribution()
            
            # æ”¶é›†æ‰€æœ‰å­æ ‘å¤§å°
            for subtree in forest.subtrees:
                all_tree_sizes.append(subtree['size'])
            
            # ç´¯è®¡è§„æ¨¡åˆ†ç±»
            for category, data in analysis['size_distribution'].items():
                size_distributions[category] += data['count']
        
        if not all_tree_sizes:
            return {"error": "æ²¡æœ‰å­æ ‘æ•°æ®"}
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_subtrees = len(all_tree_sizes)
        total_nodes = sum(all_tree_sizes)
        
        # è®¡ç®—ç›´æ–¹å›¾
        histogram_ranges = [1, 2, 3, 5, 10, 20, 50, 100]
        histogram = {}
        
        for i in range(len(histogram_ranges)):
            if i == 0:
                range_key = f"1"
                count = len([s for s in all_tree_sizes if s == 1])
            elif i == len(histogram_ranges) - 1:
                range_key = f"{histogram_ranges[i]}+"
                count = len([s for s in all_tree_sizes if s >= histogram_ranges[i]])
            else:
                prev_range = histogram_ranges[i-1]
                curr_range = histogram_ranges[i]
                range_key = f"{prev_range+1}-{curr_range}"
                count = len([s for s in all_tree_sizes if prev_range < s <= curr_range])
            
            histogram[range_key] = {
                'count': count,
                'percentage': (count / total_subtrees * 100) if total_subtrees > 0 else 0
            }
        
        # è§„æ¨¡åˆ†ç±»ç™¾åˆ†æ¯”
        for category in size_distributions:
            size_distributions[category] = {
                'count': size_distributions[category],
                'percentage': (size_distributions[category] / total_subtrees * 100) if total_subtrees > 0 else 0
            }
        
        return {
            'total_forests': len(self.forests),
            'total_subtrees': total_subtrees,
            'total_nodes': total_nodes,
            'avg_subtree_size': total_nodes / total_subtrees if total_subtrees > 0 else 0,
            'max_subtree_size': max(all_tree_sizes) if all_tree_sizes else 0,
            'min_subtree_size': min(all_tree_sizes) if all_tree_sizes else 0,
            'histogram': histogram,
            'size_distribution': size_distributions
        }
    
    def sample_and_visualize_subtrees_from_distribution(self, samples_per_group=1):
        """
        ä»ä¸åŒçš„ç›´æ–¹å›¾åˆ†å¸ƒä¸­éšæœºé‡‡æ ·æŒ‡å®šæ•°é‡çš„å­æ ‘å¹¶å¯è§†åŒ–
        
        å‚æ•°:
            samples_per_group: æ¯ä¸ªåˆ†å¸ƒåŒºé—´é‡‡æ ·çš„å­æ ‘æ•°é‡ï¼Œé»˜è®¤ä¸º1
        """
        if not self.forests:
            print("âŒ æ²¡æœ‰æ£®æ—æ•°æ®")
            return
        
        # æ”¶é›†æ‰€æœ‰å­æ ‘ï¼ŒæŒ‰å¤§å°åˆ†ç»„
        subtree_groups = {
            '1': [],
            '2': [],
            '3': [],
            '4-5': [],
            '6-10': [],
            '11-20': [],
            '21-50': [],
            '51-100': [],
            '100+': []
        }
        
        for post_id, forest in self.forests.items():
            for subtree in forest.subtrees:
                size = subtree['size']
                # æ ¹æ®å¤§å°åˆ†ç»„
                if size == 1:
                    subtree_groups['1'].append((post_id, subtree))
                elif size == 2:
                    subtree_groups['2'].append((post_id, subtree))
                elif size == 3:
                    subtree_groups['3'].append((post_id, subtree))
                elif size <= 5:
                    subtree_groups['4-5'].append((post_id, subtree))
                elif size <= 10:
                    subtree_groups['6-10'].append((post_id, subtree))
                elif size <= 20:
                    subtree_groups['11-20'].append((post_id, subtree))
                elif size <= 50:
                    subtree_groups['21-50'].append((post_id, subtree))
                elif size <= 100:
                    subtree_groups['51-100'].append((post_id, subtree))
                else:
                    subtree_groups['100+'].append((post_id, subtree))
        
        print("=" * 120)
        print(f"ğŸ² ä»ä¸åŒåˆ†å¸ƒåŒºé—´é‡‡æ ·å­æ ‘è¿›è¡Œå¯è§†åŒ– (æ¯ç»„é‡‡æ · {samples_per_group} ä¸ª)")
        print("=" * 120)
        
        total_sampled = 0
        for group_name, subtrees in subtree_groups.items():
            if not subtrees:
                print(f"\nğŸ“Š åˆ†å¸ƒåŒºé—´ [{group_name}ä¸ªèŠ‚ç‚¹]: æ— æ•°æ®")
                continue
            
            # ç¡®å®šå®é™…é‡‡æ ·æ•°é‡
            actual_samples = min(samples_per_group, len(subtrees))
            
            print(f"\n{'='*80}")
            print(f"ğŸ“Š åˆ†å¸ƒåŒºé—´: [{group_name}ä¸ªèŠ‚ç‚¹] - æ€»æ•°: {len(subtrees)} æ£µï¼Œé‡‡æ ·: {actual_samples} æ£µ")
            print(f"{'='*80}")
            
            # å¦‚æœé‡‡æ ·æ•°é‡ç­‰äºæ€»æ•°ï¼Œåˆ™æ˜¾ç¤ºæ‰€æœ‰å­æ ‘ï¼›å¦åˆ™éšæœºé‡‡æ ·
            if actual_samples == len(subtrees):
                print(f"ğŸ’¡ è¯¥åŒºé—´å­æ ‘æ•°é‡ä¸è¶³ {samples_per_group} ä¸ªï¼Œæ˜¾ç¤ºå…¨éƒ¨ {len(subtrees)} æ£µå­æ ‘")
                selected_subtrees = subtrees
            else:
                print(f"ğŸ¯ ä» {len(subtrees)} æ£µå­æ ‘ä¸­éšæœºé‡‡æ · {actual_samples} æ£µ")
                selected_subtrees = random.sample(subtrees, actual_samples)
            
            # å¯è§†åŒ–é€‰ä¸­çš„å­æ ‘
            for i, (post_id, sampled_subtree) in enumerate(selected_subtrees):
                total_sampled += 1
                
                print(f"\n{'-'*60}")
                print(f"ğŸŒ³ æ ·æœ¬ {i+1}/{actual_samples} (æ€»ç¬¬ {total_sampled} ä¸ª)")
                print(f"{'-'*60}")
                print(f"ğŸ“ æ¥æºå¸–å­: {post_id}")
                print(f"ğŸ“Š å­æ ‘å¤§å°: {sampled_subtree['size']} ä¸ªèŠ‚ç‚¹")
                print(f"ğŸ“ å­æ ‘æ·±åº¦: {sampled_subtree['depth']} å±‚")
                
                # å¯è§†åŒ–è¿™ä¸ªå­æ ‘
                print(f"\nğŸŒ² å­æ ‘ç»“æ„:")
                self._visualize_subtree_simple(sampled_subtree['root'])
        
        if total_sampled == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯é‡‡æ ·çš„å­æ ‘")
        else:
            print(f"\nâœ… æˆåŠŸé‡‡æ ·å¹¶å¯è§†åŒ–äº† {total_sampled} ä¸ªå­æ ‘")
            
            # æ˜¾ç¤ºé‡‡æ ·ç»Ÿè®¡
            print(f"\nğŸ“Š é‡‡æ ·ç»Ÿè®¡:")
            for group_name, subtrees in subtree_groups.items():
                if subtrees:
                    actual_samples = min(samples_per_group, len(subtrees))
                    sample_rate = (actual_samples / len(subtrees)) * 100
                    print(f"   {group_name:>8} èŠ‚ç‚¹: {actual_samples}/{len(subtrees)} ({sample_rate:.1f}%)")
        
        print("=" * 120)
        """
        ä»ä¸åŒçš„ç›´æ–¹å›¾åˆ†å¸ƒä¸­å„éšæœºé‡‡æ ·1ä¸ªå­æ ‘å¹¶å¯è§†åŒ–
        """
        if not self.forests:
            print("âŒ æ²¡æœ‰æ£®æ—æ•°æ®")
            return
        
        # æ”¶é›†æ‰€æœ‰å­æ ‘ï¼ŒæŒ‰å¤§å°åˆ†ç»„
        subtree_groups = {
            '1': [],
            '2': [],
            '3': [],
            '4-5': [],
            '6-10': [],
            '11-20': [],
            '21-50': [],
            '51-100': [],
            '100+': []
        }
        
        for post_id, forest in self.forests.items():
            for subtree in forest.subtrees:
                size = subtree['size']
                # æ ¹æ®å¤§å°åˆ†ç»„
                if size == 1:
                    subtree_groups['1'].append((post_id, subtree))
                elif size == 2:
                    subtree_groups['2'].append((post_id, subtree))
                elif size == 3:
                    subtree_groups['3'].append((post_id, subtree))
                elif size <= 5:
                    subtree_groups['4-5'].append((post_id, subtree))
                elif size <= 10:
                    subtree_groups['6-10'].append((post_id, subtree))
                elif size <= 20:
                    subtree_groups['11-20'].append((post_id, subtree))
                elif size <= 50:
                    subtree_groups['21-50'].append((post_id, subtree))
                elif size <= 100:
                    subtree_groups['51-100'].append((post_id, subtree))
                else:
                    subtree_groups['100+'].append((post_id, subtree))
        
        print("=" * 120)
        print("ğŸ² ä»ä¸åŒåˆ†å¸ƒåŒºé—´éšæœºé‡‡æ ·å­æ ‘è¿›è¡Œå¯è§†åŒ–")
        print("=" * 120)
        
        
        sampled_count = 0
        for group_name, subtrees in subtree_groups.items():
            if not subtrees:
                print(f"\nğŸ“Š åˆ†å¸ƒåŒºé—´ [{group_name}ä¸ªèŠ‚ç‚¹]: æ— æ•°æ®")
                continue
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªå­æ ‘
            post_id, sampled_subtree = random.choice(subtrees)
            sampled_count += 1
            
            print(f"\n{'='*80}")
            print(f"ğŸŒ³ æ ·æœ¬ {sampled_count} - åˆ†å¸ƒåŒºé—´: [{group_name}ä¸ªèŠ‚ç‚¹]")
            print(f"{'='*80}")
            print(f"ğŸ“ æ¥æºå¸–å­: {post_id}")
            print(f"ğŸ“Š å­æ ‘å¤§å°: {sampled_subtree['size']} ä¸ªèŠ‚ç‚¹")
            print(f"ğŸ“ å­æ ‘æ·±åº¦: {sampled_subtree['depth']} å±‚")
            print(f"ğŸ”¢ è¯¥åŒºé—´æ€»æ•°: {len(subtrees)} æ£µå­æ ‘")
            
            # å¯è§†åŒ–è¿™ä¸ªå­æ ‘
            print(f"\nğŸŒ² å­æ ‘ç»“æ„:")
            self._visualize_subtree_simple(sampled_subtree['root'])
        
        if sampled_count == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯é‡‡æ ·çš„å­æ ‘")
        else:
            print(f"\nâœ… æˆåŠŸé‡‡æ ·å¹¶å¯è§†åŒ–äº† {sampled_count} ä¸ªä¸åŒåˆ†å¸ƒåŒºé—´çš„å­æ ‘")
        print("=" * 120)
    
    def _visualize_subtree_simple(self, node, depth=0, prefix=""):
        """
        ç®€åŒ–çš„å­æ ‘å¯è§†åŒ–æ–¹æ³•
        """
        # æ˜¾ç¤ºå½“å‰èŠ‚ç‚¹
        content_preview = node.content[:60] + '...' if len(node.content) > 60 else node.content
        node_info = f"[L{depth}] {content_preview}"
        print(f"{prefix}{node_info}")
        print(f"{prefix}     ID: {node.comment_id}")
        
        # æ˜¾ç¤ºå­èŠ‚ç‚¹
        for i, child in enumerate(node.children):
            is_last_child = (i == len(node.children) - 1)
            
            if is_last_child:
                branch = "â””â”€â”€â”€ "
                child_prefix = prefix + "     "
            else:
                branch = "â”œâ”€â”€â”€ "
                child_prefix = prefix + "â”‚    "
            
            print(f"{prefix}{branch}")
            self._visualize_subtree_simple(child, depth + 1, child_prefix)
    
    def compare_forests_by_threshold(self, thresholds=[0.3, 0.5, 0.7, 0.9], post_id=None):
        """
        æ¯”è¾ƒä¸åŒé˜ˆå€¼ä¸‹çš„å‰ªææ•ˆæœ
        
        å‚æ•°:
            thresholds: è¦æ¯”è¾ƒçš„ç›¸ä¼¼åº¦é˜ˆå€¼åˆ—è¡¨
            post_id: æŒ‡å®šå¸–å­IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¸–å­
        
        è¿”å›:
            ä¸åŒé˜ˆå€¼ä¸‹çš„æ¯”è¾ƒç»“æœ
        """
        if not self.posts:
            return {"error": "æ²¡æœ‰å¸–å­æ•°æ®"}
        
        # é€‰æ‹©è¦åˆ†æçš„å¸–å­
        if post_id is None:
            post_id = list(self.posts.keys())[0]
        
        if post_id not in self.posts:
            return {"error": f"å¸–å­ {post_id} ä¸å­˜åœ¨"}
        
        post_tree = self.posts[post_id]
        comparison_results = {}
        
        print(f"\næ¯”è¾ƒå¸–å­ {post_id} åœ¨ä¸åŒé˜ˆå€¼ä¸‹çš„å‰ªææ•ˆæœ:")
        print("-" * 80)
        print(f"{'é˜ˆå€¼':<8} {'å­æ ‘æ•°':<8} {'æ€»èŠ‚ç‚¹æ•°':<10} {'å‰ªè¾¹æ•°':<8} {'å¹³å‡å­æ ‘å¤§å°':<12}")
        print("-" * 80)
        
        for threshold in thresholds:
            try:
                forest = post_tree.prune_by_similarity(threshold)
                stats = forest.get_forest_statistics()
                
                comparison_results[threshold] = stats
                
                print(f"{threshold:<8} {stats.get('subtree_count', 0):<8} "
                      f"{stats.get('total_nodes', 0):<10} {stats.get('cut_edges_count', 0):<8} "
                      f"{stats.get('avg_subtree_size', 0):<12.2f}")
                      
            except Exception as e:
                print(f"{threshold:<8} é”™è¯¯: {e}")
        
        print("-" * 80)
        return comparison_results

    def visualize_forest_with_cut_edges(self, post_id=None, max_depth=None, max_subtrees=None, show_cut_edges=True, min_subtree_size=2):
        """
        å¯è§†åŒ–æ£®æ—ç»“æ„ï¼Œæ˜¾ç¤ºå­æ ‘å’Œè¢«å‰ªæ‰çš„è¾¹ä¿¡æ¯
        
        å‚æ•°:
            post_id: è¦å¯è§†åŒ–çš„å¸–å­IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ£®æ—
            max_depth: æ˜¾ç¤ºçš„æœ€å¤§æ·±åº¦
            max_subtrees: æ˜¾ç¤ºçš„æœ€å¤§å­æ ‘æ•°é‡
            show_cut_edges: æ˜¯å¦æ˜¾ç¤ºè¢«å‰ªæ‰çš„è¾¹ä¿¡æ¯
            min_subtree_size: æ˜¾ç¤ºå­æ ‘çš„æœ€å°èŠ‚ç‚¹æ•°é‡ï¼Œé»˜è®¤ä¸º1
        """
        if not self.forests:
            print("âŒ æ²¡æœ‰æ£®æ—æ•°æ®å¯ä¾›å¯è§†åŒ–")
            return
        
        # é€‰æ‹©è¦å¯è§†åŒ–çš„æ£®æ—
        if post_id is None:
            post_id = list(self.forests.keys())[0]
        
        if post_id not in self.forests:
            print(f"âŒ å¸–å­ {post_id} çš„æ£®æ—ä¸å­˜åœ¨")
            return
        
        forest = self.forests[post_id]
        
        print("=" * 120)
        print(f"ğŸŒ² å¸–å­ {post_id} å‰ªæåæ£®æ—ç»“æ„å¯è§†åŒ–")
        print("=" * 120)
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        stats = forest.get_forest_statistics()
        print(f"ğŸ“Š æ£®æ—ç»Ÿè®¡: {stats.get('subtree_count', 0)} æ£µå­æ ‘, "
              f"{stats.get('total_nodes', 0)} ä¸ªèŠ‚ç‚¹, "
              f"{stats.get('cut_edges_count', 0)} æ¡è¢«å‰ªè¾¹")
        print(f"ğŸ¯ ç›¸ä¼¼åº¦é˜ˆå€¼: {forest.similarity_threshold}")
        
        # è¿‡æ»¤æ»¡è¶³æœ€å°å¤§å°è¦æ±‚çš„å­æ ‘
        filtered_subtrees = [subtree for subtree in forest.subtrees if subtree['size'] >= min_subtree_size]
        
        if not filtered_subtrees:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°èŠ‚ç‚¹æ•° >= {min_subtree_size} çš„å­æ ‘")
            return
        
        print(f"ğŸ” ç­›é€‰æ¡ä»¶: æ˜¾ç¤ºèŠ‚ç‚¹æ•° >= {min_subtree_size} çš„å­æ ‘")
        print(f"ğŸ“Š ç­›é€‰ç»“æœ: {len(filtered_subtrees)}/{len(forest.subtrees)} æ£µå­æ ‘ç¬¦åˆæ¡ä»¶")
        
        # æ„å»ºè¢«å‰ªè¾¹çš„æ˜ å°„å…³ç³»
        cut_edge_map = {}
        for edge in forest.cut_edges:
            parent_id = edge['parent_id']
            if parent_id not in cut_edge_map:
                cut_edge_map[parent_id] = []
            cut_edge_map[parent_id].append(edge)
        
        # æ˜¾ç¤ºå­æ ‘
        subtrees_to_show = filtered_subtrees[:max_subtrees] if max_subtrees else filtered_subtrees
        
        for i, subtree_info in enumerate(subtrees_to_show):
            print(f"\n{'='*60}")
            print(f"ğŸŒ³ å­æ ‘ {i+1}/{len(filtered_subtrees)}")
            print(f"{'='*60}")
            print(f"ğŸ“ æ ¹èŠ‚ç‚¹ID: {subtree_info['root'].comment_id}")
            print(f"ğŸ“Š å¤§å°: {subtree_info['size']} ä¸ªèŠ‚ç‚¹")
            print(f"ğŸ“ æ·±åº¦: {subtree_info['depth']} å±‚")
            print(f"ğŸ”— åŸå§‹çˆ¶èŠ‚ç‚¹: {subtree_info['original_parent_id']}")
            
            # æ˜¾ç¤ºä»è¿™ä¸ªèŠ‚ç‚¹è¢«å‰ªæ‰çš„è¾¹
            root_id = subtree_info['root'].comment_id
            if show_cut_edges and root_id in cut_edge_map:
                print(f"\nâœ‚ï¸  ä»æ­¤èŠ‚ç‚¹å‰ªæ‰çš„è¾¹:")
                for edge in cut_edge_map[root_id]:
                    similarity = edge['similarity_score']
                    child_id = edge['child_id']
                    reason = edge['reason']
                    print(f"   â”ˆâ”ˆâ”ˆ {root_id} â”ˆâ”ˆâ”ˆâ–· {child_id} (ç›¸ä¼¼åº¦: {similarity:.4f}, åŸå› : {reason})")
            
            print(f"\nğŸŒ² å­æ ‘ç»“æ„:")
            self._visualize_subtree(subtree_info['root'], max_depth, cut_edge_map, show_cut_edges)
        
        # å¦‚æœæœ‰æ›´å¤šå­æ ‘æœªæ˜¾ç¤º
        if max_subtrees and len(filtered_subtrees) > max_subtrees:
            remaining = len(filtered_subtrees) - max_subtrees
            print(f"\n... è¿˜æœ‰ {remaining} æ£µç¬¦åˆæ¡ä»¶çš„å­æ ‘æœªæ˜¾ç¤º")
        
        # æ˜¾ç¤ºè¢«å‰ªè¾¹çš„æ€»ä½“ç»Ÿè®¡
        if show_cut_edges and forest.cut_edges:
            self._show_cut_edges_summary(forest)
        
        print("=" * 120)
    
    def _visualize_subtree(self, node, max_depth=None, cut_edge_map=None, show_cut_edges=True, depth=0, prefix=""):
        """
        é€’å½’å¯è§†åŒ–å•ä¸ªå­æ ‘
        """
        if max_depth is not None and depth > max_depth:
            return
        
        # æ˜¾ç¤ºå½“å‰èŠ‚ç‚¹
        content_preview = node.content[:50] + '...' if len(node.content) > 50 else node.content
        node_type = f"L{depth}" if depth > 0 else "ROOT"
        print(f"{prefix}[{node_type}] {content_preview}")
        print(f"{prefix}     ID: {node.comment_id}")
        
        # æ˜¾ç¤ºå­èŠ‚ç‚¹å’Œè¿æ¥å…³ç³»
        for i, child in enumerate(node.children):
            is_last_child = (i == len(node.children) - 1)
            
            # è¿æ¥çº¿æ ·å¼
            if is_last_child:
                branch = "â””â”€â”€â”€ "
                child_prefix = prefix + "     "
            else:
                branch = "â”œâ”€â”€â”€ "
                child_prefix = prefix + "â”‚    "
            
            # æ˜¾ç¤ºè¿æ¥å…³ç³»
            print(f"{prefix}{branch}[ä¿ç•™è¿æ¥] â–¶")
            
            # é€’å½’æ˜¾ç¤ºå­èŠ‚ç‚¹
            self._visualize_subtree(child, max_depth, cut_edge_map, show_cut_edges, 
                                  depth + 1, child_prefix)
        
        # æ˜¾ç¤ºä»å½“å‰èŠ‚ç‚¹è¢«å‰ªæ‰çš„è¾¹
        if show_cut_edges and cut_edge_map and node.comment_id in cut_edge_map:
            cut_edges = cut_edge_map[node.comment_id]
            for j, edge in enumerate(cut_edges):
                is_last_cut = (j == len(cut_edges) - 1) and (len(node.children) == 0)
                
                if len(node.children) == 0 and is_last_cut:
                    cut_branch = "â””â”ˆâ”ˆâ”ˆ "
                else:
                    cut_branch = "â”œâ”ˆâ”ˆâ”ˆ "
                
                similarity = edge['similarity_score']
                child_id = edge['child_id']
                print(f"{prefix}{cut_branch}[å·²å‰ªæ–­] â–· èŠ‚ç‚¹ {child_id} (ç›¸ä¼¼åº¦: {similarity:.4f})")
    
    def _show_cut_edges_summary(self, forest):
        """
        æ˜¾ç¤ºè¢«å‰ªè¾¹çš„æ±‡æ€»ä¿¡æ¯
        """
        print(f"\n{'='*60}")
        print("âœ‚ï¸  è¢«å‰ªè¾¹æ±‡æ€»ä¿¡æ¯")
        print(f"{'='*60}")
        
        # æŒ‰ç›¸ä¼¼åº¦åˆ†ç»„ç»Ÿè®¡
        similarity_ranges = {
            '0.0-0.1': 0, '0.1-0.2': 0, '0.2-0.3': 0, '0.3-0.4': 0, '0.4-0.5': 0,
            '0.5-0.6': 0, '0.6-0.7': 0, '0.7-0.8': 0, '0.8-0.9': 0, '0.9-1.0': 0
        }
        
        valid_similarities = []
        for edge in forest.cut_edges:
            sim = edge['similarity_score']
            if sim >= 0:  # æ’é™¤æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦çš„è¾¹
                valid_similarities.append(sim)
                # åˆ†ç»„ç»Ÿè®¡
                if sim < 0.1:
                    similarity_ranges['0.0-0.1'] += 1
                elif sim < 0.2:
                    similarity_ranges['0.1-0.2'] += 1
                elif sim < 0.3:
                    similarity_ranges['0.2-0.3'] += 1
                elif sim < 0.4:
                    similarity_ranges['0.3-0.4'] += 1
                elif sim < 0.5:
                    similarity_ranges['0.4-0.5'] += 1
                elif sim < 0.6:
                    similarity_ranges['0.5-0.6'] += 1
                elif sim < 0.7:
                    similarity_ranges['0.6-0.7'] += 1
                elif sim < 0.8:
                    similarity_ranges['0.7-0.8'] += 1
                elif sim < 0.9:
                    similarity_ranges['0.8-0.9'] += 1
                else:
                    similarity_ranges['0.9-1.0'] += 1
        
        print(f"ğŸ“Š æ€»è¢«å‰ªè¾¹æ•°: {len(forest.cut_edges)}")
        if valid_similarities:
            print(f"ğŸ“ˆ ç›¸ä¼¼åº¦ç»Ÿè®¡:")
            print(f"   å¹³å‡å€¼: {np.mean(valid_similarities):.4f}")
            print(f"   ä¸­ä½æ•°: {np.median(valid_similarities):.4f}")
            print(f"   èŒƒå›´: {min(valid_similarities):.4f} - {max(valid_similarities):.4f}")
            
            print(f"\nğŸ“Š ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
            for range_name, count in similarity_ranges.items():
                if count > 0:
                    percentage = count / len(valid_similarities) * 100
                    bar = "â–ˆ" * min(20, count)
                    print(f"   {range_name}: {bar} {count} ({percentage:.1f}%)")
        
        # æ˜¾ç¤ºå‰ªè¾¹åŸå› ç»Ÿè®¡
        reason_counts = {}
        for edge in forest.cut_edges:
            reason = edge['reason']
            reason_counts[reason] = reason_counts.get(reason, 0) + 1
        
        print(f"\nğŸ” å‰ªè¾¹åŸå› ç»Ÿè®¡:")
        for reason, count in reason_counts.items():
            percentage = count / len(forest.cut_edges) * 100
            print(f"   {reason}: {count} ({percentage:.1f}%)")
    
    def visualize_original_vs_pruned(self, original_tree, max_depth=None):
        """
        å¯¹æ¯”æ˜¾ç¤ºåŸå§‹æ ‘å’Œå‰ªæåçš„æ£®æ—
        
        å‚æ•°:
            original_tree: åŸå§‹PostTreeå¯¹è±¡
            max_depth: æ˜¾ç¤ºçš„æœ€å¤§æ·±åº¦
        """
        print("=" * 140)
        print("ğŸ”„ åŸå§‹æ ‘ vs å‰ªæåæ£®æ—å¯¹æ¯”")
        print("=" * 140)
        
        # æ„å»ºè¢«å‰ªè¾¹çš„é›†åˆ
        cut_edges = set()
        for edge in self.cut_edges:
            cut_edges.add((edge['parent_id'], edge['child_id']))
        
        print("ğŸ“Š å¯¹æ¯”ç»Ÿè®¡:")
        original_stats = self._count_original_tree_stats(original_tree.root)
        forest_stats = self.get_forest_statistics()
        
        print(f"   åŸå§‹æ ‘: {original_stats['total_nodes']} ä¸ªèŠ‚ç‚¹, {original_stats['total_edges']} æ¡è¾¹")
        print(f"   å‰ªæå: {forest_stats.get('total_nodes', 0)} ä¸ªèŠ‚ç‚¹, "
              f"{original_stats['total_edges'] - len(self.cut_edges)} æ¡è¾¹, "
              f"{forest_stats.get('subtree_count', 0)} æ£µå­æ ‘")
        print(f"   è¢«å‰ªæ‰: {len(self.cut_edges)} æ¡è¾¹ "
              f"({len(self.cut_edges)/original_stats['total_edges']*100:.1f}%)")
        
        print(f"\nğŸŒ³ åŸå§‹æ ‘ç»“æ„ (æ ‡è®°è¢«å‰ªè¾¹):")
        print("-" * 70)
        self._visualize_original_with_cuts(original_tree.root, cut_edges, max_depth)
