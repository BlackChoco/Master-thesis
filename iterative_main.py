"""
è¿­ä»£å®éªŒç®¡ç†ç³»ç»Ÿ
æ•´åˆå¯¹æ¯”å­¦ä¹ ã€ç›‘ç£å­¦ä¹ ã€åˆ†ç±»å™¨é€‰æ‹©ã€ä¸€è‡´æ€§è¯„åˆ†å’ŒåŠ æƒå¯¹æ¯”å­¦ä¹ çš„å¤šè½®è¿­ä»£æµç¨‹
"""

import os
import sys
import json
import yaml
import argparse
import traceback
import tempfile
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import shutil
from pathlib import Path

# å¯¼å…¥å®éªŒç®¡ç†æ¨¡å—
from experiment_manager import (
    ExperimentStatusDetector,
    ExperimentStateManager,
    ExperimentVariantManager,
    print_experiment_status
)

# å¯¼å…¥ç°æœ‰æ¨¡å—çš„æ¥å£
try:
    from cl_main import run_stage1_contrastive_training
except ImportError as e:
    print(f"Failed to import cl_main: {e}")
    run_stage1_contrastive_training = None
except Exception as e:
    print(f"Other error importing cl_main: {e}")
    run_stage1_contrastive_training = None

try:
    from weighted_cl_training import run_stage2_weighted_contrastive
except ImportError as e:
    print(f"Failed to import weighted_cl_training: {e}")
    run_stage2_weighted_contrastive = None
except Exception as e:
    print(f"Other error importing weighted_cl_training: {e}")
    run_stage2_weighted_contrastive = None

try:
    from sup_training import run_supervised_training_interface
except ImportError as e:
    print(f"Failed to import sup_training: {e}")
    run_supervised_training_interface = None
except Exception as e:
    print(f"Other error importing sup_training: {e}")
    run_supervised_training_interface = None

try:
    from classifier_selector import run_classifier_selection_interface
except ImportError as e:
    print(f"Failed to import classifier_selector: {e}")
    run_classifier_selection_interface = None
except Exception as e:
    print(f"Other error importing classifier_selector: {e}")
    run_classifier_selection_interface = None

try:
    from consistency_scorer import run_consistency_scoring_interface
except ImportError as e:
    print(f"Failed to import consistency_scorer: {e}")
    run_consistency_scoring_interface = None
except Exception as e:
    print(f"Other error importing consistency_scorer: {e}")
    run_consistency_scoring_interface = None


class IterativeExperimentManager:
    """è¿­ä»£å®éªŒç®¡ç†å™¨ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤šå˜ä½“å®éªŒï¼‰"""

    def __init__(self, config_path: str, experiment_dir: Optional[str] = None,
                 resume: bool = False, force_restart: bool = False,
                 use_fresh_bert: Optional[bool] = None):
        """
        åˆå§‹åŒ–å®éªŒç®¡ç†å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            experiment_dir: å®éªŒç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨åˆ›å»º
            resume: æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 
            force_restart: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¼€å§‹
            use_fresh_bert: æ˜¯å¦æ¯è½®ä»åŸå§‹BERTé‡æ–°è®­ç»ƒï¼ˆå‘½ä»¤è¡Œå‚æ•°ï¼Œä¼šè¦†ç›–YAMLé…ç½®ï¼‰
        """
        self.config = self._load_config(config_path)
        self.experiment_name = self.config['experiment_meta']['name']
        self.resume = resume and not force_restart
        self.force_restart = force_restart

        # âœ¨ å¤„ç†æ¨¡å‹åŸºåº§é€‰æ‹©å‚æ•°ï¼ˆå‘½ä»¤è¡Œä¼˜å…ˆçº§ > YAMLé…ç½®ï¼‰
        if use_fresh_bert is not None:
            # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–YAMLé…ç½®
            if 'experiment_meta' not in self.config:
                self.config['experiment_meta'] = {}
            self.config['experiment_meta']['use_fresh_bert_each_round'] = use_fresh_bert

        if experiment_dir:
            self.experiment_dir = experiment_dir
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.experiment_dir = os.path.join(
                "iterative_experiments",
                f"{self.experiment_name}_{timestamp}"
            )

        os.makedirs(self.experiment_dir, exist_ok=True)
        self.log_file = os.path.join(self.experiment_dir, "experiment_log.json")
        self.experiment_log = self._load_or_create_log()

        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        self.state_manager = ExperimentStateManager(self.config, self.experiment_dir)
        self._latest_supervised_output: Optional[Dict] = None
        self._latest_classifier_output: Optional[Dict] = None

        print(f"è¿­ä»£å®éªŒç®¡ç†å™¨åˆå§‹åŒ–")
        print(f"å®éªŒç›®å½•: {self.experiment_dir}")
        print(f"é…ç½®æ–‡ä»¶: {config_path}")
        print(f"å®éªŒåç§°: {self.experiment_name}")
        print(f"æ–­ç‚¹ç»­ä¼ : {'å¯ç”¨' if self.resume else 'ç¦ç”¨'}")
        print(f"å¼ºåˆ¶é‡å¯: {'æ˜¯' if self.force_restart else 'å¦'}")

        # âœ¨ æ˜¾ç¤ºæ¨¡å‹åŸºåº§æ¨¡å¼
        use_fresh = self.config.get('experiment_meta', {}).get('use_fresh_bert_each_round', False)
        if use_fresh:
            print(f"æ¨¡å‹åŸºåº§: æ¯è½®ä»åŸå§‹BERTé‡æ–°è®­ç»ƒ âœ¨")
        else:
            print(f"æ¨¡å‹åŸºåº§: ç´¯ç§¯è®­ç»ƒï¼ˆæ¯è½®åŸºäºä¸Šä¸€è½®æ¨¡å‹ï¼‰")

    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.endswith('.yaml') or config_path.endswith('.yml'):
                return yaml.safe_load(f)
            else:
                return json.load(f)

    def _load_or_create_log(self) -> Dict:
        """åŠ è½½æˆ–åˆ›å»ºå®éªŒæ—¥å¿—"""
        if os.path.exists(self.log_file):
            with open(self.log_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                'experiment_name': self.experiment_name,
                'start_time': datetime.now().isoformat(),
                'config': self.config,
                'rounds': {}
            }

    def _save_log(self):
        """ä¿å­˜å®éªŒæ—¥å¿—"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(self.experiment_log, f, ensure_ascii=False, indent=2)

    def _get_round_config(self, round_num: int) -> Dict:
        """è·å–ç‰¹å®šè½®æ¬¡çš„é…ç½®"""
        # ä»é»˜è®¤é…ç½®å¼€å§‹
        round_config = self.config.get('defaults', {}).copy()

        # åº”ç”¨è½®æ¬¡ç‰¹å®šçš„è¦†ç›–é…ç½®
        if 'round_specific' in self.config and round_num in self.config['round_specific']:
            round_overrides = self.config['round_specific'][round_num]
            for key, value in round_overrides.items():
                if key in round_config:
                    round_config[key].update(value)
                else:
                    round_config[key] = value

        return round_config

    def _find_previous_encoder(self, round_num: int) -> Optional[str]:
        """æŸ¥æ‰¾ä¸Šä¸€è½®çš„æœ€ä½³ç¼–ç å™¨"""
        prev_round_dir = os.path.join(self.experiment_dir, f"round{round_num-1}")

        # é¦–å…ˆæŸ¥æ‰¾best_model.pthï¼ˆStage 2+çš„è¾“å‡ºï¼‰
        best_model_path = os.path.join(prev_round_dir, "best_model.pth")
        if os.path.exists(best_model_path):
            return best_model_path

        # å¦‚æœæ˜¯ç¬¬ä¸€è½®ï¼ŒæŸ¥æ‰¾contrastive_trainingç›®å½•ä¸‹çš„æ¨¡å‹
        contrastive_dir = os.path.join(prev_round_dir, "contrastive_training")
        if os.path.exists(contrastive_dir):
            # æŸ¥æ‰¾best_contrastive_model.pthæˆ–ç±»ä¼¼æ–‡ä»¶
            for file in os.listdir(contrastive_dir):
                if 'best' in file and file.endswith('.pth'):
                    return os.path.join(contrastive_dir, file)

        return None

    def _find_previous_enhanced_dataset(self, round_num: int) -> Optional[str]:
        """æŸ¥æ‰¾ä¸Šä¸€è½®çš„å¢å¼ºæ•°æ®é›†"""
        prev_round_dir = os.path.join(self.experiment_dir, f"round{round_num-1}")
        consistency_dir = os.path.join(prev_round_dir, "consistency_scoring")

        if os.path.exists(consistency_dir):
            # æŸ¥æ‰¾enhanced_datasetå¼€å¤´çš„pklæ–‡ä»¶
            for root, dirs, files in os.walk(consistency_dir):
                for file in files:
                    if file.startswith('enhanced_dataset') and file.endswith('.pkl'):
                        return os.path.join(root, file)

        return None

    def _find_classifier_for_fraction(self, round_dir: str, fraction: float) -> Optional[str]:
        """æŸ¥æ‰¾æŒ‡å®šæ•°æ®æ¯”ä¾‹çš„åˆ†ç±»å™¨"""
        selection_dir = os.path.join(round_dir, "classifier_selection", "selected_models")

        if os.path.exists(selection_dir):
            for file in os.listdir(selection_dir):
                # æŸ¥æ‰¾åŒ…å«æŒ‡å®šfractionçš„jsonæ–‡ä»¶
                if f"frac{fraction}" in file and file.endswith('.json'):
                    json_path = os.path.join(selection_dir, file)
                    with open(json_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        model_path = data.get('model_path')
                        if model_path:
                            return json_path  # è¿”å›JSONè·¯å¾„ï¼Œè®©consistency_scorerå¤„ç†

        return None

    def run_single_round_with_resume(self, round_num: int) -> bool:
        """
        è¿è¡Œå•è½®å®éªŒï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

        Args:
            round_num: è½®æ¬¡ç¼–å·

        Returns:
            æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹ç¬¬ {round_num} è½®å®éªŒï¼ˆæ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼‰")
        print(f"{'='*60}")

        round_dir = os.path.join(self.experiment_dir, f"round{round_num}")
        os.makedirs(round_dir, exist_ok=True)

        round_config = self._get_round_config(round_num)

        round_key = f'round{round_num}'
        round_entry = self.experiment_log['rounds'].setdefault(round_key, {})
        if 'start_time' not in round_entry:
            round_entry['start_time'] = datetime.now().isoformat()
        round_entry.setdefault('status', 'running')
        round_entry['config'] = round_config
        self._save_log()

        # åˆ›å»ºçŠ¶æ€æ£€æµ‹å™¨
        detector = ExperimentStatusDetector(self.experiment_dir, round_num)

        # è®°å½•è½®æ¬¡å¼€å§‹
        if not self.state_manager.is_round_completed(round_num):
            self.state_manager.save_stage_in_progress(round_num, 'round_start')

        try:
            # Step 1: å¯¹æ¯”å­¦ä¹ ï¼ˆStage 1 æˆ– Stage 2+ï¼‰
            if round_num == 1:
                stage1_done, encoder_path = detector.detect_stage1_contrastive_status()
                if stage1_done and self.resume:
                    print("[è·³è¿‡] âœ… Stage 1å¯¹æ¯”å­¦ä¹ å·²å®Œæˆ")
                else:
                    print("[æ‰§è¡Œ] â–¶ï¸  å¼€å§‹Stage 1å¯¹æ¯”å­¦ä¹ ...")
                    encoder_path = self._run_stage1_contrastive(round_config, round_dir)
                    # âœ… Grid Search æ¨¡å¼ä¼šè¿”å› None
                    if encoder_path:
                        self.state_manager.save_stage_completion(round_num, 'stage1_contrastive', encoder_path)
            else:
                stage2_done, encoder_path = detector.detect_stage2_contrastive_status()
                if stage2_done and self.resume:
                    print("[è·³è¿‡] âœ… Stage 2å¯¹æ¯”å­¦ä¹ å·²å®Œæˆ")
                else:
                    print("[æ‰§è¡Œ] â–¶ï¸  å¼€å§‹Stage 2å¯¹æ¯”å­¦ä¹ ...")
                    encoder_path = self._run_stage2_weighted_contrastive(round_num, round_config, round_dir)
                    if encoder_path:
                        self.state_manager.save_stage_completion(round_num, 'stage2_contrastive', encoder_path)

            if not encoder_path:
                # âœ… Grid Search æ¨¡å¼ï¼šè·³è¿‡åç»­æµç¨‹
                print(f"\n{'='*60}")
                print(f"âš ï¸  Grid Search æ¨¡å¼ï¼šRound {round_num} ä»…ç”Ÿæˆè¯„ä¼°ç»“æœ")
                print(f"   è¯·æŸ¥çœ‹ Grid Search ç»“æœï¼Œé€‰æ‹©æœ€ä½³è¶…å‚æ•°åæ‰‹åŠ¨é…ç½®å¹¶é‡æ–°è¿è¡Œ")
                print(f"{'='*60}\n")

                # æ ‡è®°è½®æ¬¡ä¸º grid_search_only
                round_entry['status'] = 'grid_search_only'
                round_entry['end_time'] = datetime.now().isoformat()
                self._save_log()

                return True  # è¿”å›æˆåŠŸï¼Œä½†è·³è¿‡åç»­æµç¨‹

            print(f"[å®Œæˆ] ç¼–ç å™¨è®­ç»ƒå®Œæˆ: {encoder_path}")

            # Step 2: ç›‘ç£å­¦ä¹ 
            sup_done, sup_result_dir = detector.detect_supervised_learning_status()
            if sup_done and self.resume:
                print("[è·³è¿‡] âœ… ç›‘ç£å­¦ä¹ å·²å®Œæˆ")
                # ä»ç£ç›˜æ¢å¤æœ€ä¼˜æ¨¡å‹ä¿¡æ¯
                sup_output = self._load_supervised_output_from_disk(sup_result_dir)
            else:
                print("[æ‰§è¡Œ] â–¶ï¸  å¼€å§‹ç›‘ç£å­¦ä¹ ...")
                sup_output = self._run_supervised_training(encoder_path, round_config, round_dir)
                self.state_manager.save_stage_completion(round_num, 'supervised_learning', sup_output['best_model_path'])

            best_model_path = sup_output['best_model_path']
            print(f"[å®Œæˆ] ç›‘ç£å­¦ä¹ å®Œæˆ: {best_model_path}")

            # âœ… è®°å½•è¯¦ç»†æŒ‡æ ‡åˆ°å®éªŒæ—¥å¿—
            round_entry['best_model_path'] = best_model_path
            round_entry['best_hyperparams'] = sup_output['hyperparameters']
            round_entry['best_val_f1'] = sup_output.get('best_val_f1')
            round_entry['best_epoch'] = sup_output.get('best_epoch')
            round_entry['train_loss_at_best'] = sup_output.get('train_loss_at_best')
            round_entry['metrics'] = sup_output['metrics']  # {train, dev, test}
            self._save_log()

            # âŒ Step 3: åˆ†ç±»å™¨é€‰æ‹© - å·²åˆ é™¤

            # Step 4: ä¸€è‡´æ€§è¯„åˆ†
            cons_done, enhanced_dataset = detector.detect_consistency_scoring_status()
            if cons_done and self.resume:
                print("[è·³è¿‡] âœ… ä¸€è‡´æ€§è¯„åˆ†å·²å®Œæˆ")
                consistency_result_dir = os.path.join(round_dir, "consistency_scoring")
            else:
                print("[æ‰§è¡Œ] â–¶ï¸  å¼€å§‹ä¸€è‡´æ€§è¯„åˆ†...")
                consistency_result_dir = self._run_consistency_scoring(
                    best_model_path,  # âœ… ç›´æ¥ä¼ æ¨¡å‹è·¯å¾„
                    round_config,
                    round_dir
                )
                self.state_manager.save_stage_completion(round_num, 'consistency_scoring', consistency_result_dir)

            print(f"[å®Œæˆ] ä¸€è‡´æ€§è¯„åˆ†å®Œæˆ: {consistency_result_dir}")

            # è®°å½•è½®æ¬¡æˆåŠŸ
            round_entry['status'] = 'completed'
            round_entry['end_time'] = datetime.now().isoformat()
            round_entry['encoder_path'] = encoder_path
            self._save_log()

            print(f"[æˆåŠŸ] ç¬¬ {round_num} è½®å®éªŒæˆåŠŸå®Œæˆï¼")
            return True

        except Exception as e:
            print(f"[é”™è¯¯] ç¬¬ {round_num} è½®å®éªŒå¤±è´¥: {e}")
            traceback.print_exc()

            # è®°å½•è½®æ¬¡å¤±è´¥
            round_entry['status'] = 'failed'
            round_entry['error'] = str(e)
            self._save_log()

            return False

    def run_single_round(self, round_num: int) -> bool:
        """
        è¿è¡Œå•è½®å®éªŒ

        Args:
            round_num: è½®æ¬¡ç¼–å·

        Returns:
            æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹ç¬¬ {round_num} è½®å®éªŒ")
        print(f"{'='*60}")

        round_dir = os.path.join(self.experiment_dir, f"round{round_num}")
        os.makedirs(round_dir, exist_ok=True)

        round_config = self._get_round_config(round_num)

        # è®°å½•è½®æ¬¡å¼€å§‹
        self.experiment_log['rounds'][f'round{round_num}'] = {
            'start_time': datetime.now().isoformat(),
            'config': round_config,
            'status': 'running'
        }
        self._save_log()

        try:
            # Step 1: å¯¹æ¯”å­¦ä¹ ï¼ˆStage 1 æˆ– Stage 2+ï¼‰
            if round_num == 1:
                encoder_path = self._run_stage1_contrastive(round_config, round_dir)
            else:
                encoder_path = self._run_stage2_weighted_contrastive(round_num, round_config, round_dir)

            if not encoder_path:
                # âœ… Grid Search æ¨¡å¼ï¼šè·³è¿‡åç»­æµç¨‹
                print(f"\n{'='*60}")
                print(f"âš ï¸  Grid Search æ¨¡å¼ï¼šRound {round_num} ä»…ç”Ÿæˆè¯„ä¼°ç»“æœ")
                print(f"   è¯·æŸ¥çœ‹ Grid Search ç»“æœï¼Œé€‰æ‹©æœ€ä½³è¶…å‚æ•°åæ‰‹åŠ¨é…ç½®å¹¶é‡æ–°è¿è¡Œ")
                print(f"{'='*60}\n")

                # æ ‡è®°è½®æ¬¡ä¸º grid_search_only
                round_entry = self.experiment_log['rounds'][f'round{round_num}']
                round_entry['status'] = 'grid_search_only'
                round_entry['end_time'] = datetime.now().isoformat()
                self._save_log()

                return True  # è¿”å›æˆåŠŸï¼Œä½†è·³è¿‡åç»­æµç¨‹

            print(f"[å®Œæˆ] ç¼–ç å™¨è®­ç»ƒå®Œæˆ: {encoder_path}")

            # Step 2: ç›‘ç£å­¦ä¹ 
            sup_output = self._run_supervised_training(encoder_path, round_config, round_dir)
            best_model_path = sup_output['best_model_path']
            print(f"[å®Œæˆ] ç›‘ç£å­¦ä¹ å®Œæˆ: {best_model_path}")

            # âœ… è®°å½•è¯¦ç»†æŒ‡æ ‡åˆ°å®éªŒæ—¥å¿—
            round_entry = self.experiment_log['rounds'][f'round{round_num}']
            round_entry['best_model_path'] = best_model_path
            round_entry['best_hyperparams'] = sup_output['hyperparameters']
            round_entry['best_val_f1'] = sup_output.get('best_val_f1')
            round_entry['best_epoch'] = sup_output.get('best_epoch')
            round_entry['train_loss_at_best'] = sup_output.get('train_loss_at_best')
            round_entry['metrics'] = sup_output['metrics']  # {train, dev, test}
            self._save_log()

            # âŒ Step 3: åˆ†ç±»å™¨é€‰æ‹© - å·²åˆ é™¤

            # Step 4: ä¸€è‡´æ€§è¯„åˆ†
            consistency_result_dir = self._run_consistency_scoring(
                best_model_path,  # âœ… ç›´æ¥ä¼ æ¨¡å‹è·¯å¾„
                round_config,
                round_dir
            )
            print(f"[å®Œæˆ] ä¸€è‡´æ€§è¯„åˆ†å®Œæˆ: {consistency_result_dir}")

            # è®°å½•è½®æ¬¡æˆåŠŸ
            self.experiment_log['rounds'][f'round{round_num}']['status'] = 'completed'
            self.experiment_log['rounds'][f'round{round_num}']['end_time'] = datetime.now().isoformat()
            self.experiment_log['rounds'][f'round{round_num}']['encoder_path'] = encoder_path
            self._save_log()

            print(f"[æˆåŠŸ] ç¬¬ {round_num} è½®å®éªŒæˆåŠŸå®Œæˆï¼")
            return True

        except Exception as e:
            print(f"[é”™è¯¯] ç¬¬ {round_num} è½®å®éªŒå¤±è´¥: {e}")
            traceback.print_exc()

            # è®°å½•è½®æ¬¡å¤±è´¥
            self.experiment_log['rounds'][f'round{round_num}']['status'] = 'failed'
            self.experiment_log['rounds'][f'round{round_num}']['error'] = str(e)
            self._save_log()

            return False

    def _run_stage1_contrastive(self, config: Dict, round_dir: str) -> Optional[str]:
        """è¿è¡ŒStage 1å¯¹æ¯”å­¦ä¹ """
        print("[Stage 1] è¿è¡ŒStage 1å¯¹æ¯”å­¦ä¹ ï¼ˆBERTç›¸ä¼¼åº¦å‰ªæï¼‰...")

        output_dir = os.path.join(round_dir, "contrastive_training")
        os.makedirs(output_dir, exist_ok=True)

        if not run_stage1_contrastive_training:
            raise RuntimeError("Stage 1å¯¹æ¯”å­¦ä¹ æ¥å£æœªå®ç°")

        stage1_config = config.get('stage1_contrastive', {})

        # ä»å…¨å±€data_pathsè·å–æ•°æ®è·¯å¾„
        data_paths = self.config.get('data_paths', {})
        stage1_config['cl_comments_data'] = data_paths.get('cl_comments_data', 'data/cl_data/train_comments_filtered.csv')
        stage1_config['cl_posts_data'] = data_paths.get('cl_posts_data', 'data/cl_data/train_posts_filtered.csv')

        # è®¾ç½®è¾“å‡ºç›®å½•ä¸ºå®éªŒç›®å½•ï¼ˆç¡®ä¿æ•°æ®é›†ä¿å­˜åœ¨å®éªŒç›®å½•å†…ï¼‰
        stage1_config['output_dir'] = output_dir

        # âœ… ä¿®å¤ï¼šä¼ å…¥å®Œæ•´é…ç½®ï¼ˆåŒ…å« supervised_learning ç­‰ï¼‰
        result = run_stage1_contrastive_training(
            stage1_config,
            output_dir,
            self.config  # ä¼ å…¥å®Œæ•´é…ç½®æ ‘ï¼ˆç”¨äº Grid Search è¯„ä¼°ï¼‰
        )

        # âœ… å¤„ç† Grid Search è¿”å›å­—å…¸çš„æƒ…å†µ
        if isinstance(result, dict) and result.get('mode') == 'grid_search':
            # Grid Search æ¨¡å¼ï¼šä¸è¿”å›æ¨¡å‹ï¼Œè®°å½•æœ€ä½³è¶…å‚æ•°
            print(f"\n[Grid Search] å®Œæˆ {result['total_runs']} æ¬¡è¿è¡Œ")
            print(f"[Grid Search] æˆåŠŸ: {result['successful_runs']} æ¬¡")

            if result['best_hyperparameters']:
                print(f"\n[Grid Search] æœ€ä½³è¶…å‚æ•°:")
                for key, value in result['best_hyperparameters'].items():
                    print(f"   - {key}: {value}")

                print(f"\n[Grid Search] æœ€ä½³éªŒè¯é›†æŒ‡æ ‡:")
                if result['best_metrics']:
                    print(f"   - Val F1: {result['best_metrics']['val_f1']:.4f}")
                    print(f"   - Val Accuracy: {result['best_metrics']['val_accuracy']:.4f}")
                    print(f"   - Val Precision: {result['best_metrics']['val_precision']:.4f}")
                    print(f"   - Val Recall: {result['best_metrics']['val_recall']:.4f}")

            # è®°å½• Grid Search ç»“æœåˆ°å®éªŒæ—¥å¿—
            self.experiment_log['rounds'][f'round1']['grid_search'] = {
                'total_runs': result['total_runs'],
                'successful_runs': result['successful_runs'],
                'best_hyperparameters': result['best_hyperparameters'],
                'best_metrics': result['best_metrics'],
                'results_file': result['results_file']
            }

            self._save_log()

            # âš ï¸ Grid Search æ¨¡å¼ï¼šè·³è¿‡åç»­æµç¨‹ï¼ˆæ²¡æœ‰æ¨¡å‹ï¼‰
            print(f"\nâš ï¸  Grid Search æ¨¡å¼ï¼šä»…ç”Ÿæˆè¯„ä¼°ç»“æœï¼Œä¸ç»§ç»­åç»­æµç¨‹")
            print(f"   ç»“æœæ–‡ä»¶: {result['results_file']}")
            print(f"\nğŸ’¡ è¯·æŸ¥çœ‹ Grid Search ç»“æœï¼Œé€‰æ‹©æœ€ä½³è¶…å‚æ•°åæ‰‹åŠ¨é‡æ–°è®­ç»ƒ")

            return None  # è¿”å› None è¡¨ç¤ºæ²¡æœ‰æ¨¡å‹

        # å•æ¬¡è®­ç»ƒæ¨¡å¼ï¼šè¿”å›æ¨¡å‹è·¯å¾„
        model_path = result

        # âœ… ä»checkpointè¯»å–å¹¶è®°å½•æ•°æ®é›†å¤§å°åˆ°å®éªŒæ—¥å¿—
        try:
            import torch
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
            dataset_sizes = checkpoint.get('training_history', {}).get('dataset_sizes', {})
            positive_pair_strategy = checkpoint.get('positive_pair_strategy', 'unknown')

            # è·å–æœ€æ–°çš„æ•°æ®é›†å¤§å°ï¼ˆæœ€åä¸€æ¬¡æ„å»ºï¼‰
            ds1_size = dataset_sizes.get('dataset1', [0])[-1] if dataset_sizes.get('dataset1') else 0
            ds2_size = dataset_sizes.get('dataset2', [0])[-1] if dataset_sizes.get('dataset2') else 0

            # è®°å½•åˆ°å®éªŒæ—¥å¿—
            self.experiment_log['rounds'][f'round1']['dataset_info'] = {
                'dataset_path': os.path.join(output_dir, 'dataset.pkl'),
                'dataset1_size': int(ds1_size),
                'dataset2_size': int(ds2_size),
                'positive_pair_strategy': positive_pair_strategy,
                'dataset_sizes_history': {
                    'dataset1': [int(x) for x in dataset_sizes.get('dataset1', [])],
                    'dataset2': [int(x) for x in dataset_sizes.get('dataset2', [])]
                }
            }

            print(f"[è®°å½•] æ•°æ®é›†å¤§å°å·²ä¿å­˜åˆ°å®éªŒæ—¥å¿—:")
            print(f"   - ç­–ç•¥: {positive_pair_strategy}")
            print(f"   - Dataset1: {ds1_size}")
            print(f"   - Dataset2: {ds2_size}")

        except Exception as e:
            print(f"[è­¦å‘Š] æ— æ³•ä»checkpointè¯»å–æ•°æ®é›†å¤§å°: {e}")
            # é™çº§å¤„ç†ï¼šåªè®°å½•è·¯å¾„
            self.experiment_log['rounds'][f'round1']['dataset_path'] = os.path.join(output_dir, 'dataset.pkl')

        self._save_log()

        return model_path

    def _run_stage2_weighted_contrastive(self, round_num: int, config: Dict, round_dir: str) -> Optional[str]:
        """è¿è¡ŒStage 2+åŠ æƒå¯¹æ¯”å­¦ä¹ """

        # âœ… æ£€æŸ¥æ˜¯å¦æ¯è½®ä»åŸå§‹BERTé‡æ–°è®­ç»ƒ
        use_fresh_bert = self.config.get('experiment_meta', {}).get('use_fresh_bert_each_round', False)

        if use_fresh_bert:
            # ä»åŸå§‹BERTé‡æ–°è®­ç»ƒæ¨¡å¼
            stage1_config = self.config.get('defaults', {}).get('stage1_contrastive', {})
            prev_encoder = stage1_config.get('model_name_or_path', 'google-bert/bert-base-chinese')
            print(f"[Stage 2+] ä»åŸå§‹BERTé‡æ–°è®­ç»ƒï¼ˆRound {round_num}ï¼‰")
            print(f"  âœ¨ æ¨¡å¼: å›ºå®šåŸå§‹BERTåŸºåº§")
            print(f"  ä½¿ç”¨æ¨¡å‹: {prev_encoder}")
        else:
            # ç´¯ç§¯è®­ç»ƒæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            prev_encoder = self._find_previous_encoder(round_num)
            if not prev_encoder:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç¬¬{round_num-1}è½®çš„ç¼–ç å™¨")
            print(f"[Stage 2+] ç´¯ç§¯è®­ç»ƒæ¨¡å¼ï¼ˆåŸºäºç¬¬{round_num-1}è½®ï¼‰")
            print(f"  ä½¿ç”¨ç¼–ç å™¨: {prev_encoder}")

        # æŸ¥æ‰¾ä¸Šä¸€è½®çš„å¢å¼ºæ•°æ®é›†ï¼ˆä¸¤ç§æ¨¡å¼éƒ½éœ€è¦ï¼‰
        prev_enhanced_dataset = self._find_previous_enhanced_dataset(round_num)
        if not prev_enhanced_dataset:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç¬¬{round_num-1}è½®çš„å¢å¼ºæ•°æ®é›†")

        print(f"  ä½¿ç”¨å¢å¼ºæ•°æ®é›†: {prev_enhanced_dataset}")

        if not run_stage2_weighted_contrastive:
            raise RuntimeError("Stage 2åŠ æƒå¯¹æ¯”å­¦ä¹ æ¥å£æœªå®ç°")

        stage2_config = config.get('stage2_contrastive', {})
        # ç›´æ¥ä¿å­˜åˆ°roundç›®å½•ä¸‹çš„best_model.pth
        return run_stage2_weighted_contrastive(
            stage2_config, prev_encoder, prev_enhanced_dataset, round_dir, round_num
        )

    def _run_supervised_training(self, encoder_path: str, config: Dict, round_dir: str) -> Dict:
        """è¿è¡Œç›‘ç£å­¦ä¹ """
        print("[ç›‘ç£å­¦ä¹ ] è¿è¡Œç›‘ç£å­¦ä¹ è¶…å‚æ•°æœç´¢...")

        output_dir = os.path.join(round_dir, "supervised_training")
        os.makedirs(output_dir, exist_ok=True)

        if not run_supervised_training_interface:
            raise RuntimeError("ç›‘ç£å­¦ä¹ æ¥å£æœªå®ç°")

        sup_config = config.get('supervised_learning', {})

        # ä»round_diræå–è½®æ¬¡å·
        round_num = int(os.path.basename(round_dir).replace('round', ''))

        sup_result = run_supervised_training_interface(encoder_path, sup_config, output_dir, round_num)

        # âœ… ç›´æ¥è¿”å›å®Œæ•´çš„ç›‘ç£å­¦ä¹ è¾“å‡ºï¼ˆåŒ…å«best_model_pathå’Œmetricsï¼‰
        if isinstance(sup_result, dict):
            sup_result.setdefault('experiment_dir', output_dir)
            self._latest_supervised_output = sup_result
            return sup_result

        # å…¼å®¹æ—§ç‰ˆæœ¬æ¥å£ä»…è¿”å›ç›®å½•è·¯å¾„çš„æƒ…å†µï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
        self._latest_supervised_output = {
            'experiment_dir': sup_result,
            'best_model_path': None,
            'metrics': {},
            'best_epoch': None,
            'train_loss_at_best': None,
            'hyperparameters': None,
            'used_cache': False
        }
        return self._latest_supervised_output

    def _load_supervised_output_from_disk(self, sup_result_dir: str) -> Dict:
        """ä»ç›‘ç£å­¦ä¹ ç»“æœç›®å½•æ¢å¤æœ€ä½³æ¨¡å‹ä¿¡æ¯"""
        results_file = os.path.join(sup_result_dir, "all_seeds_results.json")
        if not os.path.exists(results_file):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç›‘ç£å­¦ä¹ ç»“æœæ–‡ä»¶: {results_file}")

        with open(results_file, 'r', encoding='utf-8') as f:
            all_results = json.load(f)

        # âœ… åŸºäºéªŒè¯é›†F1é€‰æ‹©æœ€ä¼˜æ¨¡å‹
        best_entry = None
        best_val_f1 = float('-inf')

        for runs in all_results.values():
            for run in runs:
                val_f1 = run.get('val_f1', float('-inf'))
                if val_f1 > best_val_f1:
                    best_val_f1 = val_f1
                    best_entry = run

        if not best_entry:
            raise RuntimeError(f"æ— æ³•ä» {results_file} æ¢å¤ç›‘ç£å­¦ä¹ æœ€ä¼˜ç»“æœ")

        model_path = best_entry.get('model_path')
        if model_path and not os.path.isabs(model_path):
            model_path = os.path.abspath(os.path.join(sup_result_dir, model_path))

        return {
            'experiment_dir': sup_result_dir,
            'best_model_path': model_path,
            'metrics': {
                'train': best_entry.get('train_metrics'),
                'dev': best_entry.get('val_metrics'),
                'test': best_entry.get('test_metrics')
            },
            'best_epoch': best_entry.get('best_epoch'),
            'train_loss_at_best': best_entry.get('train_loss_at_best'),
            'hyperparameters': best_entry.get('hyperparameters'),
            'used_cache': best_entry.get('used_cache', False),
            'best_val_f1': best_val_f1  # âœ… æ–°å¢éªŒè¯é›†F1
        }

    def _run_classifier_selection(self, sup_result_dir: str, config: Dict, round_dir: str) -> str:
        """è¿è¡Œåˆ†ç±»å™¨é€‰æ‹©"""
        print("[åˆ†ç±»å™¨é€‰æ‹©] è¿è¡Œåˆ†ç±»å™¨é€‰æ‹©...")

        output_dir = os.path.join(round_dir, "classifier_selection")
        os.makedirs(output_dir, exist_ok=True)

        if not run_classifier_selection_interface:
            raise RuntimeError("åˆ†ç±»å™¨é€‰æ‹©æ¥å£æœªå®ç°")

        selection_config = config.get('classifier_selection', {})
        return run_classifier_selection_interface(sup_result_dir, selection_config, output_dir)

    def _run_consistency_scoring(self, best_model_path: str, config: Dict, round_dir: str) -> str:
        """è¿è¡Œä¸€è‡´æ€§è¯„åˆ†"""
        print("[ä¸€è‡´æ€§è¯„åˆ†] è¿è¡Œä¸€è‡´æ€§è¯„åˆ†...")

        output_dir = os.path.join(round_dir, "consistency_scoring")
        os.makedirs(output_dir, exist_ok=True)

        scoring_config = config.get('consistency_scoring', {})

        # åŠ¨æ€è·å–æ•°æ®é›†è·¯å¾„
        dataset_path = self._find_current_dataset(round_dir)
        if not dataset_path:
            # è·å–å½“å‰è½®æ¬¡å·
            round_num = int(os.path.basename(round_dir).replace('round', ''))
            if round_num == 1:
                # ç¬¬ä¸€è½®ï¼ŒæŸ¥æ‰¾Stage 1ç”Ÿæˆçš„æ•°æ®é›†
                dataset_path = os.path.join(round_dir, "contrastive_training", "dataset.pkl")
                if not os.path.exists(dataset_path):
                    # å°è¯•æŸ¥æ‰¾å…¶ä»–æ ¼å¼çš„æ•°æ®é›†æ–‡ä»¶
                    contrastive_dir = os.path.join(round_dir, "contrastive_training")
                    if os.path.exists(contrastive_dir):
                        for file in os.listdir(contrastive_dir):
                            if file.endswith('.pkl') and 'dataset' in file:
                                dataset_path = os.path.join(contrastive_dir, file)
                                break
            else:
                # åç»­è½®æ¬¡ï¼Œä½¿ç”¨ä¸Šä¸€è½®çš„å¢å¼ºæ•°æ®é›†
                dataset_path = self._find_previous_enhanced_dataset(round_num)

        if not dataset_path:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç¬¬{round_num}è½®çš„æ•°æ®é›†")

        print(f"   ä½¿ç”¨æ•°æ®é›†: {dataset_path}")
        print(f"   ä½¿ç”¨æ¨¡å‹: {best_model_path}")
        scoring_config['dataset_path'] = dataset_path

        if not run_consistency_scoring_interface:
            raise RuntimeError("ä¸€è‡´æ€§è¯„åˆ†æ¥å£æœªå®ç°")

        # âœ… ç›´æ¥ä¼ å…¥æ¨¡å‹è·¯å¾„ï¼Œä¸å†ä¼ classifier_path
        return run_consistency_scoring_interface(
            best_model_path,  # ç›´æ¥ä¼ æ¨¡å‹è·¯å¾„
            dataset_path,
            scoring_config,
            output_dir
        )

    def _find_current_dataset(self, round_dir: str) -> Optional[str]:
        """æŸ¥æ‰¾å½“å‰è½®æ¬¡çš„æ•°æ®é›†"""
        # è·å–è½®æ¬¡å·
        round_num = int(os.path.basename(round_dir).replace('round', ''))

        if round_num == 1:
            # ç¬¬ä¸€è½®ï¼šæŸ¥æ‰¾Stage 1ç”Ÿæˆçš„æ•°æ®é›†
            dataset_path = os.path.join(round_dir, "contrastive_training", "dataset.pkl")
            if os.path.exists(dataset_path):
                return dataset_path

            # æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ•°æ®é›†æ–‡ä»¶
            contrastive_dir = os.path.join(round_dir, "contrastive_training")
            if os.path.exists(contrastive_dir):
                for file in os.listdir(contrastive_dir):
                    if file.endswith('.pkl') and 'dataset' in file:
                        return os.path.join(contrastive_dir, file)
        else:
            # åç»­è½®æ¬¡ï¼šä½¿ç”¨ä¸Šä¸€è½®çš„å¢å¼ºæ•°æ®é›†
            return self._find_previous_enhanced_dataset(round_num)

        return None

    def _get_selected_rounds(self) -> List[int]:
        """è·å–è¦è¿è¡Œçš„è½®æ¬¡åˆ—è¡¨"""
        return self.config['experiment_meta'].get('rounds', [1, 2, 3])

    def run_experiment(self, rounds: Optional[List[int]] = None, start_round: Optional[int] = None,
                       target_round: Optional[int] = None):
        """
        è¿è¡Œå®Œæ•´çš„è¿­ä»£å®éªŒï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

        Args:
            rounds: æŒ‡å®šè¦è¿è¡Œçš„è½®æ¬¡åˆ—è¡¨
            start_round: ä»æŸè½®å¼€å§‹
            target_round: ç›®æ ‡è½®æ¬¡ï¼ˆè¿è¡Œåˆ°æ­¤è½®ç»“æŸï¼‰
        """
        # å¦‚æœå¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œé¦–å…ˆæ£€æŸ¥å®éªŒçŠ¶æ€
        if self.resume and not self.force_restart:
            print("\nğŸ” æ£€æµ‹å·²æœ‰å®éªŒçŠ¶æ€...")
            print_experiment_status(self.experiment_dir, target_round or 3)

            if not self.state_manager.validate_config_compatibility():
                response = input("\nâš ï¸  é…ç½®æ–‡ä»¶å·²æ›´æ”¹ï¼Œæ˜¯å¦ç»§ç»­ä½¿ç”¨æ–°é…ç½®ï¼Ÿ(y/n): ")
                if response.lower() != 'y':
                    print("å®éªŒå·²å–æ¶ˆ")
                    return

            print(self.state_manager.get_progress_summary())

        # ç¡®å®šè¦è¿è¡Œçš„è½®æ¬¡
        if rounds:
            selected_rounds = rounds
        elif target_round:
            selected_rounds = list(range(1, target_round + 1))
        else:
            selected_rounds = self._get_selected_rounds()

        if start_round:
            selected_rounds = [r for r in selected_rounds if r >= start_round]

        print(f"\nè®¡åˆ’è¿è¡Œè½®æ¬¡: {selected_rounds}")

        success_rounds = []
        failed_rounds = []
        skipped_rounds = []

        for round_num in selected_rounds:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
            if self._should_skip_round(round_num):
                print(f"[è·³è¿‡] è·³è¿‡ç¬¬ {round_num} è½®ï¼ˆé…ç½®ä¸­æ ‡è®°ä¸ºskipï¼‰")
                skipped_rounds.append(round_num)
                continue

            # å¦‚æœå¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œæ£€æŸ¥è½®æ¬¡æ˜¯å¦å·²å®Œæˆ
            if self.resume and self.state_manager.is_round_completed(round_num):
                print(f"[è·³è¿‡] âœ… ç¬¬ {round_num} è½®å·²å®Œæˆ")
                skipped_rounds.append(round_num)
                success_rounds.append(round_num)
                continue

            # è¿è¡Œå•è½®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
            if self.resume:
                success = self.run_single_round_with_resume(round_num)
            else:
                success = self.run_single_round(round_num)

            if success:
                success_rounds.append(round_num)
            else:
                failed_rounds.append(round_num)
                # å¦‚æœæŸè½®å¤±è´¥ï¼Œåç»­è½®æ¬¡å¯èƒ½ä¾èµ–å®ƒï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
                if round_num < max(selected_rounds):
                    response = input(f"ç¬¬ {round_num} è½®å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­åç»­è½®æ¬¡ï¼Ÿ(y/n): ")
                    if response.lower() != 'y':
                        break

        # å®éªŒæ€»ç»“
        print(f"\n{'='*60}")
        print(f"å®éªŒæ€»ç»“")
        print(f"{'='*60}")
        print(f"[æˆåŠŸ] æˆåŠŸè½®æ¬¡: {success_rounds}")
        print(f"[è·³è¿‡] è·³è¿‡è½®æ¬¡: {skipped_rounds}")
        print(f"[å¤±è´¥] å¤±è´¥è½®æ¬¡: {failed_rounds}")
        print(f"å®éªŒç›®å½•: {self.experiment_dir}")
        print(f"å®éªŒæ—¥å¿—: {self.log_file}")

        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        self.experiment_log['end_time'] = datetime.now().isoformat()
        self.experiment_log['summary'] = {
            'success_rounds': success_rounds,
            'failed_rounds': failed_rounds,
            'skipped_rounds': skipped_rounds,
            'total_rounds': len(success_rounds) + len(failed_rounds) + len(skipped_rounds)
        }
        self._save_log()

    def _should_skip_round(self, round_num: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æŸè½®"""
        if 'round_specific' in self.config:
            round_config = self.config['round_specific'].get(round_num, {})
            return round_config.get('skip', False)
        return False

    def _copy_contrastive_only(self, source_dir: str, target_dir: str):
        """
        åªå¤åˆ¶å¯¹æ¯”å­¦ä¹ ç»“æœåˆ°ç›®æ ‡ç›®å½•
        ç”¨äºåŠ å™ªå®éªŒï¼Œåªå…±äº«ç¼–ç å™¨ï¼Œå…¶ä»–é˜¶æ®µé‡æ–°è®­ç»ƒ

        Args:
            source_dir: æºå®éªŒç›®å½•
            target_dir: ç›®æ ‡å˜ä½“ç›®å½•
        """
        print(f"   [å¤åˆ¶æ¨¡å¼] åªå¤åˆ¶ Round 1 å¯¹æ¯”å­¦ä¹ ç»“æœ")
        print(f"   [è¯´æ˜] ç›‘ç£å­¦ä¹ ã€åˆ†ç±»å™¨é€‰æ‹©ã€ä¸€è‡´æ€§è¯„åˆ†å°†é‡æ–°è®­ç»ƒ")

        source_round1 = os.path.join(source_dir, 'round1')
        target_round1 = os.path.join(target_dir, 'round1')
        os.makedirs(target_round1, exist_ok=True)

        # åªå¤åˆ¶ contrastive_training
        source_contrastive = os.path.join(source_round1, 'contrastive_training')
        if not os.path.exists(source_contrastive):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°å¯¹æ¯”å­¦ä¹ ç»“æœ: {source_contrastive}")

        target_contrastive = os.path.join(target_round1, 'contrastive_training')
        if os.path.exists(target_contrastive):
            shutil.rmtree(target_contrastive)

        shutil.copytree(source_contrastive, target_contrastive)
        print(f"    âœ… å·²å¤åˆ¶: round1/contrastive_training")
        print(f"    â­ï¸  è·³è¿‡: supervised_training, classifier_selection, consistency_scoring")

    def _copy_round1_results(self, source_dir: str, target_dir: str,
                             include_dirs: Optional[List[str]] = None,
                             skip_dirs: Optional[List[str]] = None):
        """
        print("[è­¦å‘Š] run_noise_variants_legacy å·²å¼ƒç”¨ï¼Œå°†è½¬å‘åˆ° run_noise_variantsã€‚")
        return self.run_noise_variants(
            target_round=target_round,
            noise_params=noise_params,
            variant_dir_prefix=variant_dir_prefix
        )
        å¤åˆ¶ Round 1 ç»“æœåˆ°ç›®æ ‡å®éªŒï¼ˆå…è®¸æŒ‡å®šéœ€è¦å¤ç”¨çš„å­ç›®å½•ï¼Œå¹¶æ¸…ç†éœ€è¦é‡æ–°ç”Ÿæˆçš„ç›®å½•ï¼‰
        """
        include_dirs = include_dirs or ['contrastive_training', 'supervised_training', 'classifier_selection']
        skip_dirs = skip_dirs or []

        source_round1 = os.path.join(source_dir, 'round1')
        target_round1 = os.path.join(target_dir, 'round1')
        os.makedirs(target_round1, exist_ok=True)

        for subdir in include_dirs:
            src = os.path.join(source_round1, subdir)
            if not os.path.exists(src):
                raise FileNotFoundError(f"æœªæ‰¾åˆ°è¦å¤ç”¨çš„ç›®å½•: {src}")
            dst = os.path.join(target_round1, subdir)
            if os.path.exists(dst):
                shutil.rmtree(dst)
            shutil.copytree(src, dst)
            print(f"   âœ… å·²å¤åˆ¶: round1/{subdir}")

        for subdir in skip_dirs:
            dst = os.path.join(target_round1, subdir)
            if os.path.exists(dst):
                shutil.rmtree(dst)
                print(f"   â™»ï¸ å·²æ¸…ç†: round1/{subdir}")

    def run_scoring_fraction_variants(self, target_round: int = 3,
                                      scoring_fractions: List[float] = None,
                                      variant_dir_prefix: str = None):
        """
        è¿è¡Œå¤šä¸ªå˜ä½“å®éªŒï¼Œåªæ”¹å˜consistency_scoring_fractionå‚æ•°

        å¤ç”¨ç­–ç•¥ï¼š
        1. å¤åˆ¶ Round 1 çš„å¯¹æ¯”å­¦ä¹ ã€ç›‘ç£å­¦ä¹ ã€åˆ†ç±»å™¨é€‰æ‹©ç»“æœ
        2. ä¸å¤åˆ¶ consistency_scoringï¼ˆå› ä¸ºè¦ç”¨ä¸åŒæ•°æ®æ¯”ä¾‹é‡æ–°ç”Ÿæˆï¼‰
        3. åŸºäºä¸åŒçš„æ•°æ®æ¯”ä¾‹é‡æ–°è¿è¡Œä¸€è‡´æ€§è¯„åˆ†
        4. ç»§ç»­è¿è¡Œ Round 2-N

        Args:
            target_round: ç›®æ ‡è½®æ¬¡
            scoring_fractions: ä¸åŒçš„æ•°æ®æ¯”ä¾‹åˆ—è¡¨ï¼Œå¦‚ [0.05, 0.1, 0.2]
            variant_dir_prefix: å˜ä½“ç›®å½•å‰ç¼€ï¼Œå¦‚æœæŒ‡å®šåˆ™ä½¿ç”¨è¯¥å‰ç¼€è€ŒéåŸºç¡€ç›®å½•å
        """
        print(f"\n{'='*60}")
        print(f"å¤šå˜ä½“å®éªŒï¼šä¸åŒåˆ†ç±»å™¨é€‰æ‹©æ¯”ä¾‹")
        print(f"{'='*60}")

        if not scoring_fractions:
            scoring_fractions = [0.05, 0.1, 0.2]  # é»˜è®¤å€¼

        print(f"å°†æµ‹è¯•ä»¥ä¸‹æ•°æ®æ¯”ä¾‹çš„åˆ†ç±»å™¨ï¼š{scoring_fractions}")
        print(f"[å¤ç”¨ç­–ç•¥] å¤åˆ¶Round 1çš„å¯¹æ¯”å­¦ä¹ ã€ç›‘ç£å­¦ä¹ ã€åˆ†ç±»å™¨é€‰æ‹©")
        print(f"[é‡æ–°è¿è¡Œ] åŸºäºä¸åŒæ•°æ®æ¯”ä¾‹é‡æ–°è¿è¡Œä¸€è‡´æ€§è¯„åˆ†")

        # æ£€æŸ¥åŸºç¡€å®éªŒçš„Round 1æ˜¯å¦å­˜åœ¨
        source_round1 = os.path.join(self.experiment_dir, 'round1')
        if not os.path.exists(source_round1):
            raise FileNotFoundError(f"åŸºç¡€å®éªŒçš„ Round 1 ä¸å­˜åœ¨: {source_round1}\nè¯·å…ˆè¿è¡Œ: python iterative_main.py -c config.yaml -d {self.experiment_dir} --rounds 1")

        # ä¸ºæ¯ä¸ªæ¯”ä¾‹åˆ›å»ºä¸€ä¸ªå˜ä½“
        for fraction in scoring_fractions:
            print(f"\n{'='*40}")
            print(f"è¿è¡Œå˜ä½“ï¼šæ•°æ®æ¯”ä¾‹ = {fraction}")
            print(f"{'='*40}")

            # åˆ›å»ºå˜ä½“ç›®å½•å
            fraction_str = str(fraction).replace('.', '_')
            if variant_dir_prefix:
                variant_dir = f"{variant_dir_prefix}_frac{fraction_str}"
            else:
                variant_dir = f"{self.experiment_dir}_frac{fraction_str}"

            # å¤åˆ¶é…ç½®å¹¶ä¿®æ”¹consistency_scoring_fraction
            import copy
            variant_config = copy.deepcopy(self.config)

            # ä¿®æ”¹ä¸€è‡´æ€§è¯„åˆ†ä½¿ç”¨çš„æ•°æ®æ¯”ä¾‹
            if 'defaults' not in variant_config:
                variant_config['defaults'] = {}
            if 'classifier_selection' not in variant_config['defaults']:
                variant_config['defaults']['classifier_selection'] = {}

            variant_config['defaults']['classifier_selection']['consistency_scoring_fraction'] = fraction

            # åˆ›å»ºæ–°çš„ç®¡ç†å™¨å®ä¾‹è¿è¡Œè¿™ä¸ªå˜ä½“
            # ä¿å­˜å˜ä½“é…ç½®åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False, encoding='utf-8') as tmp_config:
                yaml.dump(variant_config, tmp_config, allow_unicode=True)
                tmp_config_path = tmp_config.name

            try:
                variant_manager = IterativeExperimentManager(
                    config_path=tmp_config_path,  # ä½¿ç”¨ä¸´æ—¶é…ç½®æ–‡ä»¶
                    experiment_dir=variant_dir,
                    resume=False,
                    force_restart=False
                )
                variant_manager.experiment_name = f"{self.experiment_name}_frac{fraction_str}"

                # å¤åˆ¶Round 1ï¼ˆæ’é™¤consistency_scoringï¼‰
                print(f"\nğŸ“ å¤åˆ¶åŸºç¡€å®éªŒçš„ Round 1 éƒ¨åˆ†ç»“æœ...")
                target_round1 = os.path.join(variant_dir, 'round1')
                os.makedirs(target_round1, exist_ok=True)

                # å¤åˆ¶å¯¹æ¯”å­¦ä¹ 
                source_contrastive = os.path.join(source_round1, 'contrastive_training')
                if os.path.exists(source_contrastive):
                    target_contrastive = os.path.join(target_round1, 'contrastive_training')
                    if os.path.exists(target_contrastive):
                        shutil.rmtree(target_contrastive)
                    shutil.copytree(source_contrastive, target_contrastive)
                    print(f"    âœ… å·²å¤åˆ¶: round1/contrastive_training")

                # å¤åˆ¶ç›‘ç£å­¦ä¹ 
                source_supervised = os.path.join(source_round1, 'supervised_training')
                if os.path.exists(source_supervised):
                    target_supervised = os.path.join(target_round1, 'supervised_training')
                    if os.path.exists(target_supervised):
                        shutil.rmtree(target_supervised)
                    shutil.copytree(source_supervised, target_supervised)
                    print(f"    âœ… å·²å¤åˆ¶: round1/supervised_training")

                # å¤åˆ¶åˆ†ç±»å™¨é€‰æ‹©
                source_classifier = os.path.join(source_round1, 'classifier_selection')
                if os.path.exists(source_classifier):
                    target_classifier = os.path.join(target_round1, 'classifier_selection')
                    if os.path.exists(target_classifier):
                        shutil.rmtree(target_classifier)
                    shutil.copytree(source_classifier, target_classifier)
                    print(f"    âœ… å·²å¤åˆ¶: round1/classifier_selection")

                # ä¸å¤åˆ¶consistency_scoringï¼Œå°†é‡æ–°è¿è¡Œ
                print(f"    â­ï¸  è·³è¿‡: round1/consistency_scoring (å°†é‡æ–°è¿è¡Œ)")

                # ä»Round 1çš„ä¸€è‡´æ€§è¯„åˆ†å¼€å§‹è¿è¡Œï¼ˆåªè¿è¡Œconsistency_scoringï¼‰
                print(f"\nğŸš€ é‡æ–°è¿è¡ŒRound 1çš„ä¸€è‡´æ€§è¯„åˆ†ï¼ˆä½¿ç”¨æ•°æ®æ¯”ä¾‹={fraction}ï¼‰...")

                # è·å–Round 1çš„é…ç½®
                round1_config = variant_manager._get_round_config(1)

                # è¿è¡Œä¸€è‡´æ€§è¯„åˆ†
                classifier_selection_dir = os.path.join(target_round1, 'classifier_selection')
                consistency_result_dir = variant_manager._run_consistency_scoring(
                    classifier_selection_dir, round1_config, target_round1
                )
                print(f"[å®Œæˆ] Round 1ä¸€è‡´æ€§è¯„åˆ†å®Œæˆ: {consistency_result_dir}")

                # å¦‚æœtarget_round > 1ï¼Œç»§ç»­è¿è¡Œåç»­è½®æ¬¡
                if target_round > 1:
                    print(f"\nğŸš€ ç»§ç»­è¿è¡Œ Round 2-{target_round}...")
                    variant_manager.run_experiment(start_round=2, target_round=target_round)

                print(f"\nâœ… å˜ä½“ frac{fraction_str} å®Œæˆ")
            except Exception as e:
                print(f"\nâŒ å˜ä½“ frac{fraction_str} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            finally:
                # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
                if os.path.exists(tmp_config_path):
                    os.remove(tmp_config_path)

        print(f"\n{'='*60}")
        print("æ‰€æœ‰å˜ä½“å®éªŒå®Œæˆï¼")
        print(f"åŸºç¡€ç›®å½•: {self.experiment_dir}")
        print("å˜ä½“ç›®å½•:")
        for fraction in scoring_fractions:
            fraction_str = str(fraction).replace('.', '_')
            print(f"  - {self.experiment_dir}_frac{fraction_str}")
        print(f"{'='*60}")

    def run_noise_variants_legacy(self, target_round: int = 3,
                          noise_params: List[str] = None,
                          variant_dir_prefix: str = None):
        """
        è¿è¡Œ Round 1 ç›‘ç£å­¦ä¹ åŠ å™ªå®éªŒï¼ˆçº¯å‘½ä»¤è¡Œé©±åŠ¨ï¼‰

        Args:
            target_round: ç›®æ ‡è½®æ¬¡
            noise_params: åŠ å™ªå‚æ•°ç»„åˆåˆ—è¡¨ï¼Œæ ¼å¼ ["epoch,lr[,batch_size]", ...]
                         ä¾‹å¦‚ï¼š["5,1e-5", "10,1e-4,64", "20,5e-5,128"]
                         batch_sizeå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
            variant_dir_prefix: å˜ä½“ç›®å½•å‰ç¼€
        """
        print(f"\n{'='*60}")
        print(f"Round 1 ç›‘ç£å­¦ä¹ åŠ å™ªé²æ£’æ€§å®éªŒï¼ˆçº¯å‘½ä»¤è¡Œï¼‰")
        print(f"{'='*60}")

        if not noise_params:
            raise ValueError("å¿…é¡»æä¾› --noise-params å‚æ•°")

        # è§£æå¹¶éªŒè¯å‚æ•°
        parsed_params = []
        print(f"\nå°†åˆ›å»º {len(noise_params)} ä¸ªåŠ å™ªå˜ä½“:")
        for param_str in noise_params:
            try:
                parts = param_str.split(',')
                if len(parts) < 2 or len(parts) > 3:
                    raise ValueError(f"æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º 'epoch,lr[,batch_size]'")

                epochs = int(parts[0].strip())
                lr = float(parts[1].strip())
                batch_size = int(parts[2].strip()) if len(parts) == 3 else None

                parsed_params.append((epochs, lr, batch_size, param_str))

                if batch_size is not None:
                    print(f"  - epoch={epochs}, lr={lr}, batch_size={batch_size}")
                else:
                    print(f"  - epoch={epochs}, lr={lr}, batch_size=<ä½¿ç”¨é…ç½®é»˜è®¤å€¼>")

            except Exception as e:
                raise ValueError(f"è§£æå‚æ•°å¤±è´¥ '{param_str}': {e}")

        print(f"\nå®éªŒè¯´æ˜:")
        print(f"  1. å…±äº« Round 1 å¯¹æ¯”å­¦ä¹ ç¼–ç å™¨ï¼ˆæ¥è‡ªåŸºç¡€å®éªŒï¼‰")
        print(f"  2. Round 1 ç›‘ç£å­¦ä¹ ä½¿ç”¨åŠ å™ªå‚æ•°ï¼ˆé‡æ–°è®­ç»ƒï¼‰")
        print(f"  3. Round 2-{target_round} ä½¿ç”¨é…ç½®æ–‡ä»¶çš„æ­£å¸¸å‚æ•°")

        # åˆ›å»ºå¹¶è¿è¡Œå„å˜ä½“
        for epochs, lr, batch_size, param_str in parsed_params:
            print(f"\n{'='*40}")
            if batch_size is not None:
                print(f"è¿è¡Œå˜ä½“: epoch={epochs}, lr={lr}, batch_size={batch_size}")
            else:
                print(f"è¿è¡Œå˜ä½“: epoch={epochs}, lr={lr}, batch_size=<é»˜è®¤>")
            print(f"{'='*40}")

            # åŠ¨æ€ç”Ÿæˆå˜ä½“åç§°å’Œç›®å½•
            if batch_size is not None:
                variant_name = f"noise_epoch{epochs}_lr{lr:.0e}_bs{batch_size}"
            else:
                variant_name = f"noise_epoch{epochs}_lr{lr:.0e}"

            if variant_dir_prefix:
                variant_dir = f"{variant_dir_prefix}_{variant_name}"
            else:
                variant_dir = f"{self.experiment_dir}_{variant_name}"

            # åŠ¨æ€åˆ›å»ºå˜ä½“é…ç½®ï¼ˆåŸºäºå½“å‰é…ç½®ï¼‰
            import copy
            variant_config = copy.deepcopy(self.config)

            # æ·»åŠ å˜ä½“å…ƒä¿¡æ¯
            noise_params_info = {
                'round': 1,
                'stage': 'supervised_learning',
                'epochs': epochs,
                'learning_rate': lr
            }
            if batch_size is not None:
                noise_params_info['batch_size'] = batch_size

            variant_config['variant_meta'] = {
                'type': 'noise_robustness',
                'base_experiment': self.experiment_dir,
                'noise_params': noise_params_info,
                'creation_time': datetime.now().isoformat()
            }

            # è®¾ç½® round_specific è¦†ç›–ï¼ˆåªå½±å“ Round 1ï¼‰
            round_specific = variant_config.setdefault('round_specific', {})
            round1_overrides = copy.deepcopy(round_specific.get(1, {}))
            sup_overrides = copy.deepcopy(round1_overrides.get('supervised_learning', {}))

            # ç›‘ç£å­¦ä¹ æ¥å£è¦æ±‚å¯è¿­ä»£çš„è¶…å‚æ•°ï¼Œå°è£…ä¸ºå•å…ƒç´ åˆ—è¡¨ç¡®ä¿å…¼å®¹
            sup_overrides['epochs'] = [epochs]
            sup_overrides['learning_rate'] = [lr]
            if batch_size is not None:
                sup_overrides['batch_size'] = [batch_size]

            round1_overrides['supervised_learning'] = sup_overrides
            round_specific[1] = round1_overrides

            # ä¿å­˜å˜ä½“é…ç½®åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False, encoding='utf-8') as tmp_config:
                yaml.dump(variant_config, tmp_config, allow_unicode=True)
                tmp_config_path = tmp_config.name

            try:
                # åˆ›å»ºå˜ä½“å®éªŒç®¡ç†å™¨
                variant_manager = IterativeExperimentManager(
                    config_path=tmp_config_path,
                    experiment_dir=variant_dir,
                    resume=True,
                    force_restart=False
                )
                variant_manager.experiment_name = f"{self.experiment_name}_{variant_name}"

                # åªå¤åˆ¶å¯¹æ¯”å­¦ä¹ ç»“æœï¼ˆå…³é”®æ­¥éª¤ï¼‰
                print(f"\nğŸ“ å¤åˆ¶åŸºç¡€å®éªŒçš„ Round 1 å¯¹æ¯”å­¦ä¹ åˆ°å˜ä½“ç›®å½•...")
                self._copy_contrastive_only(self.experiment_dir, variant_dir)

                # è¿è¡Œå®éªŒï¼ˆä» Round 1 å¼€å§‹ï¼Œä¼šé‡æ–°è®­ç»ƒç›‘ç£å­¦ä¹ ï¼‰
                print(f"\nğŸš€ å¼€å§‹è¿è¡Œå˜ä½“å®éªŒ...")
                if batch_size is not None:
                    print(f"   Round 1: ä½¿ç”¨åŠ å™ªå‚æ•°ï¼ˆepoch={epochs}, lr={lr}, batch_size={batch_size}ï¼‰")
                else:
                    print(f"   Round 1: ä½¿ç”¨åŠ å™ªå‚æ•°ï¼ˆepoch={epochs}, lr={lr}, batch_size=<é»˜è®¤>ï¼‰")
                print(f"   Round 2-{target_round}: ä½¿ç”¨æ­£å¸¸å‚æ•°")

                variant_manager.run_experiment(
                    start_round=1,
                    target_round=target_round
                )
                print(f"\nâœ… å˜ä½“å®Œæˆ: {variant_dir}")

            except Exception as e:
                print(f"\nâŒ å˜ä½“å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            finally:
                # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
                if os.path.exists(tmp_config_path):
                    os.remove(tmp_config_path)

        print(f"\n{'='*60}")
        print("æ‰€æœ‰åŠ å™ªå˜ä½“å®éªŒå®Œæˆï¼")
        print(f"{'='*60}")
        print(f"åŸºç¡€å®éªŒç›®å½•: {self.experiment_dir}")
        print("å˜ä½“ç›®å½•:")
        for epochs, lr, batch_size, _ in parsed_params:
            if batch_size is not None:
                variant_name = f"noise_epoch{epochs}_lr{lr:.0e}_bs{batch_size}"
            else:
                variant_name = f"noise_epoch{epochs}_lr{lr:.0e}"

            if variant_dir_prefix:
                print(f"  - {variant_dir_prefix}_{variant_name}")
            else:
                print(f"  - {self.experiment_dir}_{variant_name}")
        print(f"{'='*60}")

    def run_noise_variants(self, target_round: int = 3,
                          noise_params: List[str] = None,
                          variant_dir_prefix: str = None,
                          noise_mode: str = 'by_bins',
                          noise_threshold: float = 0.4,
                          noise_pool: str = '0.0-0.01',
                          noise_target_bins: Optional[str] = None,
                          noise_seed: Optional[int] = None):
        """
        è¿è¡Œ Round 1 ä¸€è‡´æ€§è¯„åˆ†å™ªå£°å®éªŒï¼ˆå¤ç”¨å¯¹æ¯”å­¦ä¹ ä¸ç›‘ç£å­¦ä¹ ç»“æœï¼Œä»…æ‰°åŠ¨ä¸€è‡´æ€§æ•°æ®é›†ï¼‰
        """
        print(f"\n{'='*60}")
        print("Round 1 ä¸€è‡´æ€§è¯„åˆ†å™ªå£°å®éªŒï¼ˆä»…å‘½ä»¤è¡Œé…ç½®ï¼‰")
        print(f"{'='*60}")

        if not noise_params:
            raise ValueError("å¿…é¡»æä¾› --noise-params å‚æ•°ï¼Œä¾‹å¦‚ï¼š--noise-params 0.05 0.1")

        def _parse_range(value: str, default: Tuple[float, float]) -> Tuple[float, float]:
            cleaned = value.replace('[', '').replace(']', '').strip()
            delimiter = '-' if '-' in cleaned else ','
            parts = [p.strip() for p in cleaned.split(delimiter) if p.strip()]
            if len(parts) != 2:
                return default
            try:
                return float(parts[0]), float(parts[1])
            except ValueError:
                return default

        def _parse_bins(value: Optional[str], default: List[Tuple[float, float]]) -> List[Tuple[float, float]]:
            if not value:
                return default
            bins = []
            for chunk in value.split(','):
                chunk = chunk.strip()
                if not chunk:
                    continue
                rng = _parse_range(chunk, None)
                if rng:
                    bins.append(rng)
            return bins or default

        base_noise_pool = _parse_range(noise_pool, (0.0, 0.01))
        default_bins = [(noise_threshold, 0.6), (0.6, 0.8), (0.8, 1.0)]
        base_target_bins = _parse_bins(noise_target_bins, default_bins)

        def _format_fraction(frac: float) -> str:
            return f"{frac:.3f}".rstrip('0').rstrip('.')

        def _sanitize_token(token: str) -> str:
            return token.replace('.', 'p').replace('-', 'to').replace(',', '_').replace(' ', '')

        def _format_range_for_suffix(rng: Tuple[float, float]) -> str:
            return _sanitize_token(f"{rng[0]:.2f}-{rng[1]:.2f}")

        def _parse_noise_param(param_str: str, base_settings: dict) -> dict:
            import copy
            settings = copy.deepcopy(base_settings)
            settings['fraction'] = None
            settings['label'] = None

            segments = [seg.strip() for seg in param_str.replace('|', ';').split(';') if seg.strip()]
            for seg in segments:
                if '=' in seg:
                    key, value = seg.split('=', 1)
                    key = key.strip().lower()
                    value = value.strip()
                    if key in ('fraction', 'frac', 'ratio', 'percent', 'percentage', 'p'):
                        settings['fraction'] = float(value)
                    elif key == 'mode':
                        settings['mode'] = value
                    elif key in ('threshold', 'noise_threshold'):
                        settings['threshold'] = float(value)
                    elif key in ('noise_pool', 'pool'):
                        settings['noise_pool'] = _parse_range(value, settings['noise_pool'])
                    elif key in ('target_bins', 'bins'):
                        settings['target_bins'] = _parse_bins(value, settings['target_bins'])
                    elif key == 'seed':
                        settings['seed'] = int(value)
                    elif key in ('apply', 'apply_to_dataset', 'write_back'):
                        settings['apply_to_dataset'] = value.lower() in ('true', '1', 'yes', 'y')
                    elif key in ('label', 'name', 'suffix'):
                        settings['label'] = value
                    else:
                        print(f" [è­¦å‘Š] æœªè¯†åˆ«çš„å™ªå£°å‚æ•°é”®: {key}ï¼Œå·²å¿½ç•¥")
                else:
                    settings['fraction'] = float(seg)

            if settings.get('fraction') is None:
                raise ValueError(f"å™ªå£°å‚æ•° '{param_str}' ç¼ºå°‘ fraction é…ç½®")

            if settings['mode'] != 'by_bins':
                settings['target_bins'] = None

            return settings

        base_settings = {
            'mode': noise_mode,
            'threshold': noise_threshold,
            'noise_pool': base_noise_pool,
            'target_bins': base_target_bins,
            'seed': noise_seed,
            'apply_to_dataset': False
        }

        parsed_variants = []
        print(f"\nå°†åˆ›å»º {len(noise_params)} ä¸ªå™ªå£°å˜ä½“ï¼š")
        for param_str in noise_params:
            settings = _parse_noise_param(param_str, base_settings)
            parsed_variants.append(settings)
            bins_desc = settings['target_bins'] if settings['target_bins'] else [(settings['threshold'], 1.0)]
            bins_text = ', '.join([f"{b[0]}-{b[1]}" for b in bins_desc])
            print(f"  - fraction={settings['fraction']}, mode={settings['mode']}, bins={bins_text}, pool={settings['noise_pool']}, apply_to_dataset={settings.get('apply_to_dataset', False)}")

        print("\nå®éªŒè¯´æ˜ï¼š")
        print("  1. å¤ç”¨ Round 1 å¯¹æ¯”å­¦ä¹ ã€ç›‘ç£å­¦ä¹ å’Œåˆ†ç±»å™¨é€‰æ‹©ç»“æœ")
        print("  2. åªåœ¨ä¸€è‡´æ€§è¯„åˆ†é˜¶æ®µæ³¨å…¥å™ªå£°ï¼Œç”Ÿæˆæ–°çš„å¢å¼ºæ•°æ®é›†")
        print(f"  3. Round 2-{target_round} æŒ‰åŸé…ç½®ç»§ç»­è¿­ä»£")

        import copy
        import tempfile

        variant_records = []

        for settings in parsed_variants:
            fraction_tag = _format_fraction(settings['fraction']).replace('.', '_')
            if settings.get('label'):
                label_suffix = settings['label']
            else:
                auto_parts = [settings['mode'], f"frac{fraction_tag}"]
                if settings.get('target_bins'):
                    bins_token = 'bins' + '_'.join(_format_range_for_suffix(b) for b in settings['target_bins'])
                    auto_parts.append(bins_token)
                else:
                    auto_parts.append(_sanitize_token(f"thr{settings['threshold']:.2f}"))
                pool_token = 'pool' + _format_range_for_suffix(settings['noise_pool'])
                auto_parts.append(pool_token)
                if settings.get('seed') is not None:
                    auto_parts.append(f"seed{settings['seed']}")
                if settings.get('apply_to_dataset', False):
                    auto_parts.append('apply')
                label_suffix = '_'.join(auto_parts)
            variant_name = f"noise_{label_suffix}"

            if variant_dir_prefix:
                variant_dir = f"{variant_dir_prefix}_{label_suffix}"
            else:
                variant_dir = f"{self.experiment_dir}_{label_suffix}"

            print(f"\n{'='*40}")
            print(f"è¿è¡Œå˜ä½“: {variant_name}")
            print(f"  fraction={settings['fraction']}, mode={settings['mode']}, threshold={settings['threshold']}, pool={settings['noise_pool']}")
            if settings.get('target_bins'):
                print(f"  target_bins={settings['target_bins']}")
            if settings.get('seed') is not None:
                print(f"  seed={settings['seed']}")
            print(f"  apply_to_dataset={settings.get('apply_to_dataset', False)}")
            print(f"{'='*40}")

            variant_config = copy.deepcopy(self.config)
            noise_config = {
                'enabled': True,
                'mode': settings['mode'],
                'threshold': settings['threshold'],
                'fraction': settings['fraction'],
                'noise_pool': list(settings['noise_pool']),
                'target_bins': [list(b) for b in settings.get('target_bins') or []],
                'seed': settings.get('seed'),
                'apply_to_dataset': settings.get('apply_to_dataset', False)
            }

            variant_config['variant_meta'] = {
                'type': 'noise_robustness',
                'base_experiment': self.experiment_dir,
                'noise_params': noise_config,
                'creation_time': datetime.now().isoformat()
            }

            round_specific = variant_config.setdefault('round_specific', {})
            round1_overrides = copy.deepcopy(round_specific.get(1, {}))
            consistency_overrides = copy.deepcopy(round1_overrides.get('consistency_scoring', {}))
            consistency_overrides['noise_injection'] = noise_config
            round1_overrides['consistency_scoring'] = consistency_overrides
            round_specific[1] = round1_overrides

            with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False, encoding='utf-8') as tmp_config:
                yaml.dump(variant_config, tmp_config, allow_unicode=True)
                tmp_config_path = tmp_config.name

            try:
                variant_manager = IterativeExperimentManager(
                    config_path=tmp_config_path,
                    experiment_dir=variant_dir,
                    resume=True,
                    force_restart=False
                )
                variant_manager.experiment_name = f"{self.experiment_name}_{label_suffix}"

                self._copy_round1_results(
                    self.experiment_dir,
                    variant_dir,
                    include_dirs=['contrastive_training', 'supervised_training', 'classifier_selection'],
                    skip_dirs=['consistency_scoring', 'consistency_scores']
                )

                detector = ExperimentStatusDetector(variant_dir, 1)
                stage1_done, stage1_path = detector.detect_stage1_contrastive_status()
                if stage1_done and stage1_path:
                    variant_manager.state_manager.save_stage_completion(
                        1, 'stage1_contrastive', stage1_path,
                        metadata={'reuse_from': self.experiment_dir}
                    )

                sup_done, sup_dir = detector.detect_supervised_learning_status()
                if sup_done and sup_dir:
                    variant_manager.state_manager.save_stage_completion(
                        1, 'supervised_learning', sup_dir,
                        metadata={'reuse_from': self.experiment_dir}
                    )

                cls_done, _ = detector.detect_classifier_selection_status()
                if cls_done:
                    cls_dir = os.path.join(variant_dir, 'round1', 'classifier_selection')
                    variant_manager.state_manager.save_stage_completion(
                        1, 'classifier_selection', cls_dir,
                        metadata={'reuse_from': self.experiment_dir}
                    )

                variant_manager.run_experiment(start_round=1, target_round=target_round)
                variant_records.append({'name': label_suffix, 'dir': variant_dir, 'status': 'completed'})
                print(f"âœ… å˜ä½“å®Œæˆ: {variant_dir}")

            except Exception as exc:
                variant_records.append({'name': label_suffix, 'dir': variant_dir, 'status': 'failed', 'error': str(exc)})
                print(f"âŒ å˜ä½“å¤±è´¥: {exc}")
                import traceback
                traceback.print_exc()
            finally:
                if os.path.exists(tmp_config_path):
                    os.remove(tmp_config_path)

        print(f"\n{'='*60}")
        print("å™ªå£°å˜ä½“å®éªŒå®Œæˆ")
        for record in variant_records:
            flag = 'âœ…' if record['status'] == 'completed' else 'âŒ'
            print(f" {flag} {record['name']}: {record['dir']}")
        print(f"{'='*60}")

    def run_multi_variant_experiment(self, target_round: int = 3,
                                    stage2_only: bool = False,
                                    custom_variants: List[dict] = None):
        """
        è¿è¡Œå¤šå˜ä½“å®éªŒ

        Args:
            target_round: ç›®æ ‡è½®æ¬¡
            stage2_only: æ˜¯å¦åªè¿è¡ŒStage2å˜ä½“
            custom_variants: è‡ªå®šä¹‰å˜ä½“é…ç½®åˆ—è¡¨
        """
        print(f"\n{'='*60}")
        print(f"å¤šå˜ä½“å®éªŒæ¨¡å¼")
        print(f"{'='*60}")

        # æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µæ˜¯å¦å®Œæˆ
        if stage2_only:
            detector = ExperimentStatusDetector(self.experiment_dir, 1)
            stage1_done, stage1_model = detector.detect_stage1_contrastive_status()

            if not stage1_done:
                print("âŒ ç¬¬ä¸€é˜¶æ®µæœªå®Œæˆï¼Œæ— æ³•åˆ›å»ºStage2å˜ä½“å®éªŒ")
                response = input("æ˜¯å¦å…ˆè¿è¡Œç¬¬ä¸€é˜¶æ®µï¼Ÿ(y/n): ")
                if response.lower() == 'y':
                    # åªè¿è¡Œç¬¬ä¸€è½®
                    self.run_experiment(rounds=[1])
                    # é‡æ–°æ£€æŸ¥
                    stage1_done, stage1_model = detector.detect_stage1_contrastive_status()
                    if not stage1_done:
                        print("ç¬¬ä¸€é˜¶æ®µè¿è¡Œå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                        return
                else:
                    return

        # åˆ›å»ºå˜ä½“ç®¡ç†å™¨
        variant_manager = ExperimentVariantManager(self.config, self.experiment_dir)

        # ä»é…ç½®æ–‡ä»¶è¯»å–å˜ä½“å®šä¹‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨custom_variantsæˆ–é»˜è®¤å€¼
        if 'variants' in self.config:
            # ä»é…ç½®æ–‡ä»¶è¯»å–å˜ä½“
            config_variants = []
            for variant_config in self.config['variants']:
                stage2_params = variant_config.get('stage2_contrastive', {})
                config_variants.append({
                    'weighting_strategy': stage2_params.get('weighting_strategy', 'threshold'),
                    'weight_threshold': stage2_params.get('weight_threshold', 0.5),
                    'base_lr': stage2_params.get('base_lr', 1e-4),
                    'epochs': stage2_params.get('epochs', 30),
                    'variant_name': variant_config.get('name', 'unnamed'),
                    'description': variant_config.get('description', '')
                })
            variants = variant_manager.create_stage2_variants(config_variants)
        else:
            # ä½¿ç”¨custom_variantsæˆ–é»˜è®¤å€¼
            variants = variant_manager.create_stage2_variants(custom_variants)

        print(f"\nğŸ“‹ å°†åˆ›å»º {len(variants)} ä¸ªå®éªŒå˜ä½“:")
        for i, (variant_config, variant_dir) in enumerate(variants):
            variant_name = variant_config.get('variant_meta', {}).get('name', 'unknown')
            print(f"  {i+1}. {variant_name} -> {variant_dir}")

        response = input("\nç¡®è®¤åˆ›å»ºè¿™äº›å˜ä½“ï¼Ÿ(y/n): ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆ")
            return

        # å¤åˆ¶ç¬¬ä¸€é˜¶æ®µç»“æœåˆ°å„å˜ä½“ç›®å½•
        variant_dirs = [variant_dir for _, variant_dir in variants]
        variant_manager.copy_stage1_results(self.experiment_dir, variant_dirs)

        print(f"\nå¼€å§‹è¿è¡Œå„å˜ä½“å®éªŒ...")

        # è¿è¡Œå„å˜ä½“
        variant_results = []
        for variant_config, variant_dir in variants:
            variant_name = variant_config.get('variant_meta', {}).get('name', 'unknown')
            print(f"\n{'='*40}")
            print(f"ğŸš€ å¼€å§‹å˜ä½“: {variant_name}")
            print(f"{'='*40}")

            try:
                # åˆ›å»ºå˜ä½“å®éªŒç®¡ç†å™¨
                variant_experiment = IterativeExperimentManager(
                    config_path=None,  # ç›´æ¥ä½¿ç”¨é…ç½®å¯¹è±¡
                    experiment_dir=variant_dir,
                    resume=True  # å˜ä½“æ€»æ˜¯å¯ç”¨æ–­ç‚¹ç»­ä¼ 
                )
                # ç›´æ¥è®¾ç½®é…ç½®
                variant_experiment.config = variant_config

                # ä»ç¬¬2è½®å¼€å§‹è¿è¡Œï¼ˆç¬¬1è½®å·²ç»å¤åˆ¶ï¼‰
                if stage2_only:
                    variant_experiment.run_experiment(
                        start_round=2,
                        target_round=target_round
                    )
                else:
                    variant_experiment.run_experiment(
                        target_round=target_round
                    )

                variant_results.append({
                    'name': variant_name,
                    'dir': variant_dir,
                    'status': 'completed'
                })

            except Exception as e:
                print(f"å˜ä½“ {variant_name} è¿è¡Œå¤±è´¥: {e}")
                variant_results.append({
                    'name': variant_name,
                    'dir': variant_dir,
                    'status': 'failed',
                    'error': str(e)
                })

        # æ±‡æ€»å˜ä½“ç»“æœ
        print(f"\n{'='*60}")
        print(f"å¤šå˜ä½“å®éªŒæ€»ç»“")
        print(f"{'='*60}")
        for result in variant_results:
            status_symbol = 'âœ…' if result['status'] == 'completed' else 'âŒ'
            print(f"{status_symbol} {result['name']}: {result['status']}")
            if result.get('error'):
                print(f"    é”™è¯¯: {result['error']}")

        print(f"\nåŸºç¡€å®éªŒç›®å½•: {self.experiment_dir}")
        print(f"å˜ä½“æ•°é‡: {len(variant_results)}")
        print(f"æˆåŠŸ: {sum(1 for r in variant_results if r['status'] == 'completed')}")
        print(f"å¤±è´¥: {sum(1 for r in variant_results if r['status'] == 'failed')}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è¿­ä»£å®éªŒç®¡ç†ç³»ç»Ÿï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤šå˜ä½“å®éªŒï¼‰')

    # åŸºæœ¬å‚æ•°
    parser.add_argument('--config', '-c', type=str, required=True,
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (YAMLæˆ–JSON)')

    parser.add_argument('--experiment-dir', '-d', type=str, default=None,
                       help='å®éªŒç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨åˆ›å»ºï¼‰')

    # è½®æ¬¡æ§åˆ¶
    parser.add_argument('--rounds', '-r', type=int, default=None,
                       help='ç›®æ ‡è½®æ¬¡ï¼Œè¿è¡Œåˆ°ç¬¬Nè½®ç»“æŸï¼ˆå¦‚: 3 è¡¨ç¤ºè¿è¡Œ1-3è½®ï¼‰')

    parser.add_argument('--start-round', '-s', type=int, default=None,
                       help='ä»æŸè½®å¼€å§‹è¿è¡Œ')

    parser.add_argument('--specific-rounds', type=str, default=None,
                       help='æŒ‡å®šå…·ä½“è¿è¡Œè½®æ¬¡ï¼Œå¦‚: "1,3,5" æˆ– "2-5"')

    # æ–­ç‚¹ç»­ä¼ ç›¸å…³
    parser.add_argument('--resume', action='store_true',
                       help='å¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œè‡ªåŠ¨è·³è¿‡å·²å®Œæˆçš„é˜¶æ®µ')

    parser.add_argument('--force-restart', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°å¼€å§‹ï¼Œå¿½ç•¥å·²æœ‰è¿›åº¦')

    # å¤šå˜ä½“å®éªŒç›¸å…³
    parser.add_argument('--multi-variant', action='store_true',
                       help='è¿è¡Œå¤šå˜ä½“å®éªŒï¼ˆåŸºäºç¬¬ä¸€é˜¶æ®µç»“æœï¼‰')

    parser.add_argument('--stage2-only', action='store_true',
                       help='å¤šå˜ä½“å®éªŒåªä»Stage2å¼€å§‹ï¼ˆéœ€è¦ç¬¬ä¸€é˜¶æ®µå·²å®Œæˆï¼‰')

    parser.add_argument('--scoring-fractions', type=float, nargs='+',
                       default=None,
                       help='ä¸€è‡´æ€§è¯„åˆ†ä½¿ç”¨çš„æ•°æ®æ¯”ä¾‹åˆ—è¡¨ï¼ˆå¦‚ï¼š0.05 0.1 0.2ï¼‰ï¼Œç”¨äºåˆ›å»ºå¤šä¸ªå˜ä½“ã€‚'
                            'è‡ªåŠ¨å¤ç”¨åŸºç¡€å®éªŒçš„Round 1ï¼ˆå¯¹æ¯”å­¦ä¹ ã€ç›‘ç£å­¦ä¹ ã€åˆ†ç±»å™¨é€‰æ‹©ï¼‰ï¼Œ'
                            'åªé‡æ–°è¿è¡Œä¸€è‡´æ€§è¯„åˆ†ã€‚éœ€è¦å…ˆè¿è¡ŒåŸºç¡€å®éªŒçš„Round 1ã€‚')

    parser.add_argument('--variant-dir-prefix', type=str, default=None,
                       help='å˜ä½“å®éªŒç›®å½•å‰ç¼€ï¼ˆå¦‚ï¼šmy_variantsï¼‰ï¼Œé»˜è®¤ä½¿ç”¨åŸºç¡€å®éªŒç›®å½•å')

    parser.add_argument('--noise-round1-supervised', action='store_true',
                       help='ä¸º Round 1 ä¸€è‡´æ€§è¯„åˆ†æ³¨å…¥å™ªå£°ï¼ˆå¤ç”¨å¯¹æ¯”å­¦ä¹ ä¸ç›‘ç£å­¦ä¹ ç»“æœï¼‰')

    parser.add_argument('--noise-params', type=str, nargs='+',
                       default=None,
                       help='Round 1 å™ªå£°å‚æ•°ç»„åˆï¼Œç¤ºä¾‹ï¼š"0.05" æˆ– '
                            '"fraction=0.1;mode=all_above_threshold;label=wide"ã€‚'
                            'batch_sizeå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼ã€‚'
                            'æ”¯æŒé”®ï¼šfraction/fracã€modeã€thresholdã€noise_poolã€target_binsã€seedã€labelã€‚'
                            'æ¯ä¸ªå‚æ•°ç»„åˆåˆ›å»ºä¸€ä¸ªå˜ä½“ï¼Œå®Œå…¨é€šè¿‡å‘½ä»¤è¡Œæ§åˆ¶ï¼Œæ— éœ€ä¿®æ”¹é…ç½®æ–‡ä»¶ã€‚')
    parser.add_argument('--noise-mode', type=str, choices=['by_bins', 'all_above_threshold'],
                       default='by_bins',
                       help='å™ªå£°æ³¨å…¥ç­–ç•¥ï¼šby_binsï¼ˆæŒ‰åŒºé—´æ›¿æ¢ï¼‰æˆ– all_above_thresholdï¼ˆæ•´ä½“æ›¿æ¢è¶…è¿‡é˜ˆå€¼çš„æ ·æœ¬ï¼‰ã€‚')
    parser.add_argument('--noise-threshold', type=float, default=0.4,
                       help='é«˜ç½®ä¿¡æ ·æœ¬é˜ˆå€¼ï¼ˆé»˜è®¤ 0.4ï¼Œä»…å½“æ¨¡å¼ä¸º all_above_threshold æ—¶ä½¿ç”¨ï¼‰ã€‚')
    parser.add_argument('--noise-pool', type=str, default='0.0-0.01',
                       help='å™ªå£°æ ·æœ¬æ± åŒºé—´ï¼ˆé»˜è®¤ 0.0-0.01ï¼Œå¯¹åº”ä½ä¸€è‡´æ€§æ ·æœ¬ï¼‰ã€‚')
    parser.add_argument('--noise-target-bins', type=str, default=None,
                       help='æ¨¡å¼ä¸º by_bins æ—¶ä½¿ç”¨ï¼ŒæŒ‡å®šé«˜ç½®ä¿¡åŒºé—´åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š"0.4-0.6,0.6-0.8,0.8-1.0"ã€‚')
    parser.add_argument('--noise-seed', type=int, default=None,
                       help='å™ªå£°æ³¨å…¥è¿‡ç¨‹çš„éšæœºç§å­ï¼Œé»˜è®¤éšæœºã€‚')

    # âœ¨ æ–°å¢ï¼šæ¨¡å‹åŸºåº§é€‰æ‹©
    parser.add_argument('--use-fresh-bert', action='store_true',
                       help='æ¯è½®ä»åŸå§‹BERTé‡æ–°è®­ç»ƒï¼ˆå›ºå®šåŸå§‹BERTåŸºåº§æ¨¡å¼ï¼‰ã€‚'
                            'é»˜è®¤ä¸ºç´¯ç§¯è®­ç»ƒæ¨¡å¼ï¼ˆæ¯è½®åŸºäºä¸Šä¸€è½®æ¨¡å‹ç»§ç»­è®­ç»ƒï¼‰ã€‚'
                            'æ­¤å‚æ•°ä¼šè¦†ç›–YAMLé…ç½®ä¸­çš„ use_fresh_bert_each_round è®¾ç½®ã€‚')

    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--check-status', action='store_true',
                       help='ä»…æ£€æŸ¥å®éªŒçŠ¶æ€ï¼Œä¸è¿è¡Œ')

    return parser.parse_args()


def parse_rounds_string(rounds_str: str) -> List[int]:
    """è§£æè½®æ¬¡å­—ç¬¦ä¸²"""
    if ',' in rounds_str:
        return [int(r.strip()) for r in rounds_str.split(',')]
    elif '-' in rounds_str:
        start, end = map(int, rounds_str.split('-'))
        return list(range(start, end + 1))
    else:
        return [int(rounds_str)]


def main():
    """ä¸»å‡½æ•°"""
    print("è¿­ä»£å®éªŒç®¡ç†ç³»ç»Ÿå¯åŠ¨")
    print("="*60)

    args = parse_arguments()

    try:
        # å¦‚æœåªæ˜¯æ£€æŸ¥çŠ¶æ€
        if args.check_status:
            if args.experiment_dir and os.path.exists(args.experiment_dir):
                print_experiment_status(args.experiment_dir, args.rounds or 3)
            else:
                print("è¯·æŒ‡å®šæœ‰æ•ˆçš„å®éªŒç›®å½•")
            return 0

        # åˆ›å»ºå®éªŒç®¡ç†å™¨
        manager = IterativeExperimentManager(
            config_path=args.config,
            experiment_dir=args.experiment_dir,
            resume=args.resume,
            force_restart=args.force_restart,
            use_fresh_bert=args.use_fresh_bert if args.use_fresh_bert else None  # âœ¨ ä¼ é€’æ¨¡å‹åŸºåº§å‚æ•°
        )

        # è¿è¡Œå¤šå˜ä½“å®éªŒ
        if args.multi_variant:
            # æ£€æŸ¥æ˜¯åŠ å™ªå®éªŒè¿˜æ˜¯æ•°æ®æ¯”ä¾‹å®éªŒ
            if args.noise_round1_supervised:
                # Round 1 åŠ å™ªå®éªŒ
                if not args.noise_params:
                    print("é”™è¯¯ï¼šä½¿ç”¨ --noise-round1-supervised éœ€è¦ --noise-params")
                    print('ç¤ºä¾‹ï¼š--noise-params "5,1e-5" "10,1e-4,64"')
                    print('      --noise-params "5,1e-5" "10,1e-4" "20,5e-5,128"')
                    return 1

                # ç¡®å®šç›®æ ‡è½®æ¬¡ï¼šå‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼3
                if args.rounds:
                    target_round = args.rounds
                else:
                    config_rounds = manager.config.get('experiment_meta', {}).get('rounds', [1, 2, 3])
                    target_round = max(config_rounds) if config_rounds else 3

                print(f"ç›®æ ‡è½®æ¬¡: {target_round}")
                manager.run_noise_variants(
                    target_round=target_round,
                    noise_params=args.noise_params,
                    variant_dir_prefix=args.variant_dir_prefix,
                    noise_mode=args.noise_mode,
                    noise_threshold=args.noise_threshold,
                    noise_pool=args.noise_pool,
                    noise_target_bins=args.noise_target_bins,
                    noise_seed=args.noise_seed
                )
            elif args.scoring_fractions:
                # æ•°æ®æ¯”ä¾‹å®éªŒ
                # ç¡®å®šç›®æ ‡è½®æ¬¡ï¼šå‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > é»˜è®¤å€¼3
                if args.rounds:
                    target_round = args.rounds
                else:
                    # ä»é…ç½®æ–‡ä»¶è¯»å–roundsè®¾ç½®
                    config_rounds = manager.config.get('experiment_meta', {}).get('rounds', [1, 2, 3])
                    target_round = max(config_rounds) if config_rounds else 3

                print(f"ç›®æ ‡è½®æ¬¡: {target_round}")
                manager.run_scoring_fraction_variants(
                    target_round=target_round,
                    scoring_fractions=args.scoring_fractions,
                    variant_dir_prefix=args.variant_dir_prefix
                )
            else:
                print("é”™è¯¯ï¼šä½¿ç”¨ --multi-variant éœ€è¦æŒ‡å®šä»¥ä¸‹ä¹‹ä¸€ï¼š")
                print("  1. æ•°æ®æ¯”ä¾‹å®éªŒï¼š--scoring-fractions 0.05 0.1 0.2")
                print('  2. Round 1 åŠ å™ªå®éªŒï¼š--noise-round1-supervised --noise-params "5,1e-5" "10,1e-4"')
                return 1
        else:
            # è§£æè½®æ¬¡å‚æ•°
            specific_rounds = None
            if args.specific_rounds:
                specific_rounds = parse_rounds_string(args.specific_rounds)

            # è¿è¡Œæ ‡å‡†å®éªŒ
            manager.run_experiment(
                rounds=specific_rounds,
                start_round=args.start_round,
                target_round=args.rounds
            )

    except FileNotFoundError as e:
        print(f"[é”™è¯¯] æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return 1
    except KeyboardInterrupt:
        print("\n[ä¸­æ–­] ç”¨æˆ·å–æ¶ˆå®éªŒ")
        return 2
    except Exception as e:
        print(f"[é”™è¯¯] å®éªŒå¤±è´¥: {e}")
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
